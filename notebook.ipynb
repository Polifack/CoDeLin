{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  S                          \n",
      "      ____________|_______________________    \n",
      "     |                VP                  |  \n",
      "     |         _______|____               |   \n",
      "     |        |   |       SBAR            |  \n",
      "     |        |   |    ____|____          |   \n",
      "     |        |   |   |         S         |  \n",
      "     |        |   |   |     ____|___      |   \n",
      "     NP       |   |  WHNP  NP       VP    |  \n",
      "  ___|___     |   |   |    |        |     |   \n",
      " DT     NNS  VBP  RB  WP  PRP      VBP  PUNCT\n",
      " |       |    |   |   |    |        |     |   \n",
      "The     owls are not what they     seem   .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_string = '(S (NP (DT The) (NNS owls)) (VP (VBP are) (RB not) (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (VBP seem))))) (PUNCT .))'\n",
    "tree = Tree.fromstring(tree_string)\n",
    "tree.pretty_print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive absolute encodes the number of commons between words w<sub>i</sub> and w<sub>i+1</sub>. This number is in the label associated to w<sub>i</sub>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'The' has 2 common ancestors with his next word. The last common ancestor is NP\n",
      "Word 'owls' has 1 common ancestors with his next word. The last common ancestor is S\n",
      "Word 'are' has 2 common ancestors with his next word. The last common ancestor is VP\n",
      "Word 'not' has 2 common ancestors with his next word. The last common ancestor is VP\n",
      "Word 'what' has 3 common ancestors with his next word. The last common ancestor is SBAR\n",
      "Word 'they' has 4 common ancestors with his next word. The last common ancestor is S\n",
      "Word 'seem' has 1 common ancestors with his next word. The last common ancestor is S\n",
      "Word '.' has 1 common ancestors with his next word. The last common ancestor is S\n"
     ]
    }
   ],
   "source": [
    "from src.encs.enc_const.naive_absolute import C_NaiveAbsoluteEncoding\n",
    "from src.models.const_tree import ConstituentTree\n",
    "\n",
    "encoder = C_NaiveAbsoluteEncoding(separator=\"_\", unary_joiner=\"+\")\n",
    "constituent_tree = ConstituentTree.from_string(tree_string)\n",
    "w, p, l, f = encoder.encode(constituent_tree)\n",
    "\n",
    "for i in range(len(w)):\n",
    "    n, lc = l[i].n_commons, l[i].last_common\n",
    "    print(\"Word '{}' has {} common ancestors with his next word. The last common ancestor is {}\".format(w[i], n, lc))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to encode in the word w<sub>i</sub> the number of commons between word w<sub>i-1</sub> and w<sub>i</sub>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Word 'The' has 1 common ancestors with his previous word. The last common ancestor is S.\n",
    "Word 'owls' has 2 common ancestors with his previous word. The last common ancestor is NP.\n",
    "Word 'are' has 1 common ancestors with his previous word. The last common ancestor is S.\n",
    "Word 'not' has 2 common ancestors with his previous word. The last common ancestor is VP.\n",
    "Word 'what' has 2 common ancestors with his previous word. The last common ancestor is VP.\n",
    "Word 'they' has 3 common ancestors with his previous word. The last common ancestor is SBAR.\n",
    "Word 'seem' has 4 common ancestors with his previous word. The last common ancestor is S.\n",
    "Word '.' has 1 common ancestors with his previous word. The last common ancestor is S.\n",
    "(...)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.encs.abstract_encoding import ACEncoding\n",
    "from src.utils.constants import C_ABSOLUTE_ENCODING, C_ROOT_LABEL, C_CONFLICT_SEPARATOR, C_NONE_LABEL, C_DUMMY_START, C_DUMMY_END\n",
    "from src.models.const_label import ConstituentLabel\n",
    "from src.models.const_tree import ConstituentTree\n",
    "\n",
    "import re\n",
    "\n",
    "class C_NaiveIncremental(ACEncoding):\n",
    "    def __init__(self, separator, unary_joiner):\n",
    "        self.separator = separator\n",
    "        self.unary_joiner = unary_joiner\n",
    "\n",
    "    def get_unary_chain(self, postag):\n",
    "        unary_chain = None\n",
    "        leaf_unary_chain = postag.split(self.unary_joiner)\n",
    "\n",
    "        if len(leaf_unary_chain)>1:\n",
    "            unary_list = []\n",
    "            for element in leaf_unary_chain[:-1]:\n",
    "                unary_list.append(element.split(\"##\")[0])\n",
    "\n",
    "            unary_chain = self.unary_joiner.join(unary_list)\n",
    "            postag = leaf_unary_chain[len(leaf_unary_chain)-1]\n",
    "        \n",
    "        return unary_chain, postag\n",
    "    \n",
    "    def get_features(self, node, feature_marker=\"##\", feature_splitter=\"|\"):\n",
    "        postag_split = node.split(feature_marker)\n",
    "        feats = None\n",
    "\n",
    "        if len(postag_split) > 1:\n",
    "            postag = re.sub(r'[0-9]+', '', postag_split[0])\n",
    "            feats = postag_split[1].split(feature_splitter)\n",
    "        else:\n",
    "            postag = re.sub(r'[0-9]+', '', node)\n",
    "        return postag, feats\n",
    "    \n",
    "    def clean_last_common(self, node, feature_marker=\"##\"):\n",
    "        node = re.sub(r'[0-9]+', '', node)\n",
    "        last_common = node.split(feature_marker)[0]\n",
    "        return last_common\n",
    "\n",
    "    def encode(self, constituent_tree):\n",
    "        constituent_tree.reverse_tree()\n",
    "        leaf_paths = constituent_tree.path_to_leaves(collapse_unary=True, unary_joiner=self.unary_joiner, dummy=C_DUMMY_END)\n",
    "        labels=[]\n",
    "        words=[]\n",
    "        postags=[]\n",
    "        additional_feats=[]\n",
    "\n",
    "        for i in range(1, len(leaf_paths)):\n",
    "            path_a = leaf_paths[i-1]\n",
    "            path_b = leaf_paths[i]\n",
    "            \n",
    "            last_common = \"\"\n",
    "            n_commons   = 0\n",
    "\n",
    "            for a,b in zip(path_a, path_b):\n",
    "                if (a!=b):\n",
    "                    # Remove the digits and aditional feats in the last common node\n",
    "                    last_common = self.clean_last_common(last_common)\n",
    "\n",
    "                    # Get word and POS tag\n",
    "                    word   = path_a[-1]\n",
    "                    postag = path_a[-2]\n",
    "                    \n",
    "                    # Build the Leaf Unary Chain\n",
    "                    unary_chain, postag = self.get_unary_chain(postag)\n",
    "                    \n",
    "                    # Clean the POS Tag and extract additional features\n",
    "                    postag, feats = self.get_features(postag)\n",
    "\n",
    "                    # Append the data\n",
    "                    labels.append(ConstituentLabel(n_commons, last_common, unary_chain, C_ABSOLUTE_ENCODING, self.separator, self.unary_joiner))\n",
    "                    words.append(word)\n",
    "                    postags.append(postag)\n",
    "                    additional_feats.append(feats)\n",
    "\n",
    "                    break\n",
    "                \n",
    "                # Store Last Common and increase n_commons \n",
    "                # Note: When increasing n_commons use the number from split the collapsed chains\n",
    "                n_commons  += len(a.split(self.unary_joiner))\n",
    "                last_common = a\n",
    "        \n",
    "        # reverse and return\n",
    "        words.reverse(); postags.reverse(); labels.reverse(); additional_feats.reverse()\n",
    "        return words, postags, labels, additional_feats\n",
    "\n",
    "\n",
    "\n",
    "    def decode(self, linearized_tree):\n",
    "        # Check valid labels \n",
    "        if not linearized_tree:\n",
    "            print(\"[*] Error while decoding: Null tree.\")\n",
    "            return\n",
    "\n",
    "        # Create constituent tree\n",
    "        tree = ConstituentTree(C_ROOT_LABEL, [])\n",
    "        current_level = tree\n",
    "\n",
    "        old_n_commons=0\n",
    "        old_level=None\n",
    "\n",
    "        linearized_tree.reverse()\n",
    "        for row in linearized_tree:\n",
    "            word, postag, label = row\n",
    "            \n",
    "            # Descend through the tree until reach the level indicated by last_common\n",
    "            current_level = tree\n",
    "            for level_index in range(label.n_commons):\n",
    "                if (current_level.is_terminal()) or (level_index >= old_n_commons):\n",
    "                    current_level.add_child(ConstituentTree(C_NONE_LABEL, []))\n",
    "                \n",
    "                current_level = current_level.r_child()\n",
    "\n",
    "            # Split the Last Common field of the Label in case it has a Unary Chain Collapsed\n",
    "            label.last_common = label.last_common.split(self.unary_joiner)\n",
    "\n",
    "            if len(label.last_common) == 1:\n",
    "                # If current level has no label yet, put the label\n",
    "                # If current level has label but different than this one, set it as a conflict\n",
    "                if (current_level.label == C_NONE_LABEL):\n",
    "                    current_level.label = label.last_common[0]\n",
    "                else:\n",
    "                    current_level.label = current_level.label + C_CONFLICT_SEPARATOR + label.last_common[0]\n",
    "            else:\n",
    "                current_level = tree\n",
    "                \n",
    "                # Descend to the beginning of the Unary Chain and fill it\n",
    "                descend_levels = label.n_commons - (len(label.last_common)) + 1\n",
    "                \n",
    "                for level_index in range(descend_levels):\n",
    "                    current_level = current_level.r_child()\n",
    "                \n",
    "                for i in range(len(label.last_common)-1):\n",
    "                    if (current_level.label == C_NONE_LABEL):\n",
    "                        current_level.label = label.last_common[i]\n",
    "                    else:\n",
    "                        current_level.label = current_level.label + C_CONFLICT_SEPARATOR + label.last_common[i]\n",
    "                    current_level = current_level.r_child()\n",
    "\n",
    "                # If we reach a POS tag, set it as child of the current chain\n",
    "                if current_level.is_preterminal():\n",
    "                    temp_current_level = current_level\n",
    "                    current_level.label = label.last_common[i+1]\n",
    "                    current_level.children = [temp_current_level]\n",
    "                \n",
    "                else:\n",
    "                    current_level.label=label.last_common[i+1]\n",
    "            \n",
    "            # Fill POS tag in this node or previous one\n",
    "            if (label.n_commons >= old_n_commons):\n",
    "                current_level.fill_pos_nodes(postag, word, label.unary_chain, self.unary_joiner)\n",
    "            \n",
    "            else:\n",
    "                old_level.fill_pos_nodes(postag, word, label.unary_chain, self.unary_joiner)\n",
    "\n",
    "            old_n_commons=label.n_commons\n",
    "            old_level=current_level\n",
    "\n",
    "        tree=tree.children[0]\n",
    "        tree.reverse_tree()\n",
    "        return tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An approach to this could be to get the path to leaves in reverse order, efectivelly using the same algorithm as naive absolute / naive relative but now w<sub>i-1</sub> will be w<sub>i+1</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S0', 'PUNCT0', '.']\n",
      "['S0', 'VP1', 'SBAR1', 'S1', 'VP+VBP1', 'seem']\n",
      "['S0', 'VP1', 'SBAR1', 'S1', 'NP+PRP2', 'they']\n",
      "['S0', 'VP1', 'SBAR1', 'WHNP+WP2', 'what']\n",
      "['S0', 'VP1', 'RB2', 'not']\n",
      "['S0', 'VP1', 'VBP3', 'are']\n",
      "['S0', 'NP2', 'NNS2', 'owls']\n",
      "['S0', 'NP2', 'DT3', 'The']\n",
      "['S0', '-START-']\n"
     ]
    }
   ],
   "source": [
    "constituent_tree = ConstituentTree.from_string(tree_string)\n",
    "path_to_leaves = constituent_tree.path_to_leaves(dummy=C_DUMMY_START)\n",
    "for p in path_to_leaves:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'The' has 1 common ancestors with his previous word. The last common ancestor is S\n",
      "Word 'owls' has 2 common ancestors with his previous word. The last common ancestor is NP\n",
      "Word 'are' has 1 common ancestors with his previous word. The last common ancestor is S\n",
      "Word 'not' has 2 common ancestors with his previous word. The last common ancestor is VP\n",
      "Word 'what' has 2 common ancestors with his previous word. The last common ancestor is VP\n",
      "Word 'they' has 3 common ancestors with his previous word. The last common ancestor is SBAR\n",
      "Word 'seem' has 4 common ancestors with his previous word. The last common ancestor is S\n",
      "Word '.' has 1 common ancestors with his previous word. The last common ancestor is S\n"
     ]
    }
   ],
   "source": [
    "incr_enc = C_NaiveIncremental(separator=\"_\", unary_joiner=\"+\")\n",
    "constituent_tree = ConstituentTree.from_string(tree_string)\n",
    "\n",
    "w, p, l, f = incr_enc.encode(constituent_tree)\n",
    "for i in range(len(w)):\n",
    "    n, lc = l[i].n_commons, l[i].last_common\n",
    "    print(\"Word '{}' has {} common ancestors with his previous word. The last common ancestor is {}\".format(w[i], n, lc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will have the whole tree during the decoding process, we could also reverse the order of the linearized tree rows and implement decoding backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Original Tree\n",
      "                  S                          \n",
      "      ____________|_______________________    \n",
      "     |                VP                  |  \n",
      "     |         _______|____               |   \n",
      "     |        |   |       SBAR            |  \n",
      "     |        |   |    ____|____          |   \n",
      "     |        |   |   |         S         |  \n",
      "     |        |   |   |     ____|___      |   \n",
      "     NP       |   |  WHNP  NP       VP    |  \n",
      "  ___|___     |   |   |    |        |     |   \n",
      " DT     NNS  VBP  RB  WP  PRP      VBP  PUNCT\n",
      " |       |    |   |   |    |        |     |   \n",
      "The     owls are not what they     seem   .  \n",
      "\n",
      "\n",
      ">> Linearized Tree\n",
      "\n",
      "('The', 'DT', 1_S)\n",
      "('owls', 'NNS', 2_NP)\n",
      "('are', 'VBP', 1_S)\n",
      "('not', 'RB', 2_VP)\n",
      "('what', 'WP', 2_VP_WHNP)\n",
      "('they', 'PRP', 3_SBAR_NP)\n",
      "('seem', 'VBP', 4_S_VP)\n",
      "('.', 'PUNCT', 1_S)\n",
      "\n",
      ">> Decoded Tree\n",
      "                  S                          \n",
      "      ____________|_______________________    \n",
      "     |                VP                  |  \n",
      "     |         _______|____               |   \n",
      "     |        |   |       SBAR            |  \n",
      "     |        |   |    ____|____          |   \n",
      "     |        |   |   |         S         |  \n",
      "     |        |   |   |     ____|___      |   \n",
      "     NP       |   |  WHNP  NP       VP    |  \n",
      "  ___|___     |   |   |    |        |     |   \n",
      " DT     NNS  VBP  RB  WP  PRP      VBP  PUNCT\n",
      " |       |    |   |   |    |        |     |   \n",
      "The     owls are not what they     seem   .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils.constants import C_STRAT_MAX\n",
    "tree_string = '(S (NP (DT The) (NNS owls)) (VP (VBP are) (RB not) (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (VBP seem))))) (PUNCT .))'\n",
    "tree = Tree.fromstring(tree_string)\n",
    "\n",
    "print(\"\\n>> Original Tree\")\n",
    "tree.pretty_print()\n",
    "\n",
    "incr_enc = C_NaiveIncremental(separator=\"_\", unary_joiner=\"+\")\n",
    "constituent_tree = ConstituentTree.from_string(tree_string)\n",
    "\n",
    "w, p, l, f = incr_enc.encode(constituent_tree)\n",
    "linearized_tree = [(wi, pi, li) for wi, pi, li, fi in zip(w, p, l, f)]\n",
    "\n",
    "print(\"\\n>> Linearized Tree\\n\")\n",
    "for line in linearized_tree:\n",
    "    print(line)\n",
    "decoded_tree = incr_enc.decode(linearized_tree)\n",
    "decoded_tree.postprocess_tree(conflict_strat=C_STRAT_MAX, clean_nulls=True)\n",
    "tree = Tree.fromstring(str(decoded_tree))\n",
    "\n",
    "print(\"\\n>> Decoded Tree\")\n",
    "tree.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cfa9136a6dd62194a07e3de69c680f647f4acccfc6f18ef0b3fb404551b0b99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
