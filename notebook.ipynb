{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  S                          \n",
      "      ____________|_______________________    \n",
      "     |                VP                  |  \n",
      "     |         _______|____               |   \n",
      "     |        |   |       SBAR            |  \n",
      "     |        |   |    ____|____          |   \n",
      "     |        |   |   |         S         |  \n",
      "     |        |   |   |     ____|___      |   \n",
      "     NP       |   |  WHNP  NP       VP    |  \n",
      "  ___|___     |   |   |    |        |     |   \n",
      " DT     NNS  VBP  RB  WP  PRP      VBP  PUNCT\n",
      " |       |    |   |   |    |        |     |   \n",
      "The     owls are not what they     seem   .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_string = '(S (NP (DT The) (NNS owls)) (VP (VBP are) (RB not) (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (VBP seem))))) (PUNCT .))'\n",
    "tree = Tree.fromstring(tree_string)\n",
    "tree.pretty_print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive absolute encodes the number of commons between words w<sub>i</sub> and w<sub>i+1</sub>. This number is in the label associated to w<sub>i</sub>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'The' has 2 common ancestors with his next word. The last common ancestor is NP\n",
      "Word 'owls' has 1 common ancestors with his next word. The last common ancestor is S\n",
      "Word 'are' has 2 common ancestors with his next word. The last common ancestor is VP\n",
      "Word 'not' has 2 common ancestors with his next word. The last common ancestor is VP\n",
      "Word 'what' has 3 common ancestors with his next word. The last common ancestor is SBAR\n",
      "Word 'they' has 4 common ancestors with his next word. The last common ancestor is S\n",
      "Word 'seem' has 1 common ancestors with his next word. The last common ancestor is S\n",
      "Word '.' has 1 common ancestors with his next word. The last common ancestor is S\n"
     ]
    }
   ],
   "source": [
    "from src.encs.enc_const.naive_absolute import C_NaiveAbsoluteEncoding\n",
    "from src.models.const_tree import ConstituentTree\n",
    "\n",
    "encoder = C_NaiveAbsoluteEncoding(separator=\"_\", unary_joiner=\"+\")\n",
    "constituent_tree = ConstituentTree.from_string(tree_string)\n",
    "w, p, l, f = encoder.encode(constituent_tree)\n",
    "\n",
    "for i in range(len(w)):\n",
    "    n, lc = l[i].n_commons, l[i].last_common\n",
    "    print(\"Word '{}' has {} common ancestors with his next word. The last common ancestor is {}\".format(w[i], n, lc))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to encode in the word w<sub>i</sub> the number of commons between word w<sub>i-1</sub> and w<sub>i</sub>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Word 'The' has 1 common ancestors with his previous word. The last common ancestor is S.\n",
    "Word 'owls' has 2 common ancestors with his previous word. The last common ancestor is NP.\n",
    "Word 'are' has 1 common ancestors with his previous word. The last common ancestor is S.\n",
    "Word 'not' has 2 common ancestors with his previous word. The last common ancestor is VP.\n",
    "Word 'what' has 2 common ancestors with his previous word. The last common ancestor is VP.\n",
    "Word 'they' has 3 common ancestors with his previous word. The last common ancestor is SBAR.\n",
    "Word 'seem' has 4 common ancestors with his previous word. The last common ancestor is S.\n",
    "Word '.' has 1 common ancestors with his previous word. The last common ancestor is S.\n",
    "(...)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.encs.abstract_encoding import ACEncoding\n",
    "from src.utils.constants import C_ABSOLUTE_ENCODING, C_ROOT_LABEL, C_CONFLICT_SEPARATOR, C_NONE_LABEL, C_DUMMY_START\n",
    "from src.models.const_label import ConstituentLabel\n",
    "from src.models.const_tree import ConstituentTree\n",
    "\n",
    "import re\n",
    "\n",
    "class C_NaiveIncremental(ACEncoding):\n",
    "    def __init__(self, separator, unary_joiner):\n",
    "        self.separator = separator\n",
    "        self.unary_joiner = unary_joiner\n",
    "\n",
    "    def get_unary_chain(self, postag):\n",
    "        unary_chain = None\n",
    "        leaf_unary_chain = postag.split(self.unary_joiner)\n",
    "\n",
    "        if len(leaf_unary_chain)>1:\n",
    "            unary_list = []\n",
    "            for element in leaf_unary_chain[:-1]:\n",
    "                unary_list.append(element.split(\"##\")[0])\n",
    "\n",
    "            unary_chain = self.unary_joiner.join(unary_list)\n",
    "            postag = leaf_unary_chain[len(leaf_unary_chain)-1]\n",
    "        \n",
    "        return unary_chain, postag\n",
    "    \n",
    "    def get_features(self, node, feature_marker=\"##\", feature_splitter=\"|\"):\n",
    "        postag_split = node.split(feature_marker)\n",
    "        feats = None\n",
    "\n",
    "        if len(postag_split) > 1:\n",
    "            postag = re.sub(r'[0-9]+', '', postag_split[0])\n",
    "            feats = postag_split[1].split(feature_splitter)\n",
    "        else:\n",
    "            postag = re.sub(r'[0-9]+', '', node)\n",
    "        return postag, feats\n",
    "    \n",
    "    def clean_last_common(self, node, feature_marker=\"##\"):\n",
    "        node = re.sub(r'[0-9]+', '', node)\n",
    "        last_common = node.split(feature_marker)[0]\n",
    "        return last_common\n",
    "\n",
    "    def encode(self, constituent_tree):\n",
    "        leaf_paths = constituent_tree.path_to_leaves(collapse_unary=True, unary_joiner=self.unary_joiner, dummy=C_DUMMY_START)\n",
    "        #print(leaf_paths)\n",
    "        labels=[]\n",
    "        words=[]\n",
    "        postags=[]\n",
    "        additional_feats=[]\n",
    "\n",
    "        # reverse the paths\n",
    "        leaf_paths.reverse()\n",
    "\n",
    "        for i in range(1, len(leaf_paths)):\n",
    "            path_a = leaf_paths[i-1]\n",
    "            path_b = leaf_paths[i]\n",
    "            \n",
    "            last_common = \"\"\n",
    "            n_commons   = 0\n",
    "\n",
    "            # reverse the paths\n",
    "            print(\"comparing {} with {}\".format(path_a, path_b))\n",
    "            for a,b in zip(path_a, path_b):\n",
    "                if (a!=b):\n",
    "                    # Remove the digits and aditional feats in the last common node\n",
    "                    last_common = self.clean_last_common(last_common)\n",
    "\n",
    "                    # Get word and POS tag\n",
    "                    word   = path_a[-1]\n",
    "                    postag = path_a[-2]\n",
    "                    \n",
    "                    # Build the Leaf Unary Chain\n",
    "                    unary_chain, postag = self.get_unary_chain(postag)\n",
    "                    \n",
    "                    # Clean the POS Tag and extract additional features\n",
    "                    postag, feats = self.get_features(postag)\n",
    "\n",
    "                    # Append the data\n",
    "                    labels.append(ConstituentLabel(n_commons+1, last_common, unary_chain, C_ABSOLUTE_ENCODING, self.separator, self.unary_joiner))\n",
    "                    words.append(word)\n",
    "                    postags.append(postag)\n",
    "                    additional_feats.append(feats)\n",
    "\n",
    "                    break\n",
    "                \n",
    "                # Store Last Common and increase n_commons \n",
    "                # Note: When increasing n_commons use the number from split the collapsed chains\n",
    "                n_commons  += len(a.split(self.unary_joiner))\n",
    "                last_common = a\n",
    "        \n",
    "        return words, postags, labels, additional_feats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An approach to this could be to get the path to leaves and reverse them, efectivelly using the same algorithm as naive absolute / naive relative but now w<sub>i-1</sub> will be w<sub>i+1</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S0', '-START-']\n",
      "['S1', 'NP1', 'DT1', 'The']\n",
      "['S1', 'NP2', 'NNS2', 'owls']\n",
      "['S2', 'VP2', 'VBP2', 'are']\n",
      "['S2', 'VP3', 'RB3', 'not']\n",
      "['S2', 'VP4', 'SBAR4', 'WHNP+WP4', 'what']\n",
      "['S2', 'VP4', 'SBAR5', 'S5', 'NP+PRP5', 'they']\n",
      "['S2', 'VP4', 'SBAR5', 'S6', 'VP+VBP6', 'seem']\n",
      "['S3', 'PUNCT3', '.']\n"
     ]
    }
   ],
   "source": [
    "constituent_tree = ConstituentTree.from_string(tree_string)\n",
    "path_to_leaves = constituent_tree.path_to_leaves(dummy=C_DUMMY_START)\n",
    "for p in path_to_leaves:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing ['S3', 'PUNCT3', '.'] with ['S2', 'VP4', 'SBAR5', 'S6', 'VP+VBP6', 'seem']\n",
      "comparing ['S2', 'VP4', 'SBAR5', 'S6', 'VP+VBP6', 'seem'] with ['S2', 'VP4', 'SBAR5', 'S5', 'NP+PRP5', 'they']\n",
      "comparing ['S2', 'VP4', 'SBAR5', 'S5', 'NP+PRP5', 'they'] with ['S2', 'VP4', 'SBAR4', 'WHNP+WP4', 'what']\n",
      "comparing ['S2', 'VP4', 'SBAR4', 'WHNP+WP4', 'what'] with ['S2', 'VP3', 'RB3', 'not']\n",
      "comparing ['S2', 'VP3', 'RB3', 'not'] with ['S2', 'VP2', 'VBP2', 'are']\n",
      "comparing ['S2', 'VP2', 'VBP2', 'are'] with ['S1', 'NP2', 'NNS2', 'owls']\n",
      "comparing ['S1', 'NP2', 'NNS2', 'owls'] with ['S1', 'NP1', 'DT1', 'The']\n",
      "comparing ['S1', 'NP1', 'DT1', 'The'] with ['S0', '-START-']\n",
      "Word 'The' has 1 common ancestors with his previous word. The last common ancestor is \n",
      "Word 'owls' has 2 common ancestors with his previous word. The last common ancestor is S\n",
      "Word 'are' has 1 common ancestors with his previous word. The last common ancestor is \n",
      "Word 'not' has 2 common ancestors with his previous word. The last common ancestor is S\n",
      "Word 'what' has 2 common ancestors with his previous word. The last common ancestor is S\n",
      "Word 'they' has 3 common ancestors with his previous word. The last common ancestor is VP\n",
      "Word 'seem' has 4 common ancestors with his previous word. The last common ancestor is SBAR\n",
      "Word '.' has 1 common ancestors with his previous word. The last common ancestor is \n"
     ]
    }
   ],
   "source": [
    "incr_enc = C_NaiveIncremental(separator=\"_\", unary_joiner=\"+\")\n",
    "constituent_tree = ConstituentTree.from_string(tree_string)\n",
    "w, p, l, f = incr_enc.encode(constituent_tree)\n",
    "\n",
    "# reverse the results\n",
    "w.reverse()\n",
    "p.reverse()\n",
    "l.reverse()\n",
    "f.reverse()\n",
    "\n",
    "for i in range(len(w)):\n",
    "    n, lc = l[i].n_commons, l[i].last_common\n",
    "    print(\"Word '{}' has {} common ancestors with his previous word. The last common ancestor is {}\".format(w[i], n, lc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cfa9136a6dd62194a07e3de69c680f647f4acccfc6f18ef0b3fb404551b0b99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
