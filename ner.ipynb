{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import copy\n",
    "from codelin.models.const_tree import C_Tree\n",
    "from codelin.encs.enc_const import *\n",
    "from codelin.utils.constants import *\n",
    "from nltk import Tree\n",
    "\n",
    "def entities_to_tree(words, tags, entities):\n",
    "    '''\n",
    "    Converts a list of entities into a tree\n",
    "    '''\n",
    "    t = C_Tree(\"ROOT\")\n",
    "    for i in range(len(words)):\n",
    "        w = words[i]\n",
    "        p = tags[i]\n",
    "        e = entities[i]\n",
    "\n",
    "        terminal_tree = C_Tree(p, C_Tree(w))\n",
    "\n",
    "        # No Entity\n",
    "        if e == \"NONE\":\n",
    "            t.add_child(terminal_tree)\n",
    "        \n",
    "        # Has entity\n",
    "        else:\n",
    "            if type(e) is list:\n",
    "                # decend through the rightmost branch of the tree\n",
    "                # until we find a branch with different entity name\n",
    "                # or we reach the end of the tree\n",
    "                cl = t\n",
    "                idx = 0\n",
    "                while cl.children and cl.children[-1].label == e[idx]:\n",
    "                    cl = cl.children[-1]\n",
    "                    idx += 1\n",
    "                    \n",
    "                    # check if we reached the end of the entity\n",
    "                    if idx == (len(e)-1):\n",
    "                        break\n",
    "\n",
    "                # add the rest of the entities as children\n",
    "                t1 = C_Tree(e[idx])\n",
    "                cl.add_child(t1)\n",
    "                cl = t1\n",
    "                for j in range(idx+1, len(e)):\n",
    "                    t1 = C_Tree(e[j])\n",
    "                    cl.add_child(t1)\n",
    "                    cl = t1\n",
    "                \n",
    "                cl.add_child(terminal_tree)\n",
    "            \n",
    "            # Single Entity\n",
    "            else:\n",
    "                # if rightmost branch of the tree has the same entity\n",
    "                # add it as a child\n",
    "                if t.children and t.children[-1].label == e:\n",
    "                    t.children[-1].add_child(terminal_tree)\n",
    "                # otherwise add a new branch\n",
    "                else:\n",
    "                    t.add_child(C_Tree(e, terminal_tree))\n",
    "    return t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NNE the sentences are formated as follows\n",
    "\n",
    "$w_1, w_2, w_3,$ (...) $w_n$<br>\n",
    "$p_1, p_2, p_3,$ (...) $p_n$<br>\n",
    "$se_1,ee_1 ne_1|se_2,ee_2 ne_2|$ (...) $|se_n,ee_n ne_n$\n",
    "\n",
    "where $w_i$ are the words of the sentence, $p_i$ are the postags of the sentence, $se_i$ is the start of the entity, $ee_i$ is the end of the entity and $ne_i$ is the name of the entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tree (ROOT (DT The) (JJ male) (NN part) (, ,) (DT the) (NNS anthers) (IN of) (DT the) (NN plant) (, ,) (CC and) (DT the) (NN female) (, ,) (DT the) (NNS pistils) (, ,) (IN of) (DT the) (JJ same) (NN plant) (VBP are) (IN within) (QUANTITY1D (DT a) (CARDINAL (NN fraction)) (IN of) (DT an) (UNIT (NN inch))) (CC or) (RB even) (VBN attached) (TO to) (DT each) (JJ other) (. .)) \n",
      "\n",
      "Decoded Tree  (ROOT (DT The) (JJ male) (NN part) (, ,) (DT the) (NNS anthers) (IN of) (DT the) (NN plant) (, ,) (CC and) (DT the) (NN female) (, ,) (DT the) (NNS pistils) (, ,) (IN of) (DT the) (JJ same) (NN plant) (VBP are) (IN within) (QUANTITYD (DT a) (CARDINAL (NN fraction)) (IN of) (DT an) (UNIT (NN inch))) (CC or) (RB even) (VBN attached) (TO to) (DT each) (JJ other) (. .))\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m dnt \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mdecode(lnt)\n\u001b[1;32m     70\u001b[0m dnt \u001b[39m=\u001b[39m dnt\u001b[39m.\u001b[39mpostprocess_tree(conflict_strat\u001b[39m=\u001b[39mC_STRAT_MAX, clean_nulls\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,)\n\u001b[0;32m---> 72\u001b[0m \u001b[39massert\u001b[39;00m t\u001b[39m.\u001b[39mshallow_equals(dnt), \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOriginal Tree\u001b[39m\u001b[39m\"\u001b[39m, t, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mDecoded Tree \u001b[39m\u001b[39m\"\u001b[39m, dnt)\n",
      "\u001b[0;31mAssertionError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "path = \"/home/droca1/Treebanks/nested_ner/NNE/\"\n",
    "files = ['train.txt', 'dev.txt', 'test.txt']\n",
    "\n",
    "def parse_entities(e, l):\n",
    "    '''\n",
    "    Parse entitties from NNE and returns \n",
    "    a list of entities for each word in the sentence \n",
    "    or NONE if there is no entity\n",
    "    '''\n",
    "    es = e.split(\"|\")\n",
    "    entities = [\"NONE\"]*l\n",
    "    for e in es:\n",
    "        idxs, name = e.split(\" \")\n",
    "        name = name.rstrip()\n",
    "        start, end = idxs.split(\",\")\n",
    "        entity_range = range(int(start), int(end)+1)\n",
    "        \n",
    "        for j in entity_range:\n",
    "            # add the index to differentiate between entities with the same name\n",
    "            e_r = (name, len(entity_range))\n",
    "            if \"NONE\" in entities[j]:\n",
    "                entities[j] = e_r\n",
    "            else:\n",
    "                entities[j] = [entities[j], e_r] if type(entities[j]) is not list else [*entities[j], e_r]\n",
    "\n",
    "                # List should be sorted by taking first entities with 'greater' range\n",
    "                entities[j] = sorted(entities[j], key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # return only the entity name\n",
    "    for i in range(len(entities)):\n",
    "        if type(entities[i]) is list:\n",
    "            entities[i] = [e[0] for e in entities[i]]\n",
    "        elif type(entities[i]) is tuple:\n",
    "            entities[i] = entities[i][0]\n",
    "\n",
    "    return entities\n",
    "        \n",
    "\n",
    "# Load the data into a list of sentencesW\n",
    "sentences = []\n",
    "tags      = []\n",
    "entities  = []\n",
    "train = path+files[0]\n",
    "dev = path+files[1]\n",
    "test = path+files[2]\n",
    "\n",
    "data = open(dev,'r').read().split('\\n\\n')[:-1]\n",
    "words, postags, entities = [], [], []\n",
    "\n",
    "for s in data:\n",
    "    # Get words, postags and entities\n",
    "    if s[0] == '\\n':\n",
    "        s=s[1:]\n",
    "    lines = s.split('\\n')\n",
    "    w, p, e = lines[:3] + [None]*(3-len(lines))\n",
    "    w = w.split(' ')\n",
    "    p = p.split(' ')\n",
    "\n",
    "    cs, ct, ce = w, p, parse_entities(e, len(w)) if e else [\"NONE\"]*len(w)\n",
    "\n",
    "    # Convert entities to trees\n",
    "    t = entities_to_tree(cs, ct, ce)\n",
    "\n",
    "    # Encode tree using CoDeLin\n",
    "    encoder = C_NaiveAbsoluteEncoding(separator=\"_\", unary_joiner=\"+\", reverse=False, binary=False, binary_direction=None, binary_marker=\"'b\")\n",
    "    lnt = encoder.encode(copy.deepcopy(t))\n",
    "\n",
    "    # Decode tree using CoDeLin\n",
    "    dnt = encoder.decode(lnt)\n",
    "    dnt = dnt.postprocess_tree(conflict_strat=C_STRAT_MAX, clean_nulls=True,)\n",
    "\n",
    "    # Motivo de error => path to leaves esta borrando los numeros de las entidades\n",
    "    assert t.shallow_equals(dnt), print(\"Original Tree\", t, \"\\n\\nDecoded Tree \", dnt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENIA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In GENIA dataset the sentences are formatted as a json file as follows:\n",
    "```\n",
    "{\n",
    "    \"tokens\": [\"Expression\", \"of\", \"c-fos\", \",\", \"c-jun\", \"and\", \"jun\", \"B\", \"in\", \"peripheral\", \"blood\", \"lymphocytes\", \"from\", \"young\", \"and\", \"elderly\", \"adults\", \".\"], \n",
    "    \"doc_id\": \"MEDLINE:93061407\", \"sent_id\": \"MEDLINE:93061407-0\", \n",
    "    \"entity_mentions\": [\n",
    "        {\"start\": 2, \"end\": 3, \"entity_type\": \"DNA\", \"text\": \"c-fos\"}, \n",
    "        {\"start\": 4, \"end\": 5, \"entity_type\": \"DNA\", \"text\": \"c-jun\"}, \n",
    "        {\"start\": 6, \"end\": 8, \"entity_type\": \"DNA\", \"text\": \"jun B\"}]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entities(es, l):\n",
    "    '''\n",
    "    Parse entities from GENIA and returns\n",
    "    a list of entities for each word in the sentence\n",
    "    or NONE if there is no entity\n",
    "    '''\n",
    "    \n",
    "    entities = [\"NONE\"] * l\n",
    "    for e in es:\n",
    "        name = e['entity_type']\n",
    "        start, end = e['start'], e['end']+1\n",
    "        \n",
    "        entity_range = range(int(start), int(end))\n",
    "        \n",
    "        for j in entity_range:\n",
    "            e_r = (name, len(entity_range))\n",
    "            if \"NONE\" in entities[j]:\n",
    "                entities[j] = e_r\n",
    "            else:\n",
    "                entities[j] = [entities[j], e_r] if type(entities[j]) is not list else [*entities[j], e_r]\n",
    "                entities[j] = sorted(entities[j], key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # return only the entity name\n",
    "    for i in range(len(entities)):\n",
    "        if type(entities[i]) is list:\n",
    "            entities[i] = [e[0] for e in entities[i]]\n",
    "        elif type(entities[i]) is tuple:\n",
    "            entities[i] = entities[i][0]\n",
    "    return entities\n",
    "\n",
    "path = \"/home/droca1/Treebanks/nested_ner/GENIA/ner-json/\"\n",
    "files = [\"train.jsonlines\", \"dev.jsonlines\", \"test.jsonlines\"]\n",
    "\n",
    "words       = []\n",
    "entities    = []\n",
    "postags     = []    \n",
    "train       = path+files[0]\n",
    "dev         = path+files[1]\n",
    "test        = path+files[2]\n",
    "\n",
    "for line in open(dev,'r').readlines():\n",
    "    # Get words, postags and entities\n",
    "    s = json.loads(line)\n",
    "    cs, ct, ce = s['tokens'], [\"NONE\"]*len(s['tokens']), parse_entities(s['entity_mentions'], len(s['tokens']))\n",
    "\n",
    "    # Convert entities to trees\n",
    "    t = entities_to_tree(cs, ct, ce)\n",
    "\n",
    "    # Encode tree using CoDeLin\n",
    "    encoder = C_NaiveAbsoluteEncoding(separator=\"_\", unary_joiner=\"+\", reverse=False, binary=False, binary_direction=None, binary_marker=\"'b\")\n",
    "    lnt = encoder.encode(copy.deepcopy(t))\n",
    "\n",
    "    # Decode tree using CoDeLin\n",
    "    dnt = encoder.decode(lnt)\n",
    "    dnt = dnt.postprocess_tree(conflict_strat=C_STRAT_MAX, clean_nulls=True)\n",
    "\n",
    "\n",
    "    assert t.shallow_equals(dnt), print(\"Original Tree\", t, \"\\n\\nDecoded Tree\", dnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
