{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Sequence\n",
    "from datasets import ClassLabel\n",
    "# from hfmtl.tasks.sequence_classification import SequenceClassification\n",
    "# from hfmtl.tasks.token_classification import TokenClassification\n",
    "# from hfmtl.utils import *\n",
    "# from hfmtl.models import *\n",
    "\n",
    "from PYEVALB.scorer import Scorer\n",
    "from PYEVALB.summary import summary\n",
    "\n",
    "from codelin.models.const_tree import C_Tree\n",
    "from codelin.models.const_label import C_Label\n",
    "from codelin.models.linearized_tree import LinearizedTree\n",
    "from codelin.encs.constituent import *\n",
    "from codelin.utils.constants import *\n",
    "\n",
    "import easydict\n",
    "from chrono import Timer\n",
    "from frozendict import frozendict\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "# Set logging level\n",
    "'''\n",
    "Train the models in multi-task learning fashion. To do this\n",
    "we will split the fields of the label and train different\n",
    "tasks according to this. After training, we will evaluate\n",
    "the decoded trees by re-joining the labels.\n",
    "'''\n",
    "\n",
    "ptb_path = \"~/Treebanks/const/PENN_TREEBANK/\"\n",
    "ptb_path = os.path.expanduser(ptb_path)\n",
    "\n",
    "with open(os.path.join(ptb_path,\"test.trees\")) as f:\n",
    "    ptb_test = [l.rstrip() for l in f.read().splitlines()]\n",
    "with open(os.path.join(ptb_path,\"dev.trees\")) as f:\n",
    "    ptb_dev = [l.rstrip() for l in f.read().splitlines()]\n",
    "with open(os.path.join(ptb_path,\"train.trees\")) as f:\n",
    "    ptb_train = [l.rstrip() for l in f.read().splitlines()]\n",
    "\n",
    "def get_n_labels(dsets, tar_field):\n",
    "    label_set = set()\n",
    "    for dset in dsets:\n",
    "        for labels in dset[tar_field]:\n",
    "            label_set.update(labels)\n",
    "    label_names = sorted(list(label_set))\n",
    "    return label_names, len(label_names)\n",
    "\n",
    "def generate_dataset_from_codelin(train_dset, dev_dset, test_dset=None):\n",
    "    dsets = [train_dset, dev_dset, test_dset] if test_dset else [train_dset, dev_dset]\n",
    "    \n",
    "    l1, nl1 = get_n_labels(dsets, \"target_1\")\n",
    "    print(\"Sample of labels target_1: n_commons:\", l1[5:10])\n",
    "    l2, nl2 = get_n_labels(dsets, \"target_2\")\n",
    "    print(\"Sample of labels target_2: last_common:\", l2[5:10])\n",
    "    l3, nl3 = get_n_labels(dsets, \"target_3\")\n",
    "    print(\"Sample of labels target_3: unary_chain:\", l3[5:10])\n",
    "\n",
    "    train_dset = datasets.Dataset.from_dict(train_dset)\n",
    "    train_dset = train_dset.cast_column(\"target_1\", Sequence(ClassLabel(num_classes=nl1, names=l1)))\n",
    "    train_dset = train_dset.cast_column(\"target_2\", Sequence(ClassLabel(num_classes=nl2, names=l2)))\n",
    "    train_dset = train_dset.cast_column(\"target_3\", Sequence(ClassLabel(num_classes=nl3, names=l3)))\n",
    "\n",
    "    dev_dset = datasets.Dataset.from_dict(dev_dset)\n",
    "    dev_dset = dev_dset.cast_column(\"target_1\", Sequence(ClassLabel(num_classes=nl1, names=l1)))\n",
    "    dev_dset = dev_dset.cast_column(\"target_2\", Sequence(ClassLabel(num_classes=nl2, names=l2)))\n",
    "    dev_dset = dev_dset.cast_column(\"target_3\", Sequence(ClassLabel(num_classes=nl3, names=l3)))\n",
    "\n",
    "    if test_dset:\n",
    "        test_dset = datasets.Dataset.from_dict(test_dset)\n",
    "        test_dset = test_dset.cast_column(\"target_1\", Sequence(ClassLabel(num_classes=nl1, names=l1)))\n",
    "        test_dset = test_dset.cast_column(\"target_2\", Sequence(ClassLabel(num_classes=nl2, names=l2)))\n",
    "        test_dset = test_dset.cast_column(\"target_3\", Sequence(ClassLabel(num_classes=nl3, names=l3)))\n",
    "    \n",
    "        # Convert to Hugging Face DatasetDict format\n",
    "        dataset = datasets.DatasetDict({\n",
    "                \"train\": train_dset,\n",
    "                \"validation\": dev_dset,\n",
    "                \"test\": test_dset\n",
    "            })\n",
    "    else:\n",
    "        # Convert to Hugging Face DatasetDict format\n",
    "        dataset = datasets.DatasetDict({\n",
    "                \"train\": train_dset,\n",
    "                \"validation\": dev_dset\n",
    "            })\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def encode_dset(encoder, dset):\n",
    "    encoded_trees = {\"tokens\":[], \"target_1\":[], \"target_2\":[], \"target_3\":[]}\n",
    "    max_len_tree = 0\n",
    "    for line in dset:\n",
    "        tree = C_Tree.from_string(line)\n",
    "        lin_tree = encoder.encode(tree)\n",
    "        encoded_trees[\"tokens\"].append([w for w in lin_tree.words])\n",
    "        \n",
    "        t1,t2,t3 = [],[],[]\n",
    "        for s1,s2,s3 in lin_tree.get_labels_splitted():\n",
    "            t1.append(s1)    \n",
    "            t2.append(s2)\n",
    "            t3.append(s3)\n",
    "            \n",
    "        encoded_trees[\"target_1\"].append(t1)\n",
    "        encoded_trees[\"target_2\"].append(t2)\n",
    "        encoded_trees[\"target_3\"].append(t3)\n",
    "        \n",
    "        max_len_tree = max(max_len_tree, len(lin_tree.words))\n",
    "    \n",
    "    \n",
    "    return encoded_trees, max_len_tree\n",
    "\n",
    "def gen_dsets():\n",
    "    encodings = []\n",
    "\n",
    "    # naive absolute encodings\n",
    "    a_enc     = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute\", \"encoder\":a_enc})\n",
    "    a_br_enc  = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_br\", \"encoder\":a_br_enc})\n",
    "    a_bl_enc  = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_bl\", \"encoder\":a_bl_enc})\n",
    "    ar_enc    = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_r\", \"encoder\":ar_enc})\n",
    "    ar_br_enc = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_r_br\", \"encoder\":ar_br_enc})\n",
    "    ar_bl_enc = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_r_bl\", \"encoder\":ar_bl_enc})\n",
    "\n",
    "    # naive relative encodings\n",
    "    r_enc     = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative\", \"encoder\":r_enc})\n",
    "    r_br_enc  = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_br\", \"encoder\":r_br_enc})\n",
    "    r_bl_enc  = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_bl\", \"encoder\":r_bl_enc})\n",
    "    rr_enc    = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_r\", \"encoder\":rr_enc})\n",
    "    rr_br_enc = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_r_br\", \"encoder\":rr_br_enc})\n",
    "    rr_bl_enc = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_r_bl\", \"encoder\":rr_bl_enc})\n",
    "\n",
    "    # naive dynamic encodings\n",
    "    d_enc     = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic\", \"encoder\":d_enc})\n",
    "    d_br_enc  = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_br\", \"encoder\":d_br_enc})\n",
    "    d_bl_enc  = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_bl\", \"encoder\":d_bl_enc})\n",
    "    dr_enc    = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_r\", \"encoder\":dr_enc})\n",
    "    dr_br_enc = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_r_br\", \"encoder\":dr_br_enc})\n",
    "    dr_bl_enc = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_r_bl\", \"encoder\":dr_bl_enc})\n",
    "\n",
    "    # gaps encodings\n",
    "    g_r_enc   = C_GapsEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary_direction=\"R\", binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"gaps_r\", \"encoder\":g_r_enc})\n",
    "    g_l_enc   = C_GapsEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary_direction=\"L\", binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"gaps_l\", \"encoder\":g_l_enc})\n",
    "\n",
    "    # tetra encodings\n",
    "    t_pr_enc  = C_Tetratag(separator=\"[_]\", unary_joiner=\"[+]\", mode='preorder',  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"tetratag_preorder\", \"encoder\":t_pr_enc})\n",
    "    t_in_enc  = C_Tetratag(separator=\"[_]\", unary_joiner=\"[+]\", mode='inorder',   binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"tetratag_inorder\", \"encoder\":t_in_enc})\n",
    "    t_po_enc  = C_Tetratag(separator=\"[_]\", unary_joiner=\"[+]\", mode='postorder', binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"tetratag_postorder\", \"encoder\":t_po_enc})\n",
    "\n",
    "    # yuxtaposed encodings\n",
    "    j_enc   = C_JuxtaposedEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"juxtaposed\", \"encoder\":j_enc})\n",
    "    j_r_enc = C_JuxtaposedEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary=True, binary_direction='R',   binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"juxtaposed_r\", \"encoder\":j_r_enc})\n",
    "    j_l_enc = C_JuxtaposedEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary=True, binary_direction='L',   binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"juxtaposed_l\", \"encoder\":j_l_enc})\n",
    "\n",
    "    return encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TokenClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        self.classifier.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        if self.classifier.bias is not None:\n",
    "            self.classifier.bias.data.zero_()\n",
    "\n",
    "    def forward(self, sequence_output, pooled_output, labels = None, attention_mask = None, **kwargs):\n",
    "        sequence_output_dropout = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output_dropout)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            labels = labels.long()\n",
    "\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask is not None:\n",
    "                active_loss = attention_mask.view(-1) == 1\n",
    "                active_logits = logits.view(-1, self.num_labels)\n",
    "                active_labels = torch.where(\n",
    "                    active_loss,\n",
    "                    labels.view(-1),\n",
    "                    torch.tensor(loss_fct.ignore_index).type_as(labels),\n",
    "                )\n",
    "                loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "from torch import nn\n",
    "from torch.utils.data.sampler import RandomSampler, WeightedRandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from transformers.data.data_collator import InputDataClass\n",
    "from types import MappingProxyType\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import transformers\n",
    "from transformers.trainer_utils import EvalLoopOutput\n",
    "\n",
    "class DataLoaderWithTaskname:\n",
    "    def __init__(self, task_name, data_loader):\n",
    "        self.task = task_name\n",
    "        self.data_loader = data_loader\n",
    "        self.batch_size = data_loader.batch_size\n",
    "        self.dataset = data_loader.dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.data_loader:\n",
    "            yield batch\n",
    "class NLPDataCollator:\n",
    "    def __init__(self, tasks):\n",
    "        self.tasks = tasks\n",
    "\n",
    "    def __call__(self, features: List[Union[InputDataClass, Dict]]) -> Dict[str, torch.Tensor]:\n",
    "        print(\"NLPDATACOLLATOR Features:\",features.keys())\n",
    "        try:\n",
    "            task_index = features[0][\"task\"].flatten()[0].item()\n",
    "        except:\n",
    "            task_index = features[-1][\"task\"].flatten()[0].item()\n",
    "            \n",
    "        features = [{k:v for k,v in x.items() if k!='task'} for x in features]\n",
    "        collated = self.tasks[task_index].data_collator.__call__(features)\n",
    "        collated['task'] = torch.tensor([task_index])\n",
    "        return collated\n",
    "class MultitaskDataloader:\n",
    "    \"\"\"\n",
    "    Data loader that combines and samples from multiple single-task\n",
    "    data loaders.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataloader_dict, p=1):\n",
    "        self.dataloader_dict = dataloader_dict\n",
    "        N = max([len(x)**(1-p) for x in dataloader_dict.values()])\n",
    "        \n",
    "        f_p = lambda x: int(N*x**p)\n",
    "\n",
    "        self.num_batches_dict = {\n",
    "            task_name: f_p(len(dataloader))\n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "        self.task_name_list = list(self.dataloader_dict)\n",
    "        self.dataset = [None] * sum(\n",
    "            f_p(len(dataloader.dataset)) for dataloader in self.dataloader_dict.values()\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.num_batches_dict.values())\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        For each batch, sample a task, and yield a batch from the respective\n",
    "        task Dataloader.\n",
    "        \"\"\"\n",
    "        task_choice_list = []\n",
    "        for i, task_name in enumerate(self.task_name_list):\n",
    "            task_choice_list += [i] * self.num_batches_dict[task_name]\n",
    "        task_choice_list = np.array(task_choice_list)\n",
    "        np.random.shuffle(task_choice_list)\n",
    "        \n",
    "        dataloader_iter_dict = {\n",
    "            task_name: iter(dataloader)\n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "\n",
    "        for task_choice in task_choice_list:\n",
    "            task_name = self.task_name_list[task_choice]\n",
    "            yield next(dataloader_iter_dict[task_name])\n",
    "\n",
    "\n",
    "\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, encoder_name_or_path, tasks):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name_or_path)\n",
    "        tokenizer_kwargs = frozendict(padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(encoder_name_or_path, **tokenizer_kwargs)\n",
    "        self.output_heads = nn.ModuleDict()\n",
    "        \n",
    "        for task in tasks:\n",
    "            ###############################\n",
    "            print(\"[TRN] Creating output head for task\", task.name)\n",
    "            print(\"      - Task type:\", task.task_type)\n",
    "            print(\"      - Number of labels:\", task.num_labels)\n",
    "            print(\"      - Label names:\")\n",
    "            for k, v in task.label_names.items():\n",
    "                print(\"            -\", k, \":\", v)            \n",
    "            print(\"[TRN] Example input:\")\n",
    "            sample = task.dataset['train'][0]\n",
    "            for k, v in sample.items():\n",
    "                print(\"      -\", k, \":\", v)\n",
    "            print(\"[TRN] Example input (real labels):\")\n",
    "            sample = task.dataset['train'][0]\n",
    "            for k, v in sample.items():\n",
    "                if k in task.label_names.keys():\n",
    "                    print(\"      -\", [task.label_names[k][vi] for vi in v])\n",
    "            ###############################\n",
    "            \n",
    "            task.set_tokenizer(self.tokenizer)\n",
    "            for subtask in task.y:\n",
    "                decoder = self._create_output_head(\n",
    "                    self.encoder.config.hidden_size, \n",
    "                    task.task_type, \n",
    "                    task.num_labels[subtask]\n",
    "                )\n",
    "                \n",
    "                self.output_heads[subtask] = decoder\n",
    "\n",
    "        self.processed_tasks = self.preprocess_tasks(tasks, self.tokenizer)\n",
    "        self.label_names = {task.name: task.label_names for task in tasks}\n",
    "        self.train_dataset = {self.processed_tasks[task.name]['train'] for task in tasks}\n",
    "        self.eval_dataset = {self.processed_tasks[task.name]['validation'] for task in tasks}\n",
    "        \n",
    "        print(\"[TRN] Model has\", len(self.output_heads), \"output heads\")\n",
    "        print(\"[TRN] Model has\", len(self.train_dataset), \"training datasets\")\n",
    "        print(\"[TRN] Model has\", len(self.eval_dataset), \"evaluation datasets\")\n",
    "    \n",
    "    def preprocess_tasks(self, tasks, tokenizer):      \n",
    "        features_dict = {}\n",
    "        for i, task in enumerate(tasks):\n",
    "            print(\"Model is preprocessing task\", task.name)\n",
    "            \n",
    "            if hasattr(task, 'processed_features') and tokenizer == task.tokenizer:\n",
    "                print(\"==> Task features are already processed, skipping...\")\n",
    "                features_dict[task.name] = task.processed_features\n",
    "                continue\n",
    "            \n",
    "            for split in task.dataset:\n",
    "                task.index = task.dataset[split].index = i\n",
    "            \n",
    "            features_dict[task.name] = {}\n",
    "            for phase, phase_dataset in task.dataset.items():\n",
    "                phase_dataset.index = i\n",
    "\n",
    "                features_dict[task.name][phase] = phase_dataset.map(\n",
    "                    task.preprocess_function, \n",
    "                    batched = True,\n",
    "                    batch_size = 8,\n",
    "                    load_from_cache_file = True\n",
    "                )\n",
    "            print(\"Model finished preprocessing task\", task.name)\n",
    "        return features_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_output_head(encoder_hidden_size: int, task_type, n_labels):\n",
    "        if task_type == \"TokenClassification\":\n",
    "            print(\"Creating TokenClassification head w/\", n_labels, \"labels\")\n",
    "            return TokenClassificationHead(encoder_hidden_size, n_labels)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    \n",
    "    def forward(self, input_ids = None, attention_mask = None, token_type_ids = None, position_ids = None,\n",
    "            head_mask = None, inputs_embeds = None, labels = None, task_ids = None, **kwargs):\n",
    "            \n",
    "            # compute the transformer output\n",
    "            outputs = self.encoder(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                position_ids=position_ids,\n",
    "                head_mask=head_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "            )\n",
    "            sequence_output, pooled_output = outputs[:2]\n",
    "\n",
    "            print(\"3) Transformer has been forwarded\")\n",
    "            unique_task_ids_list = torch.unique(task_ids).tolist()\n",
    "\n",
    "            loss_list = []\n",
    "            logits = None\n",
    "            # print(\"Computing loss...\")\n",
    "            # print(\"task_ids\", task_ids)\n",
    "            print(\"==> I have to compute loss for the following tasks:\")\n",
    "            print(\"==>\", unique_task_ids_list)\n",
    "            for unique_task_id in unique_task_ids_list:\n",
    "                print(\"Task_id =\",unique_task_id)\n",
    "                ptc_train = self.processed_tasks['train']\n",
    "                target_cols = [col for col in ptc_train.features if col.startswith(\"target_\")]\n",
    "                print(\"target_cols =\", target_cols)\n",
    "\n",
    "                for tc in target_cols:\n",
    "                    print(\"Target Column =\",tc)\n",
    "                    print(\"Labels =\",labels)\n",
    "                    logits, task_loss = self.output_heads[str(unique_task_id)].forward(\n",
    "                        sequence_output[task_id_filter],\n",
    "                        pooled_output[task_id_filter],\n",
    "                        labels = None if labels is None else labels[task_id_filter],\n",
    "                        attention_mask=attention_mask[task_id_filter],\n",
    "                    )\n",
    "\n",
    "                    if labels is not None:\n",
    "                        loss_list.append(task_loss)\n",
    "\n",
    "            # Loss averaged over all tasks\n",
    "            outputs = (logits, outputs[2:])\n",
    "            if loss_list:\n",
    "                loss = torch.stack(loss_list)\n",
    "                outputs = (loss.mean(),) + outputs\n",
    "\n",
    "            return outputs\n",
    "\n",
    "class MultiTaskTrainer(transformers.Trainer):\n",
    "    def __init__(self, tasks, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.p = 1\n",
    "        self.processed_tasks = self.model.processed_tasks\n",
    "        self.label_names = self.model.label_names\n",
    "        self.train_dataset = {\n",
    "            task: dataset[\"train\"]\n",
    "            for task, dataset in self.processed_tasks.items()\n",
    "        }\n",
    "        self.eval_dataset = {\n",
    "            task: dataset[\"validation\"]\n",
    "            for task, dataset in self.processed_tasks.items()\n",
    "        }\n",
    "        self.eval_dataset = MappingProxyType(self.eval_dataset)\n",
    "        self.tokenizer = self.model.tokenizer\n",
    "        self.pretrained_transformer = self.model.encoder\n",
    "        self.device = self.pretrained_transformer.device\n",
    "        self.data_collator = NLPDataCollator(tasks)\n",
    "        print(\"[*] Init multitask trainer with tasks:\", self.processed_tasks)\n",
    "        print(\"[*] Label names are:\", self.label_names)\n",
    "        \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=[]):\n",
    "        if ignore_keys is None:\n",
    "            ignore_keys = []\n",
    "        \n",
    "        inputs.to(self.device)\n",
    "        loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n",
    "        loss = loss.mean().detach()\n",
    "        print(\"[*] Prediction Step...\")\n",
    "        print(\"    inputs\", inputs.keys())\n",
    "        print(\"    outputs\", outputs.keys())\n",
    "        print(\"    loss\", loss)\n",
    "        \n",
    "        \n",
    "        logits_dict = {}\n",
    "        labels_dict = {}\n",
    "        print(\"[*] Extracting logits and labels...\")\n",
    "        for task_name, label_names in self.label_names.items():\n",
    "            logits_dict[task_name] = {}\n",
    "            labels_dict[task_name] = {}\n",
    "            for label_name in label_names:\n",
    "                logits_dict[task_name][label_name] = outputs[label_name]\n",
    "                labels_dict[task_name][label_name] = np.argmax(outputs[label_name].detach().cpu().numpy(), axis=2)\n",
    "        \n",
    "        print(\"[*] Prediction step ended:\")\n",
    "        print(\"    logits_dict\", logits_dict.keys())\n",
    "        print(\"    labels_dict\", labels_dict.keys())\n",
    "        print(\"    loss\", loss)\n",
    "\n",
    "        return (loss, logits_dict, labels_dict)\n",
    "    \n",
    "    def get_single_train_dataloader(self, task_name, train_dataset):\n",
    "        \"\"\"\n",
    "        Create a single-task data loader that also yields task names\n",
    "        \"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "        \n",
    "        train_sampler = (SequentialSampler(train_dataset) if self.args.local_rank == -1 else DistributedSampler(train_dataset))\n",
    "\n",
    "        data_loader = DataLoaderWithTaskname(\n",
    "            task_name = task_name,\n",
    "            data_loader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size = self.args.train_batch_size,\n",
    "                shuffle = False,\n",
    "                sampler = train_sampler,\n",
    "                collate_fn = self.data_collator.__call__,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        print(type(self.train_dataset))\n",
    "        print(self.train_dataset.items())\n",
    "        return MultitaskDataloader(\n",
    "            {\n",
    "                task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
    "                for task_name, task_dataset in self.train_dataset.items()\n",
    "            }, p = self.p,\n",
    "        )\n",
    "    \n",
    "    def get_eval_dataloader(self, eval_dataset=None):\n",
    "        return MultitaskDataloader(\n",
    "            {\n",
    "                task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
    "                for task_name, task_dataset in (\n",
    "                    eval_dataset if eval_dataset else self.eval_dataset\n",
    "                ).items()\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def evaluation_loop(self, dataloader: DataLoader, description: str, prediction_loss_only: bool | None = None, ignore_keys: List[str] | None = None, metric_key_prefix: str = \"eval\") -> EvalLoopOutput:\n",
    "        print(\"[*] Evaluation_loop\")\n",
    "        def has_length(dataset):\n",
    "            try:\n",
    "                return len(dataset) is not None\n",
    "            except TypeError:\n",
    "                return False\n",
    "            \n",
    "        model = self._wrap_model(self.model, training=False, dataloader=dataloader)\n",
    "\n",
    "        if has_length(dataloader):\n",
    "            print(f\"    num examples {self.num_examples(dataloader)}\")\n",
    "        \n",
    "        eval_results = {}\n",
    "        print(dataloader)\n",
    "        for step, inputs in enumerate(dataloader):\n",
    "            print(\"[*] Step\", step, \"of\", len(dataloader), \"...\")\n",
    "            print(\"    inputs\", inputs)\n",
    "            loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n",
    "            \n",
    "            for task, label_names in self.label_names.items():\n",
    "                print(\"[*] Evaluating task:\",task)\n",
    "                logits_task = logits[task]\n",
    "                labels_task = labels[task]\n",
    "                for labels_name, labels_values in label_names.items():\n",
    "                    print(\"[*] Computing metrics for subtask\", labels_name, \"...\")\n",
    "                    logits_tl   = logits_task[labels_name]\n",
    "                    labels_tl   = labels_task[labels_name]\n",
    "\n",
    "                    # aqui estas haciendo algo mal, porque labels_tl es las labels\n",
    "                    # reales, y logits_tl son las predichas\n",
    "                    eval_pred = EvalPrediction(\n",
    "                                predictions = logits_tl, \n",
    "                                label_ids   = labels_tl, \n",
    "                                inputs      = inputs)\n",
    "                    \n",
    "                    print(\"    logits shape\", logits_tl.shape) \n",
    "                    print(\"    labels shape\", labels_tl.shape)\n",
    "                    print(\"    inputs shape\", inputs.keys())\n",
    "                    print(\"    eval_pred\", eval_pred)\n",
    "\n",
    "                    # compute metrics foreach head using the corresponding task eval_function\n",
    "                    # i copied the function from the task-specific class to this one\n",
    "                    metrics = self.compute_metrics_token_classification(eval_pred)\n",
    "                    print(\"    metrics\", metrics)\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def compute_metrics_token_classification(self, eval_pred):\n",
    "        logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        print(logits.shape)\n",
    "        predictions = np.argmax(logits.detach().cpu().numpy(), axis=-1)\n",
    "        true_labels = [\n",
    "            [self.label_names[l] for l in label if l != -100] for label in labels\n",
    "        ]\n",
    "        true_predictions = [\n",
    "            [self.label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        all_metrics = self.metric.compute(\n",
    "            predictions = true_predictions, \n",
    "            references = true_labels\n",
    "        )\n",
    "        meta = {\"name\": self.name, \"size\": len(predictions), \"index\": self.index}\n",
    "        metrics = {k.replace(\"overall_\",\"\"):v for k,v in all_metrics.items() if \"overall\" in k}\n",
    "        self.results+=[metrics]\n",
    "        return {**metrics, **meta}      \n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        print(\"[*] Computing Loss...\")\n",
    "        input_ids = inputs['input_ids'] if 'input_ids' in inputs.keys() else None\n",
    "        attention_mask = inputs['attention_mask'] if 'attention_mask' in inputs.keys() else None\n",
    "        token_type_ids = inputs['token_type_ids'] if 'token_type_ids' in inputs.keys() else None\n",
    "        position_ids = inputs['position_ids'] if 'position_ids' in inputs.keys() else None\n",
    "        head_mask = inputs['head_mask'] if 'head_mask' in inputs.keys() else None\n",
    "        inputs_embeds = inputs['inputs_embeds'] if 'inputs_embeds' in inputs.keys() else None\n",
    "\n",
    "        outputs = self.pretrained_transformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        sequence_output, pooled_output = outputs[:2]\n",
    "        loss_list = []\n",
    "        logits_list = {}\n",
    "        for i, head in enumerate(self.model.output_heads.values()):\n",
    "            labels_name = f\"target_{i+1}\"\n",
    "            labels_i = inputs.pop(labels_name, None)\n",
    "            logits, loss = head(sequence_output, pooled_output, labels=labels_i, attention_mask=attention_mask)\n",
    "            loss_list.append(loss)\n",
    "            logits_list[labels_name] = logits\n",
    "        \n",
    "        loss = torch.stack(loss_list)\n",
    "        print(\"    loss\", loss)\n",
    "        return (loss, logits_list) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "import funcy as fc\n",
    "import warnings\n",
    "from frozendict import frozendict as fdict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TokenClassification:\n",
    "    task_type = \"TokenClassification\"\n",
    "    name: str = \"TokenClassificationTask\"\n",
    "    dataset: Dataset = None\n",
    "    metric:... = evaluate.load(\"seqeval\")\n",
    "    main_split: str = \"train\"\n",
    "    tokens: str = 'tokens'\n",
    "    y: str|list = 'target'\n",
    "    num_labels: int = None\n",
    "    label_names: dict = None\n",
    "    tokenizer_kwargs: fdict = fdict(padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _align_labels_with_tokens(labels, word_ids):\n",
    "        new_labels = []\n",
    "        current_word = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                new_labels.append(-100)\n",
    "\n",
    "            elif word_id != current_word:\n",
    "                current_word = word_id\n",
    "                label = -100 if word_id is None else labels[word_id]\n",
    "                new_labels.append(label)\n",
    "            \n",
    "            else:\n",
    "                label = labels[word_id]\n",
    "                new_labels.append(label)\n",
    "        \n",
    "        return new_labels\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.label_names = {}\n",
    "        self.num_labels  = {}\n",
    "\n",
    "        for y in self.y:\n",
    "            target = self.dataset[self.main_split].features[y]\n",
    "            self.num_labels[y] = target.feature.num_classes\n",
    "            self.label_names[y] = target.feature.names if target.feature.names else [None]\n",
    "        \n",
    "        print(f\"Task loaded {self.task_type} task with {self.num_labels} labels\")\n",
    "        for k,v in self.label_names.items():\n",
    "            print(f\"      {k} labels: {v}\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        return super().get_labels() or self.label_names\n",
    "\n",
    "    def set_tokenizer(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.add_prefix_space = True\n",
    "        self.data_collator = DataCollatorForTokenClassification(\n",
    "            tokenizer = self.tokenizer\n",
    "        )\n",
    "\n",
    "    def preprocess_function(self, examples):\n",
    "        if examples[self.tokens] and type(examples[self.tokens][0]) == str:\n",
    "            unsqueeze, examples = True, {k:[v] for k,v in examples.items()}\n",
    "        \n",
    "        def get_len(outputs):\n",
    "            try:\n",
    "                return len(outputs[fc.first(outputs)])\n",
    "            except:\n",
    "                return 1\n",
    "        \n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            examples[self.tokens],\n",
    "            is_split_into_words=True,\n",
    "            **self.tokenizer_kwargs\n",
    "        )\n",
    "\n",
    "        for target_column in self.y:\n",
    "            all_labels = examples[target_column]\n",
    "            new_labels = []\n",
    "            \n",
    "            for i, labels in enumerate(all_labels):\n",
    "                word_ids = tokenized_inputs.word_ids(i)\n",
    "                new_labels.append(self._align_labels_with_tokens(labels, word_ids))\n",
    "            \n",
    "            tokenized_inputs[target_column] = new_labels        \n",
    "            tokenized_inputs['task_ids'] = [self.index]*get_len(tokenized_inputs)\n",
    "\n",
    "        return tokenized_inputs       \n",
    "\n",
    "    def compute_metrics(self, eval_pred):\n",
    "        logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        \n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        true_labels = [\n",
    "            [self.label_names[l] for l in label if l != -100] for label in labels\n",
    "        ]\n",
    "        true_predictions = [\n",
    "            [self.label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        all_metrics = self.metric.compute(\n",
    "            predictions = true_predictions, \n",
    "            references = true_labels\n",
    "        )\n",
    "        meta = {\"name\": self.name, \"size\": len(predictions), \"index\": self.index}\n",
    "        metrics = {k.replace(\"overall_\",\"\"):v for k,v in all_metrics.items() if \"overall\" in k}\n",
    "        self.results+=[metrics]\n",
    "        return {**metrics, **meta}\n",
    "\n",
    "    def check(self):\n",
    "        features = self.dataset['train'].features\n",
    "        return self.tokens in features and self.y in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "from transformers.utils import PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "@dataclass\n",
    "class DataCollatorForTokenClassificationCustom:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    label_pad_token_id: int = -100\n",
    "    return_tensors: str = \"pt\"\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        if return_tensors is None:\n",
    "            return_tensors = self.return_tensors\n",
    "        if return_tensors == \"tf\":\n",
    "            return self.tf_call(features)\n",
    "        elif return_tensors == \"pt\":\n",
    "            return self.torch_call(features)\n",
    "        elif return_tensors == \"np\":\n",
    "            return self.numpy_call(features)\n",
    "        else:\n",
    "            raise ValueError(f\"Framework '{return_tensors}' not recognized!\")\n",
    "    \n",
    "    def torch_call(self, features):\n",
    "        import torch\n",
    "        targets = [{k: v for k, v in feature.items() if \"target\" in k} for feature in features]\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature[label_name] for feature in features] if label_name in features[0].keys() else None\n",
    "        print(\"==>\",targets)\n",
    "\n",
    "        no_labels_features = [{k: v for k, v in feature.items() if \"target\" not in k} for feature in features]\n",
    "        no_labels_features = [{k: v for k, v in feature.items() if \"tokens\" not in k} for feature in features]\n",
    "        print(\"==>\",no_labels_features)\n",
    "\n",
    "        # error here\n",
    "        # input_id\n",
    "        batch = self.tokenizer.pad(\n",
    "            no_labels_features,\n",
    "            padding = self.padding,\n",
    "            max_length = 8,\n",
    "            pad_to_multiple_of = self.pad_to_multiple_of,\n",
    "            return_tensors = \"pt\",\n",
    "        )\n",
    "        \n",
    "        if labels is None:\n",
    "            return batch\n",
    "\n",
    "        sequence_length = batch[\"input_ids\"].shape[1]\n",
    "        padding_side = self.tokenizer.padding_side\n",
    "\n",
    "        def to_list(tensor_or_iterable):\n",
    "            if isinstance(tensor_or_iterable, torch.Tensor):\n",
    "                return tensor_or_iterable.tolist()\n",
    "            return list(tensor_or_iterable)\n",
    "\n",
    "        if padding_side == \"right\":\n",
    "            batch[label_name] = [\n",
    "                to_list(label) + [self.label_pad_token_id] * (sequence_length - len(label)) for label in labels\n",
    "            ]\n",
    "        else:\n",
    "            batch[label_name] = [\n",
    "                [self.label_pad_token_id] * (sequence_length - len(label)) + to_list(label) for label in labels\n",
    "            ]\n",
    "\n",
    "        batch[label_name] = torch.tensor(batch[label_name], dtype=torch.int64)\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of labels target_1: n_commons: ['14', '2', '3', '4', '5']\n",
      "Sample of labels target_2: last_common: ['QP', 'S', 'SBAR', 'SBAR[+]S', 'SBAR[+]S[+]VP']\n",
      "Sample of labels target_3: unary_chain: ['VP', 'WHADVP', 'WHNP']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0e3e3d3fa948a38981ec82a42a35bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1cbd09182240339b92f96fce184797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e3c54852b24887aa89bb0f8f75ec3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a90b5131cd44fd099311beb4cafbe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1efdba5a54c445c9cb0d4bb7f39b375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db708c750c24c0c8c316e476cea49f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Sample encoded sentence\n",
      "    ['In', 'an', 'Oct.', '19', 'review', 'of', '``', 'The', 'Misanthrope', \"''\", 'at', 'Chicago', \"'s\", 'Goodman', 'Theatre', '-LRB-', '``', 'Revitalized', 'Classics', 'Take', 'the', 'Stage', 'in', 'Windy', 'City', ',', \"''\", 'Leisure', '&', 'Arts', '-RRB-', ',', 'the', 'role', 'of', 'Celimene', ',', 'played', 'by', 'Kim', 'Cattrall', ',', 'was', 'mistakenly', 'attributed', 'to', 'Christina', 'Haag', '.']\n",
      "    ['2', '4', '4', '4', '3', '4', '5', '6', '5', '5', '6', '8', '7', '7', '3', '4', '4', '6', '5', '6', '7', '6', '7', '8', '4', '4', '4', '5', '5', '4', '1', '1', '4', '3', '4', '2', '2', '3', '4', '5', '2', '1', '2', '3', '3', '4', '5', '1', '1']\n",
      "    ['PP', 'NP', 'NP', 'NP', 'NP', 'PP', 'NP', 'NP', 'NP', 'NP', 'PP', 'NP', 'NP', 'NP', 'NP', 'PRN', 'PRN', 'NP', 'S', 'VP', 'NP', 'VP', 'PP', 'NP', 'PRN', 'PRN', 'PRN', 'NP', 'NP', 'PRN', 'S', 'S', 'NP', 'NP', 'PP', 'NP', 'NP', 'VP', 'PP', 'NP', 'NP', 'S', 'VP', 'VP', 'VP', 'PP', 'NP', 'S', 'S']\n",
      "    ['-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', 'NP', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', 'ADVP', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-']\n",
      "Task loaded TokenClassification task with {'target_1': 14, 'target_2': 15, 'target_3': 8} labels\n",
      "      target_1 labels: ['1', '10', '11', '12', '13', '14', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "      target_2 labels: ['ADJP', 'NP', 'NP[+]QP', 'PP', 'PRN', 'QP', 'S', 'SBAR', 'SBAR[+]S', 'SBAR[+]S[+]VP', 'SINV', 'S[+]VP', 'UCP', 'VP', 'WHNP']\n",
      "      target_3 labels: ['-NONE-', 'ADJP', 'ADVP', 'NP', 'PRT', 'VP', 'WHADVP', 'WHNP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRN] Creating output head for task naive_absolute_n_commons\n",
      "      - Task type: TokenClassification\n",
      "      - Number of labels: {'target_1': 14, 'target_2': 15, 'target_3': 8}\n",
      "      - Label names:\n",
      "            - target_1 : ['1', '10', '11', '12', '13', '14', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "            - target_2 : ['ADJP', 'NP', 'NP[+]QP', 'PP', 'PRN', 'QP', 'S', 'SBAR', 'SBAR[+]S', 'SBAR[+]S[+]VP', 'SINV', 'S[+]VP', 'UCP', 'VP', 'WHNP']\n",
      "            - target_3 : ['-NONE-', 'ADJP', 'ADVP', 'NP', 'PRT', 'VP', 'WHADVP', 'WHNP']\n",
      "[TRN] Example input:\n",
      "      - tokens : ['In', 'an', 'Oct.', '19', 'review', 'of', '``', 'The', 'Misanthrope', \"''\", 'at', 'Chicago', \"'s\", 'Goodman', 'Theatre', '-LRB-', '``', 'Revitalized', 'Classics', 'Take', 'the', 'Stage', 'in', 'Windy', 'City', ',', \"''\", 'Leisure', '&', 'Arts', '-RRB-', ',', 'the', 'role', 'of', 'Celimene', ',', 'played', 'by', 'Kim', 'Cattrall', ',', 'was', 'mistakenly', 'attributed', 'to', 'Christina', 'Haag', '.']\n",
      "      - target_1 : [6, 8, 8, 8, 7, 8, 9, 10, 9, 9, 10, 12, 11, 11, 7, 8, 8, 10, 9, 10, 11, 10, 11, 12, 8, 8, 8, 9, 9, 8, 0, 0, 8, 7, 8, 6, 6, 7, 8, 9, 6, 0, 6, 7, 7, 8, 9, 0, 0]\n",
      "      - target_2 : [3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 4, 4, 1, 6, 13, 1, 13, 3, 1, 4, 4, 4, 1, 1, 4, 6, 6, 1, 1, 3, 1, 1, 13, 3, 1, 1, 6, 13, 13, 13, 3, 1, 6, 6]\n",
      "      - target_3 : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[TRN] Example input (real labels):\n",
      "      - ['2', '4', '4', '4', '3', '4', '5', '6', '5', '5', '6', '8', '7', '7', '3', '4', '4', '6', '5', '6', '7', '6', '7', '8', '4', '4', '4', '5', '5', '4', '1', '1', '4', '3', '4', '2', '2', '3', '4', '5', '2', '1', '2', '3', '3', '4', '5', '1', '1']\n",
      "      - ['PP', 'NP', 'NP', 'NP', 'NP', 'PP', 'NP', 'NP', 'NP', 'NP', 'PP', 'NP', 'NP', 'NP', 'NP', 'PRN', 'PRN', 'NP', 'S', 'VP', 'NP', 'VP', 'PP', 'NP', 'PRN', 'PRN', 'PRN', 'NP', 'NP', 'PRN', 'S', 'S', 'NP', 'NP', 'PP', 'NP', 'NP', 'VP', 'PP', 'NP', 'NP', 'S', 'VP', 'VP', 'VP', 'PP', 'NP', 'S', 'S']\n",
      "      - ['-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', 'NP', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', 'ADVP', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-']\n",
      "Creating TokenClassification head w/ 14 labels\n",
      "Creating TokenClassification head w/ 15 labels\n",
      "Creating TokenClassification head w/ 8 labels\n",
      "Model is preprocessing task naive_absolute_n_commons\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5638fed66644e498b99d5e212e8c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc0f6d04fb04a7aa05220acfd756456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished preprocessing task naive_absolute_n_commons\n",
      "[TRN] Model has 3 output heads\n",
      "[TRN] Model has 1 training datasets\n",
      "[TRN] Model has 1 evaluation datasets\n",
      "[*] Init multitask trainer with tasks: {'naive_absolute_n_commons': {'train': Dataset({\n",
      "    features: ['tokens', 'target_1', 'target_2', 'target_3', 'input_ids', 'token_type_ids', 'attention_mask', 'task_ids'],\n",
      "    num_rows: 10\n",
      "}), 'validation': Dataset({\n",
      "    features: ['tokens', 'target_1', 'target_2', 'target_3', 'input_ids', 'token_type_ids', 'attention_mask', 'task_ids'],\n",
      "    num_rows: 10\n",
      "})}}\n",
      "[*] Label names are: {'naive_absolute_n_commons': {'target_1': ['1', '10', '11', '12', '13', '14', '2', '3', '4', '5', '6', '7', '8', '9'], 'target_2': ['ADJP', 'NP', 'NP[+]QP', 'PP', 'PRN', 'QP', 'S', 'SBAR', 'SBAR[+]S', 'SBAR[+]S[+]VP', 'SINV', 'S[+]VP', 'UCP', 'VP', 'WHNP'], 'target_3': ['-NONE-', 'ADJP', 'ADVP', 'NP', 'PRT', 'VP', 'WHADVP', 'WHNP']}}\n",
      "<class 'dict'>\n",
      "dict_items([('naive_absolute_n_commons', Dataset({\n",
      "    features: ['tokens', 'target_1', 'target_2', 'target_3', 'input_ids', 'token_type_ids', 'attention_mask', 'task_ids'],\n",
      "    num_rows: 10\n",
      "}))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b706f424b44f23858f15b44b0e0453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 64\u001b[0m\n\u001b[1;32m     53\u001b[0m train_dataset \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain_dataset\n\u001b[1;32m     54\u001b[0m trainer \u001b[39m=\u001b[39m MultiTaskTrainer(\n\u001b[1;32m     55\u001b[0m     model \u001b[39m=\u001b[39m model,\n\u001b[1;32m     56\u001b[0m     tasks \u001b[39m=\u001b[39m tasks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     tokenizer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtokenizer\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 64\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.10/site-packages/transformers/trainer.py:1660\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1657\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1658\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1659\u001b[0m )\n\u001b[0;32m-> 1660\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1661\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1662\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1663\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1664\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1665\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.10/site-packages/transformers/trainer.py:1895\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1892\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1894\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 1895\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1896\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1897\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "Cell \u001b[0;32mIn[3], line 85\u001b[0m, in \u001b[0;36mMultitaskDataloader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m task_choice \u001b[39min\u001b[39;00m task_choice_list:\n\u001b[1;32m     84\u001b[0m     task_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_name_list[task_choice]\n\u001b[0;32m---> 85\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mnext\u001b[39;49m(dataloader_iter_dict[task_name])\n",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m, in \u001b[0;36mDataLoaderWithTaskname.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_loader:\n\u001b[1;32m     27\u001b[0m         \u001b[39myield\u001b[39;00m batch\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:62\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m, in \u001b[0;36mNLPDataCollator.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[Union[InputDataClass, Dict]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNLPDATACOLLATOR Features:\u001b[39m\u001b[39m\"\u001b[39m,features\u001b[39m.\u001b[39;49mkeys())\n\u001b[1;32m     34\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m         task_index \u001b[39m=\u001b[39m features[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mflatten()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mitem()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# import trainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# train and evaluate using Evalb\n",
    "encodings = gen_dsets()\n",
    "results = {}\n",
    "train_limit = 10\n",
    "max_seq_len = 128\n",
    "model_name = \"bert-base-cased\"\n",
    "\n",
    "# probably this could be done in parallel\n",
    "for enc in encodings[:1]:\n",
    "    results_df = pd.DataFrame(columns=[\"encoding\", \"recall\", \"precision\", \"f1\", \"n_labels\"])\n",
    "    encoder = enc[\"encoder\"]\n",
    "    \n",
    "    train_enc, mlt1 = encode_dset(encoder, ptb_train[:train_limit] if train_limit else ptb_train)\n",
    "    dev_enc,   mlt2   = encode_dset(encoder, ptb_dev[:train_limit]   if train_limit else ptb_dev)\n",
    "    dataset  = generate_dataset_from_codelin(train_enc, dev_enc)\n",
    "    \n",
    "    print(\"[*] Sample encoded sentence\")\n",
    "    print(\"   \",train_enc['tokens'][0])\n",
    "    print(\"   \",train_enc['target_1'][0])\n",
    "    print(\"   \",train_enc['target_2'][0])\n",
    "    print(\"   \",train_enc['target_3'][0])\n",
    "\n",
    "    tasks = [TokenClassification(\n",
    "                dataset = dataset,\n",
    "                y = [\"target_1\", \"target_2\", \"target_3\"],\n",
    "                name = enc[\"name\"]+\"_n_commons\",\n",
    "                tokenizer_kwargs = frozendict(padding=\"max_length\", max_length = max_seq_len, truncation=True)\n",
    "            )]\n",
    "    \n",
    "    model = MultiTaskModel(model_name, tasks)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = f\"results/{enc['name']}\",\n",
    "        num_train_epochs = 1,\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 8,\n",
    "        warmup_steps = 500,\n",
    "        weight_decay = 0.01,\n",
    "        logging_dir = f\"results/{enc['name']}/logs\",\n",
    "        logging_steps = 10,\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        save_strategy = \"epoch\",\n",
    "        load_best_model_at_end = True,\n",
    "        metric_for_best_model = \"f1\",\n",
    "        greater_is_better = True,\n",
    "        save_total_limit = 1,\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    "\n",
    "    train_dataset = model.train_dataset\n",
    "    trainer = MultiTaskTrainer(\n",
    "        model = model,\n",
    "        tasks = tasks,\n",
    "        args = training_args,\n",
    "        train_dataset = model.train_dataset,\n",
    "        eval_dataset = model.eval_dataset,\n",
    "        compute_metrics = None,\n",
    "        tokenizer = model.tokenizer\n",
    "    )\n",
    "    \n",
    "    trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f6a80f18e31b3afbf65f4c0ba16ab618b75d927e0f96f1f2ebf3c840526a5fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
