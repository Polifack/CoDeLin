{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Sequence\n",
    "from datasets import ClassLabel\n",
    "\n",
    "from PYEVALB.scorer import Scorer\n",
    "from PYEVALB.summary import summary\n",
    "\n",
    "from codelin.models.const_tree import C_Tree\n",
    "from codelin.models.const_label import C_Label\n",
    "from codelin.models.linearized_tree import LinearizedTree\n",
    "from codelin.encs.constituent import *\n",
    "from codelin.utils.constants import *\n",
    "\n",
    "from frozendict import frozendict\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Set logging level\n",
    "'''\n",
    "Train the models in multi-task learning fashion. To do this\n",
    "we will split the fields of the label and train different\n",
    "tasks according to this. After training, we will evaluate\n",
    "the decoded trees by re-joining the labels.\n",
    "'''\n",
    "\n",
    "ptb_path = \"~/Treebanks/const/PENN_TREEBANK/\"\n",
    "ptb_path = os.path.expanduser(ptb_path)\n",
    "\n",
    "with open(os.path.join(ptb_path,\"test.trees\")) as f:\n",
    "    ptb_test = [l.rstrip() for l in f.read().splitlines()]\n",
    "with open(os.path.join(ptb_path,\"dev.trees\")) as f:\n",
    "    ptb_dev = [l.rstrip() for l in f.read().splitlines()]\n",
    "with open(os.path.join(ptb_path,\"train.trees\")) as f:\n",
    "    ptb_train = [l.rstrip() for l in f.read().splitlines()]\n",
    "\n",
    "def get_n_labels(dsets, tar_field):\n",
    "    label_set = set()\n",
    "    for dset in dsets:\n",
    "        for labels in dset[tar_field]:\n",
    "            label_set.update(labels)\n",
    "    label_names = sorted(list(label_set))\n",
    "    return label_names, len(label_names)\n",
    "\n",
    "def generate_dataset_from_codelin(train_dset, dev_dset, test_dset=None):\n",
    "    dsets = [train_dset, dev_dset, test_dset] if test_dset else [train_dset, dev_dset]\n",
    "    \n",
    "    l1, nl1 = get_n_labels(dsets, \"target_1\")\n",
    "    l2, nl2 = get_n_labels(dsets, \"target_2\")\n",
    "    l3, nl3 = get_n_labels(dsets, \"target_3\")\n",
    "\n",
    "    train_dset = datasets.Dataset.from_dict(train_dset)\n",
    "    train_dset = train_dset.cast_column(\"target_1\", Sequence(ClassLabel(num_classes=nl1, names=l1)))\n",
    "    train_dset = train_dset.cast_column(\"target_2\", Sequence(ClassLabel(num_classes=nl2, names=l2)))\n",
    "    train_dset = train_dset.cast_column(\"target_3\", Sequence(ClassLabel(num_classes=nl3, names=l3)))\n",
    "\n",
    "    dev_dset = datasets.Dataset.from_dict(dev_dset)\n",
    "    dev_dset = dev_dset.cast_column(\"target_1\", Sequence(ClassLabel(num_classes=nl1, names=l1)))\n",
    "    dev_dset = dev_dset.cast_column(\"target_2\", Sequence(ClassLabel(num_classes=nl2, names=l2)))\n",
    "    dev_dset = dev_dset.cast_column(\"target_3\", Sequence(ClassLabel(num_classes=nl3, names=l3)))\n",
    "\n",
    "    if test_dset:\n",
    "        test_dset = datasets.Dataset.from_dict(test_dset)\n",
    "        test_dset = test_dset.cast_column(\"target_1\", Sequence(ClassLabel(num_classes=nl1, names=l1)))\n",
    "        test_dset = test_dset.cast_column(\"target_2\", Sequence(ClassLabel(num_classes=nl2, names=l2)))\n",
    "        test_dset = test_dset.cast_column(\"target_3\", Sequence(ClassLabel(num_classes=nl3, names=l3)))\n",
    "    \n",
    "        # Convert to Hugging Face DatasetDict format\n",
    "        dataset = datasets.DatasetDict({\n",
    "                \"train\": train_dset,\n",
    "                \"validation\": dev_dset,\n",
    "                \"test\": test_dset\n",
    "            })\n",
    "    else:\n",
    "        # Convert to Hugging Face DatasetDict format\n",
    "        dataset = datasets.DatasetDict({\n",
    "                \"train\": train_dset,\n",
    "                \"validation\": dev_dset\n",
    "            })\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def encode_dset(encoder, dset):\n",
    "    encoded_trees = {\"tokens\":[], \"target_1\":[], \"target_2\":[], \"target_3\":[]}\n",
    "    max_len_tree = 0\n",
    "    for line in dset:\n",
    "        tree = C_Tree.from_string(line)\n",
    "        lin_tree = encoder.encode(tree)\n",
    "        encoded_trees[\"tokens\"].append([w for w in lin_tree.words])\n",
    "        \n",
    "        t1,t2,t3 = [],[],[]\n",
    "        for s1,s2,s3 in lin_tree.get_labels_splitted():\n",
    "            t1.append(s1)    \n",
    "            t2.append(s2)\n",
    "            t3.append(s3)\n",
    "            \n",
    "        encoded_trees[\"target_1\"].append(t1)\n",
    "        encoded_trees[\"target_2\"].append(t2)\n",
    "        encoded_trees[\"target_3\"].append(t3)\n",
    "        \n",
    "        max_len_tree = max(max_len_tree, len(lin_tree.words))\n",
    "    \n",
    "    \n",
    "    return encoded_trees, max_len_tree\n",
    "\n",
    "def gen_dsets():\n",
    "    encodings = []\n",
    "\n",
    "    # naive absolute encodings\n",
    "    a_enc     = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute\", \"encoder\":a_enc})\n",
    "    a_br_enc  = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_br\", \"encoder\":a_br_enc})\n",
    "    a_bl_enc  = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_bl\", \"encoder\":a_bl_enc})\n",
    "    ar_enc    = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_r\", \"encoder\":ar_enc})\n",
    "    ar_br_enc = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_r_br\", \"encoder\":ar_br_enc})\n",
    "    ar_bl_enc = C_NaiveAbsoluteEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_absolute_r_bl\", \"encoder\":ar_bl_enc})\n",
    "\n",
    "    # naive relative encodings\n",
    "    r_enc     = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative\", \"encoder\":r_enc})\n",
    "    r_br_enc  = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_br\", \"encoder\":r_br_enc})\n",
    "    r_bl_enc  = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_bl\", \"encoder\":r_bl_enc})\n",
    "    rr_enc    = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_r\", \"encoder\":rr_enc})\n",
    "    rr_br_enc = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_r_br\", \"encoder\":rr_br_enc})\n",
    "    rr_bl_enc = C_NaiveRelativeEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_relative_r_bl\", \"encoder\":rr_bl_enc})\n",
    "\n",
    "    # naive dynamic encodings\n",
    "    d_enc     = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic\", \"encoder\":d_enc})\n",
    "    d_br_enc  = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_br\", \"encoder\":d_br_enc})\n",
    "    d_bl_enc  = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=False, binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_bl\", \"encoder\":d_bl_enc})\n",
    "    dr_enc    = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_r\", \"encoder\":dr_enc})\n",
    "    dr_br_enc = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"R\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_r_br\", \"encoder\":dr_br_enc})\n",
    "    dr_bl_enc = C_NaiveDynamicEncoding(separator=\"[_]\", unary_joiner=\"[+]\", reverse=True,  binary=True,  binary_direction=\"L\",  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"naive_dynamic_r_bl\", \"encoder\":dr_bl_enc})\n",
    "\n",
    "    # gaps encodings\n",
    "    g_r_enc   = C_GapsEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary_direction=\"R\", binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"gaps_r\", \"encoder\":g_r_enc})\n",
    "    g_l_enc   = C_GapsEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary_direction=\"L\", binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"gaps_l\", \"encoder\":g_l_enc})\n",
    "\n",
    "    # tetra encodings\n",
    "    t_pr_enc  = C_Tetratag(separator=\"[_]\", unary_joiner=\"[+]\", mode='preorder',  binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"tetratag_preorder\", \"encoder\":t_pr_enc})\n",
    "    t_in_enc  = C_Tetratag(separator=\"[_]\", unary_joiner=\"[+]\", mode='inorder',   binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"tetratag_inorder\", \"encoder\":t_in_enc})\n",
    "    t_po_enc  = C_Tetratag(separator=\"[_]\", unary_joiner=\"[+]\", mode='postorder', binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"tetratag_postorder\", \"encoder\":t_po_enc})\n",
    "\n",
    "    # yuxtaposed encodings\n",
    "    j_enc   = C_JuxtaposedEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary=False, binary_direction=None, binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"juxtaposed\", \"encoder\":j_enc})\n",
    "    j_r_enc = C_JuxtaposedEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary=True, binary_direction='R',   binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"juxtaposed_r\", \"encoder\":j_r_enc})\n",
    "    j_l_enc = C_JuxtaposedEncoding(separator=\"[_]\", unary_joiner=\"[+]\", binary=True, binary_direction='L',   binary_marker=\"[b]\")\n",
    "    encodings.append({\"name\":\"juxtaposed_l\", \"encoder\":j_l_enc})\n",
    "\n",
    "    return encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TokenClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        self.classifier.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        if self.classifier.bias is not None:\n",
    "            self.classifier.bias.data.zero_()\n",
    "\n",
    "    def forward(self, sequence_output, pooled_output, labels = None, attention_mask = None, **kwargs):\n",
    "        sequence_output_dropout = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output_dropout)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            labels = labels.long()\n",
    "\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask is not None:\n",
    "                active_loss = attention_mask.view(-1) == 1\n",
    "                active_logits = logits.view(-1, self.num_labels)\n",
    "                active_labels = torch.where(\n",
    "                    active_loss,\n",
    "                    labels.view(-1),\n",
    "                    torch.tensor(loss_fct.ignore_index).type_as(labels),\n",
    "                )\n",
    "                loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are processing is composed of \n",
    "- Task: Each of the datasets that we are employing \n",
    "- Subtasks: Each of the labels we are predicting for each word in the task dataset\n",
    "\n",
    "For example:\n",
    "\n",
    "- Task-1: The, dog, is, brown\n",
    "    - Subtask-1: DT, NOUN, VERB, ADJ\n",
    "    - Subtask-2: 1_NP, 2_VP, 1_ADJ, 1_NP\n",
    "    - Subtask-3: <_det, <//_root, >_whatever, //_mod\n",
    "<br><br>\n",
    "\n",
    "- Task-2: El, perro, es, marron\n",
    "    - Subtask-1: DT, NOUN, VERB, ADJ\n",
    "    - Subtask-2: 1_NP, 2_VP, 1_ADJ, 1_NP\n",
    "\n",
    "An example of this would be:\n",
    "\n",
    "```\n",
    "{\n",
    "    'naive_absolute_ptb': \n",
    "    {\n",
    "            'train': \n",
    "                    Dataset({\n",
    "                        features: ['tokens', 'target_1', 'target_2', 'input_ids', 'token_type_ids', 'attention_mask', 'task_ids'],\n",
    "                        num_rows: 256\n",
    "                    }), \n",
    "            'validation': \n",
    "                    Dataset({\n",
    "                        features: ['tokens', 'target_1', 'target_2', 'target_3', 'input_ids', 'token_type_ids', 'attention_mask', 'task_ids'],\n",
    "                        num_rows: 256\n",
    "                    })\n",
    "    },\n",
    "    'naive_absolute_en_ewt': \n",
    "    {\n",
    "            'train': \n",
    "                    Dataset({\n",
    "                        features: ['tokens', 'target_1', 'target_2', 'input_ids', 'token_type_ids', 'attention_mask', 'task_ids'],\n",
    "                        num_rows: 256\n",
    "                    }), \n",
    "            'validation': \n",
    "                    Dataset({\n",
    "                        features: ['tokens', 'target_1', 'target_2', 'input_ids', 'token_type_ids', 'attention_mask', 'task_ids'],\n",
    "                        num_rows: 256\n",
    "                    })\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Where we are training the fields of ```head_pos``` (taget_1) and ```dep_rel``` (target_2) for dependency parsing casted as sequence labeling for two different datasets (penn treebank and english web treebank). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import EvalPrediction\n",
    "from torch import nn\n",
    "from torch.utils.data.sampler import RandomSampler, WeightedRandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from transformers.data.data_collator import InputDataClass\n",
    "from types import MappingProxyType\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import transformers\n",
    "from transformers.trainer_utils import EvalLoopOutput\n",
    "\n",
    "class DataLoaderWithTaskname:\n",
    "    def __init__(self, task_name, data_loader):\n",
    "        self.task = task_name\n",
    "        self.data_loader = data_loader\n",
    "        self.batch_size = data_loader.batch_size\n",
    "        self.dataset = data_loader.dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.data_loader:\n",
    "            yield batch\n",
    "\n",
    "class NLPDataCollator:\n",
    "    def __init__(self, tasks):\n",
    "        self.tasks = tasks\n",
    "\n",
    "    def __call__(self, features: List[Union[InputDataClass, Dict]]) -> Dict[str, torch.Tensor]:\n",
    "        features = [{k:v for k,v in x.items() if k!='task_ids'} for x in features]\n",
    "        return features\n",
    "    \n",
    "class MultitaskDataloader:\n",
    "    \"\"\"\n",
    "    Data loader that combines and samples from multiple single-task\n",
    "    data loaders.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataloader_dict, p=1):\n",
    "        self.dataloader_dict = dataloader_dict\n",
    "        N = max([len(x)**(1-p) for x in dataloader_dict.values()])\n",
    "        \n",
    "        f_p = lambda x: int(N*x**p)\n",
    "\n",
    "        self.num_batches_dict = {\n",
    "            task_name: f_p(len(dataloader))\n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "        self.task_name_list = list(self.dataloader_dict)\n",
    "        self.dataset = [None] * sum(\n",
    "            f_p(len(dataloader.dataset)) for dataloader in self.dataloader_dict.values()\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.num_batches_dict.values())\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        For each batch, sample a task, and yield a batch from the respective\n",
    "        task Dataloader.\n",
    "        \"\"\"\n",
    "        task_choice_list = []\n",
    "        for i, task_name in enumerate(self.task_name_list):\n",
    "            task_choice_list += [i] * self.num_batches_dict[task_name]\n",
    "        task_choice_list = np.array(task_choice_list)\n",
    "        np.random.shuffle(task_choice_list)\n",
    "        \n",
    "        dataloader_iter_dict = {\n",
    "            task_name: iter(dataloader)\n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "\n",
    "        for task_choice in task_choice_list:\n",
    "            task_name = self.task_name_list[task_choice]\n",
    "            yield next(dataloader_iter_dict[task_name])\n",
    "\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, encoder_name_or_path, tasks):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name_or_path)\n",
    "        tokenizer_kwargs = frozendict(padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(encoder_name_or_path, **tokenizer_kwargs)\n",
    "        self.output_heads = nn.ModuleDict()\n",
    "        \n",
    "        for task in tasks:\n",
    "            ###############################\n",
    "            print(\"[*] Creating output head for task\", task.name)\n",
    "            print(\"      - Task type:\", task.task_type)\n",
    "            print(\"      - Number of labels:\", task.num_labels)\n",
    "            print(\"      - Label names:\")\n",
    "            for k, v in task.label_names.items():\n",
    "                print(\"            -\", k, \":\", v)            \n",
    "            print(\"[*] Example input:\")\n",
    "            sample = task.dataset['train'][0]\n",
    "            for k, v in sample.items():\n",
    "                print(\"      -\", k, \":\", v)\n",
    "            print(\"[*] Example input (real labels):\")\n",
    "            sample = task.dataset['train'][0]\n",
    "            for k, v in sample.items():\n",
    "                if k in task.label_names.keys():\n",
    "                    print(\"      -\", [task.label_names[k][vi] for vi in v])\n",
    "            ###############################\n",
    "            \n",
    "            task.set_tokenizer(self.tokenizer)\n",
    "            for subtask in task.y:\n",
    "                decoder = self._create_output_head(\n",
    "                    self.encoder.config.hidden_size, \n",
    "                    task.task_type, \n",
    "                    task.num_labels[subtask]\n",
    "                )\n",
    "                \n",
    "                self.output_heads[subtask] = decoder\n",
    "\n",
    "        self.processed_tasks = self.preprocess_tasks(tasks, self.tokenizer)\n",
    "        self.label_names = {task.name: task.label_names for task in tasks}\n",
    "        self.train_dataset = {self.processed_tasks[task.name]['train'] for task in tasks}\n",
    "        self.eval_dataset = {self.processed_tasks[task.name]['validation'] for task in tasks}\n",
    "        \n",
    "        print(\"[*] Model has\", len(self.output_heads), \"output heads\")\n",
    "        print(\"[*] Model has\", len(self.train_dataset), \"training datasets\")\n",
    "        print(\"[*] Model has\", len(self.eval_dataset), \"evaluation datasets\")\n",
    "    \n",
    "    def preprocess_tasks(self, tasks, tokenizer):      \n",
    "        features_dict = {}\n",
    "        for i, task in enumerate(tasks):\n",
    "            print(\"[*] Model preprocessing task\", task.name)\n",
    "            \n",
    "            if hasattr(task, 'processed_features') and tokenizer == task.tokenizer:\n",
    "                features_dict[task.name] = task.processed_features\n",
    "                continue\n",
    "            \n",
    "            for split in task.dataset:\n",
    "                task.index = task.dataset[split].index = i\n",
    "            \n",
    "            features_dict[task.name] = {}\n",
    "            for phase, phase_dataset in task.dataset.items():\n",
    "                phase_dataset.index = i\n",
    "\n",
    "                features_dict[task.name][phase] = phase_dataset.map(\n",
    "                    task.preprocess_function, \n",
    "                    batched = True,\n",
    "                    batch_size = 8,\n",
    "                    load_from_cache_file = True\n",
    "                )\n",
    "        return features_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_output_head(encoder_hidden_size: int, task_type, n_labels):\n",
    "        if task_type == \"TokenClassification\":\n",
    "            print(\"[*] Creating TokenClassification head with\", n_labels, \"labels\")\n",
    "            return TokenClassificationHead(encoder_hidden_size, n_labels)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    \n",
    "    # def forward(self, input_ids = None, attention_mask = None, token_type_ids = None, position_ids = None,\n",
    "    #         head_mask = None, inputs_embeds = None, labels = None, task_ids = None, **kwargs):\n",
    "            \n",
    "    #         # compute the transformer output\n",
    "    #         outputs = self.encoder(\n",
    "    #             input_ids=input_ids,\n",
    "    #             attention_mask=attention_mask,\n",
    "    #             token_type_ids=token_type_ids,\n",
    "    #             position_ids=position_ids,\n",
    "    #             head_mask=head_mask,\n",
    "    #             inputs_embeds=inputs_embeds,\n",
    "    #         )\n",
    "    #         sequence_output, pooled_output = outputs[:2]\n",
    "\n",
    "    #         print(\"3) Transformer has been forwarded\")\n",
    "    #         unique_task_ids_list = torch.unique(task_ids).tolist()\n",
    "\n",
    "    #         loss_list = []\n",
    "    #         logits = None\n",
    "    #         # print(\"Computing loss...\")\n",
    "    #         # print(\"task_ids\", task_ids)\n",
    "    #         print(\"==> I have to compute loss for the following tasks:\")\n",
    "    #         print(\"==>\", unique_task_ids_list)\n",
    "    #         for unique_task_id in unique_task_ids_list:\n",
    "    #             print(\"Task_id =\",unique_task_id)\n",
    "    #             ptc_train = self.processed_tasks['train']\n",
    "    #             target_cols = [col for col in ptc_train.features if col.startswith(\"target_\")]\n",
    "    #             print(\"target_cols =\", target_cols)\n",
    "\n",
    "    #             for tc in target_cols:\n",
    "    #                 print(\"Target Column =\",tc)\n",
    "    #                 print(\"Labels =\",labels)\n",
    "    #                 logits, task_loss = self.output_heads[str(unique_task_id)].forward(\n",
    "    #                     sequence_output[task_id_filter],\n",
    "    #                     pooled_output[task_id_filter],\n",
    "    #                     labels = None if labels is None else labels[task_id_filter],\n",
    "    #                     attention_mask=attention_mask[task_id_filter],\n",
    "    #                 )\n",
    "\n",
    "    #                 if labels is not None:\n",
    "    #                     loss_list.append(task_loss)\n",
    "\n",
    "    #         # Loss averaged over all tasks\n",
    "    #         outputs = (logits, outputs[2:])\n",
    "    #         if loss_list:\n",
    "    #             loss = torch.stack(loss_list)\n",
    "    #             outputs = (loss.mean(),) + outputs\n",
    "\n",
    "    #         return outputs\n",
    "\n",
    "class MultiTaskTrainer(transformers.Trainer):\n",
    "    def __init__(self, tasks, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.p = 1\n",
    "        self.processed_tasks = self.model.processed_tasks\n",
    "        self.label_names = self.model.label_names\n",
    "        self.train_dataset = {\n",
    "            task: dataset[\"train\"]\n",
    "            for task, dataset in self.processed_tasks.items()\n",
    "        }\n",
    "        self.eval_dataset = {\n",
    "            task: dataset[\"validation\"]\n",
    "            for task, dataset in self.processed_tasks.items()\n",
    "        }\n",
    "        self.eval_dataset = MappingProxyType(self.eval_dataset)\n",
    "        self.tokenizer = self.model.tokenizer\n",
    "        self.pretrained_transformer = self.model.encoder\n",
    "        self.device = self.pretrained_transformer.device\n",
    "        self.data_collator = NLPDataCollator(tasks)\n",
    "        \n",
    "        print(\"[*] Init multitask trainer with tasks:\", self.processed_tasks)\n",
    "        print(\"[*] Label names are:\", self.label_names)\n",
    "        \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=[]):\n",
    "        if ignore_keys is None:\n",
    "            ignore_keys = []\n",
    "\n",
    "        # loss function returns the loss and the prediction logits\n",
    "        loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n",
    "        loss = loss.mean().detach()        \n",
    "        \n",
    "        print(\"[*] Prediction Step\")        \n",
    "        \n",
    "        logits_dict = {}\n",
    "        labels_dict = {}\n",
    "        for task_name, label_names in self.label_names.items():\n",
    "            logits_dict[task_name] = {}\n",
    "            labels_dict[task_name] = {}\n",
    "            for label_name in label_names:\n",
    "                logits_dict[task_name][label_name] = outputs[label_name]\n",
    "                logits_dict[task_name][label_name] = np.argmax(outputs[label_name].detach().cpu().numpy(), axis=2)\n",
    "                target_labels = []\n",
    "                for i in inputs:\n",
    "                    target_labels.append(i[label_name])\n",
    "                labels_dict[task_name][label_name] = torch.tensor(target_labels)\n",
    "        \n",
    "        return (loss, logits_dict, labels_dict)\n",
    "    \n",
    "    def get_single_train_dataloader(self, task_name, train_dataset):\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "        \n",
    "        train_sampler = (SequentialSampler(train_dataset) if self.args.local_rank == -1 else DistributedSampler(train_dataset))\n",
    "\n",
    "        data_loader = DataLoaderWithTaskname(\n",
    "            task_name = task_name,\n",
    "            data_loader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size = self.args.train_batch_size,\n",
    "                shuffle = False,\n",
    "                sampler = train_sampler,\n",
    "                collate_fn = self.data_collator.__call__,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        return MultitaskDataloader(\n",
    "            {\n",
    "                task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
    "                for task_name, task_dataset in self.train_dataset.items()\n",
    "            }, p = self.p,\n",
    "        )\n",
    "    \n",
    "    def get_eval_dataloader(self, eval_dataset=None):\n",
    "        return MultitaskDataloader(\n",
    "            {\n",
    "                task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
    "                for task_name, task_dataset in (\n",
    "                    eval_dataset if eval_dataset else self.eval_dataset\n",
    "                ).items()\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def evaluation_loop(self, dataloader: DataLoader, description: str, \n",
    "                        prediction_loss_only: bool | None = None, ignore_keys: List[str] | None = None, \n",
    "                        metric_key_prefix: str = \"eval_\") -> EvalLoopOutput:\n",
    "        \n",
    "        print(\"[*] Evaluation_loop\")        \n",
    "        model = self._wrap_model(self.model, training=False, dataloader=dataloader)\n",
    "\n",
    "        for step, inputs in enumerate(dataloader):\n",
    "            print(\"[*] Step\", step, \"of\", len(dataloader), \"...\")\n",
    "            \n",
    "            loss, preds, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n",
    "            print(\"[*] Loss:\", loss)\n",
    "            \n",
    "            for task, label_names in self.label_names.items():\n",
    "                print(\"[*] Evaluating task:\",task)\n",
    "                preds_task = preds[task]\n",
    "                labels_task = labels[task]\n",
    "                \n",
    "                for label_name, labels_values in label_names.items():\n",
    "                    print(\"[*] Computing metrics for subtask\", label_name, \"...\")\n",
    "                    preds_tl  = preds_task[label_name]\n",
    "                    labels_tl = labels_task[label_name]\n",
    "                    \n",
    "                    eval_pred = EvalPrediction(\n",
    "                                predictions = preds_tl, \n",
    "                                label_ids   = labels_tl, \n",
    "                                inputs      = inputs)\n",
    "\n",
    "                    # compute metrics foreach head using the corresponding task eval_function\n",
    "                    # i copied the function from the task-specific class to this one\n",
    "                    metrics = self.compute_metrics_token_classification(eval_pred, label_name)\n",
    "                    metrics_eval = {}\n",
    "                    for metric in metrics.items():\n",
    "                        metrics_eval[metric_key_prefix + \"_\" + metric[0]] = metric[1]\n",
    "\n",
    "        return EvalLoopOutput(predictions=preds_tl, label_ids=labels_tl, metrics=metrics_eval, num_samples=len(self.eval_dataset))\n",
    "    \n",
    "    def compute_metrics_token_classification(self, eval_pred, label_names):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        \n",
    "        # for task in tasks\n",
    "        label_names_task = self.label_names['naive_absolute_n_commons']\n",
    "        true_labels = [\n",
    "            [label_names_task[label_names][int(l)] for l in label if l != -100] for label in labels\n",
    "        ]\n",
    "        \n",
    "        true_predictions = [\n",
    "            [label_names_task[label_names][p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        metric = evaluate.load(\"seqeval\")\n",
    "        all_metrics = metric.compute(\n",
    "            predictions = true_predictions, \n",
    "            references = true_labels\n",
    "        )\n",
    "        \n",
    "        meta = {\"name\": 'naive_absolute_n_commons', \"size\": len(predictions), \"index\": 0}\n",
    "        metrics = {k.replace(\"overall_\",\"\"):v for k,v in all_metrics.items() if \"overall\" in k}\n",
    "        \n",
    "        return {**metrics, **meta}      \n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        keys = inputs[0].keys()\n",
    "\n",
    "        input_ids = torch.tensor([i['input_ids'] for i in inputs], device=self.args.device) if 'input_ids' in keys else None\n",
    "        attention_mask = torch.tensor([i['attention_mask'] for i in inputs], device=self.args.device) if 'attention_mask' in keys else None        \n",
    "        token_type_ids = torch.tensor([i['token_type_ids'] for i in inputs], device=self.args.device) if 'token_type_ids' in keys else None        \n",
    "        position_ids = torch.tensor([i['position_ids'] for i in inputs], device=self.args.device) if 'position_ids' in keys else None        \n",
    "        head_mask = torch.tensor([i['head_mask'] for i in inputs], device=self.args.device) if 'head_mask' in keys else None        \n",
    "        inputs_embeds = torch.tensor([i['inputs_embeds'] for i in inputs], device=self.args.device) if 'inputs_embeds' in keys else None\n",
    "        \n",
    "        outputs = self.pretrained_transformer(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "            position_ids = position_ids,\n",
    "            head_mask = head_mask,\n",
    "            inputs_embeds = inputs_embeds,\n",
    "        )\n",
    "\n",
    "        sequence_output, pooled_output = outputs[:2]\n",
    "        loss_list = []\n",
    "        logits_list = {}\n",
    "        \n",
    "        for i, head in enumerate(self.model.output_heads.values()):\n",
    "            labels_name = f\"target_{i+1}\"\n",
    "            labels_i = torch.tensor([i[labels_name] for i in inputs], device=self.args.device)\n",
    "            logits, loss = head(sequence_output, pooled_output, labels=labels_i, attention_mask=attention_mask)\n",
    "            loss_list.append(loss)\n",
    "            logits_list[labels_name] = logits\n",
    "        \n",
    "        loss = torch.stack(loss_list)\n",
    "        return (loss, logits_list) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "import funcy as fc\n",
    "import warnings\n",
    "from frozendict import frozendict as fdict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TokenClassification:\n",
    "    task_type = \"TokenClassification\"\n",
    "    name: str = \"TokenClassificationTask\"\n",
    "    dataset: Dataset = None\n",
    "    metric:... = evaluate.load(\"seqeval\")\n",
    "    main_split: str = \"train\"\n",
    "    tokens: str = 'tokens'\n",
    "    y: str|list = 'target'\n",
    "    num_labels: int = None\n",
    "    label_names: dict = None\n",
    "    tokenizer_kwargs: fdict = fdict(padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _align_labels_with_tokens(labels, word_ids):\n",
    "        new_labels = []\n",
    "        current_word = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                new_labels.append(-100)\n",
    "\n",
    "            elif word_id != current_word:\n",
    "                current_word = word_id\n",
    "                label = -100 if word_id is None else labels[word_id]\n",
    "                new_labels.append(label)\n",
    "            \n",
    "            else:\n",
    "                label = labels[word_id]\n",
    "                new_labels.append(label)\n",
    "        \n",
    "        return new_labels\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.label_names = {}\n",
    "        self.num_labels  = {}\n",
    "\n",
    "        for y in self.y:\n",
    "            target = self.dataset[self.main_split].features[y]\n",
    "            self.num_labels[y] = target.feature.num_classes\n",
    "            self.label_names[y] = target.feature.names if target.feature.names else [None]\n",
    "        \n",
    "        print(f\"[*] TokenClassificationTask loaded {self.task_type} task with {self.num_labels} labels\")\n",
    "        for k,v in self.label_names.items():\n",
    "            print(f\"      {k} labels: {v}\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        return super().get_labels() or self.label_names\n",
    "\n",
    "    def set_tokenizer(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.add_prefix_space = True\n",
    "        self.data_collator = DataCollatorForTokenClassification(\n",
    "            tokenizer = self.tokenizer\n",
    "        )\n",
    "\n",
    "    def preprocess_function(self, examples):\n",
    "        if examples[self.tokens] and type(examples[self.tokens][0]) == str:\n",
    "            unsqueeze, examples = True, {k:[v] for k,v in examples.items()}\n",
    "        \n",
    "        def get_len(outputs):\n",
    "            try:\n",
    "                return len(outputs[fc.first(outputs)])\n",
    "            except:\n",
    "                return 1\n",
    "        \n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            examples[self.tokens],\n",
    "            is_split_into_words=True,\n",
    "            **self.tokenizer_kwargs\n",
    "        )\n",
    "\n",
    "        for target_column in self.y:\n",
    "            all_labels = examples[target_column]\n",
    "            new_labels = []\n",
    "            \n",
    "            for i, labels in enumerate(all_labels):\n",
    "                word_ids = tokenized_inputs.word_ids(i)\n",
    "                new_labels.append(self._align_labels_with_tokens(labels, word_ids))\n",
    "            \n",
    "            tokenized_inputs[target_column] = new_labels        \n",
    "            tokenized_inputs['task_ids'] = [self.index]*get_len(tokenized_inputs)\n",
    "\n",
    "        return tokenized_inputs       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2c953960ab43098ef9817fd93295e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/39832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17484ef491c84ac18d3747106ddb85e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/39832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6715f71cde354f5b911afda0bb024d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/39832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de35aaf5d244447fb6a9c36c65ffd741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a0aee18abc4aa994139933c78b178d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1709e3062d4970ada41057f1eccbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Sample encoded sentence\n",
      "    ['In', 'an', 'Oct.', '19', 'review', 'of', '``', 'The', 'Misanthrope', \"''\", 'at', 'Chicago', \"'s\", 'Goodman', 'Theatre', '-LRB-', '``', 'Revitalized', 'Classics', 'Take', 'the', 'Stage', 'in', 'Windy', 'City', ',', \"''\", 'Leisure', '&', 'Arts', '-RRB-', ',', 'the', 'role', 'of', 'Celimene', ',', 'played', 'by', 'Kim', 'Cattrall', ',', 'was', 'mistakenly', 'attributed', 'to', 'Christina', 'Haag', '.']\n",
      "    ['2', '4', '4', '4', '3', '4', '5', '6', '5', '5', '6', '8', '7', '7', '3', '4', '4', '6', '5', '6', '7', '6', '7', '8', '4', '4', '4', '5', '5', '4', '1', '1', '4', '3', '4', '2', '2', '3', '4', '5', '2', '1', '2', '3', '3', '4', '5', '1', '1']\n",
      "    ['PP', 'NP', 'NP', 'NP', 'NP', 'PP', 'NP', 'NP', 'NP', 'NP', 'PP', 'NP', 'NP', 'NP', 'NP', 'PRN', 'PRN', 'NP', 'S', 'VP', 'NP', 'VP', 'PP', 'NP', 'PRN', 'PRN', 'PRN', 'NP', 'NP', 'PRN', 'S', 'S', 'NP', 'NP', 'PP', 'NP', 'NP', 'VP', 'PP', 'NP', 'NP', 'S', 'VP', 'VP', 'VP', 'PP', 'NP', 'S', 'S']\n",
      "    ['-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', 'NP', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', 'ADVP', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-']\n",
      "[*] TokenClassificationTask loaded TokenClassification task with {'target_1': 35, 'target_2': 105, 'target_3': 51} labels\n",
      "      target_1 labels: ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '4', '5', '6', '7', '8', '9']\n",
      "      target_2 labels: ['ADJP', 'ADJP[+]ADJP', 'ADJP[+]ADVP', 'ADJP[+]NP', 'ADJP[+]QP', 'ADVP', 'ADVP[+]ADVP', 'CONJP', 'FRAG', 'FRAG[+]ADJP', 'FRAG[+]ADVP', 'FRAG[+]NNP', 'FRAG[+]NP', 'FRAG[+]PP', 'FRAG[+]S', 'FRAG[+]SBAR', 'FRAG[+]SBARQ', 'FRAG[+]S[+]VP', 'FRAG[+]UCP', 'FRAG[+]VP', 'FRAG[+]WHADVP', 'FRAG[+]WHNP', 'FRAG[+]WHPP', 'INTJ', 'INTJ[+]S', 'LST', 'NAC', 'NP', 'NP[+]ADJP', 'NP[+]FRAG', 'NP[+]NN', 'NP[+]NNP', 'NP[+]NNS', 'NP[+]NP', 'NP[+]NP[+]NP', 'NP[+]NP[+]QP', 'NP[+]PP', 'NP[+]PRN', 'NP[+]QP', 'NP[+]S', 'NP[+]SBAR', 'NP[+]SBAR[+]S[+]VP', 'NP[+]S[+]VP', 'NP[+]VBN', 'NX', 'NX[+]NX', 'NX[+]QP', 'NX[+]S', 'NX[+]S[+]VP', 'PP', 'PP[+]NP', 'PP[+]PP', 'PRN', 'PRN[+]FRAG[+]WHADJP', 'PRN[+]NP', 'PRN[+]PP', 'PRN[+]S', 'PRN[+]SBAR', 'PRN[+]SINV', 'PRT', 'QP', 'RRC', 'RRC[+]VP', 'S', 'SBAR', 'SBARQ', 'SBAR[+]FRAG', 'SBAR[+]S', 'SBAR[+]SBARQ', 'SBAR[+]SBAR[+]S', 'SBAR[+]SINV', 'SBAR[+]S[+]VP', 'SBAR[+]WHNP', 'SINV', 'SQ', 'SQ[+]VP', 'S[+]ADJP', 'S[+]ADVP', 'S[+]NP', 'S[+]PP', 'S[+]S', 'S[+]UCP', 'S[+]VP', 'S[+]VP[+]NNP', 'S[+]VP[+]VP', 'UCP', 'UCP[+]ADJP', 'UCP[+]PP', 'VP', 'VP[+]ADVP', 'VP[+]NP', 'VP[+]PP', 'VP[+]SBAR', 'VP[+]VP', 'WHADJP', 'WHADVP', 'WHNP', 'WHNP[+]QP', 'WHPP', 'X', 'X[+]ADVP', 'X[+]NN', 'X[+]NP', 'X[+]SBARQ', 'X[+]VP']\n",
      "      target_3 labels: ['-NONE-', 'ADJP', 'ADJP[+]ADJP', 'ADVP', 'ADVP[+]ADJP', 'ADVP[+]ADVP', 'ADVP[+]PRT', 'CONJP', 'FRAG', 'FRAG[+]ADJP', 'FRAG[+]ADVP', 'FRAG[+]INTJ', 'FRAG[+]NP', 'FRAG[+]PP', 'FRAG[+]S[+]ADJP', 'FRAG[+]VP', 'FRAG[+]WHADVP', 'FRAG[+]WHNP', 'INTJ', 'LST', 'NAC', 'NP', 'NP[+]ADVP', 'NP[+]INTJ', 'NP[+]NP', 'NX', 'NX[+]NX', 'PP', 'PRN[+]S[+]VP', 'PRT', 'QP', 'SBAR', 'SBARQ[+]WHADVP', 'SBAR[+]S[+]VP', 'SBAR[+]WHADVP', 'SBAR[+]WHNP', 'SQ[+]VP', 'S[+]ADJP', 'S[+]ADVP', 'S[+]NP', 'S[+]VP', 'S[+]VP[+]ADVP', 'VP', 'VP[+]ADVP', 'VP[+]FRAG[+]ADJP', 'VP[+]S[+]VP', 'WHADVP', 'WHNP', 'WHNP[+]WHNP', 'X', 'X[+]PP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Creating output head for task naive_absolute_n_commons\n",
      "      - Task type: TokenClassification\n",
      "      - Number of labels: {'target_1': 35, 'target_2': 105, 'target_3': 51}\n",
      "      - Label names:\n",
      "            - target_1 : ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '4', '5', '6', '7', '8', '9']\n",
      "            - target_2 : ['ADJP', 'ADJP[+]ADJP', 'ADJP[+]ADVP', 'ADJP[+]NP', 'ADJP[+]QP', 'ADVP', 'ADVP[+]ADVP', 'CONJP', 'FRAG', 'FRAG[+]ADJP', 'FRAG[+]ADVP', 'FRAG[+]NNP', 'FRAG[+]NP', 'FRAG[+]PP', 'FRAG[+]S', 'FRAG[+]SBAR', 'FRAG[+]SBARQ', 'FRAG[+]S[+]VP', 'FRAG[+]UCP', 'FRAG[+]VP', 'FRAG[+]WHADVP', 'FRAG[+]WHNP', 'FRAG[+]WHPP', 'INTJ', 'INTJ[+]S', 'LST', 'NAC', 'NP', 'NP[+]ADJP', 'NP[+]FRAG', 'NP[+]NN', 'NP[+]NNP', 'NP[+]NNS', 'NP[+]NP', 'NP[+]NP[+]NP', 'NP[+]NP[+]QP', 'NP[+]PP', 'NP[+]PRN', 'NP[+]QP', 'NP[+]S', 'NP[+]SBAR', 'NP[+]SBAR[+]S[+]VP', 'NP[+]S[+]VP', 'NP[+]VBN', 'NX', 'NX[+]NX', 'NX[+]QP', 'NX[+]S', 'NX[+]S[+]VP', 'PP', 'PP[+]NP', 'PP[+]PP', 'PRN', 'PRN[+]FRAG[+]WHADJP', 'PRN[+]NP', 'PRN[+]PP', 'PRN[+]S', 'PRN[+]SBAR', 'PRN[+]SINV', 'PRT', 'QP', 'RRC', 'RRC[+]VP', 'S', 'SBAR', 'SBARQ', 'SBAR[+]FRAG', 'SBAR[+]S', 'SBAR[+]SBARQ', 'SBAR[+]SBAR[+]S', 'SBAR[+]SINV', 'SBAR[+]S[+]VP', 'SBAR[+]WHNP', 'SINV', 'SQ', 'SQ[+]VP', 'S[+]ADJP', 'S[+]ADVP', 'S[+]NP', 'S[+]PP', 'S[+]S', 'S[+]UCP', 'S[+]VP', 'S[+]VP[+]NNP', 'S[+]VP[+]VP', 'UCP', 'UCP[+]ADJP', 'UCP[+]PP', 'VP', 'VP[+]ADVP', 'VP[+]NP', 'VP[+]PP', 'VP[+]SBAR', 'VP[+]VP', 'WHADJP', 'WHADVP', 'WHNP', 'WHNP[+]QP', 'WHPP', 'X', 'X[+]ADVP', 'X[+]NN', 'X[+]NP', 'X[+]SBARQ', 'X[+]VP']\n",
      "            - target_3 : ['-NONE-', 'ADJP', 'ADJP[+]ADJP', 'ADVP', 'ADVP[+]ADJP', 'ADVP[+]ADVP', 'ADVP[+]PRT', 'CONJP', 'FRAG', 'FRAG[+]ADJP', 'FRAG[+]ADVP', 'FRAG[+]INTJ', 'FRAG[+]NP', 'FRAG[+]PP', 'FRAG[+]S[+]ADJP', 'FRAG[+]VP', 'FRAG[+]WHADVP', 'FRAG[+]WHNP', 'INTJ', 'LST', 'NAC', 'NP', 'NP[+]ADVP', 'NP[+]INTJ', 'NP[+]NP', 'NX', 'NX[+]NX', 'PP', 'PRN[+]S[+]VP', 'PRT', 'QP', 'SBAR', 'SBARQ[+]WHADVP', 'SBAR[+]S[+]VP', 'SBAR[+]WHADVP', 'SBAR[+]WHNP', 'SQ[+]VP', 'S[+]ADJP', 'S[+]ADVP', 'S[+]NP', 'S[+]VP', 'S[+]VP[+]ADVP', 'VP', 'VP[+]ADVP', 'VP[+]FRAG[+]ADJP', 'VP[+]S[+]VP', 'WHADVP', 'WHNP', 'WHNP[+]WHNP', 'X', 'X[+]PP']\n",
      "[*] Example input:\n",
      "      - tokens : ['In', 'an', 'Oct.', '19', 'review', 'of', '``', 'The', 'Misanthrope', \"''\", 'at', 'Chicago', \"'s\", 'Goodman', 'Theatre', '-LRB-', '``', 'Revitalized', 'Classics', 'Take', 'the', 'Stage', 'in', 'Windy', 'City', ',', \"''\", 'Leisure', '&', 'Arts', '-RRB-', ',', 'the', 'role', 'of', 'Celimene', ',', 'played', 'by', 'Kim', 'Cattrall', ',', 'was', 'mistakenly', 'attributed', 'to', 'Christina', 'Haag', '.']\n",
      "      - target_1 : [11, 29, 29, 29, 22, 29, 30, 31, 30, 30, 31, 33, 32, 32, 22, 29, 29, 31, 30, 31, 32, 31, 32, 33, 29, 29, 29, 30, 30, 29, 0, 0, 29, 22, 29, 11, 11, 22, 29, 30, 11, 0, 11, 22, 22, 29, 30, 0, 0]\n",
      "      - target_2 : [49, 27, 27, 27, 27, 49, 27, 27, 27, 27, 49, 27, 27, 27, 27, 52, 52, 27, 63, 88, 27, 88, 49, 27, 52, 52, 52, 27, 27, 52, 63, 63, 27, 27, 49, 27, 27, 88, 49, 27, 27, 63, 88, 88, 88, 49, 27, 63, 63]\n",
      "      - target_3 : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0]\n",
      "[*] Example input (real labels):\n",
      "      - ['2', '4', '4', '4', '3', '4', '5', '6', '5', '5', '6', '8', '7', '7', '3', '4', '4', '6', '5', '6', '7', '6', '7', '8', '4', '4', '4', '5', '5', '4', '1', '1', '4', '3', '4', '2', '2', '3', '4', '5', '2', '1', '2', '3', '3', '4', '5', '1', '1']\n",
      "      - ['PP', 'NP', 'NP', 'NP', 'NP', 'PP', 'NP', 'NP', 'NP', 'NP', 'PP', 'NP', 'NP', 'NP', 'NP', 'PRN', 'PRN', 'NP', 'S', 'VP', 'NP', 'VP', 'PP', 'NP', 'PRN', 'PRN', 'PRN', 'NP', 'NP', 'PRN', 'S', 'S', 'NP', 'NP', 'PP', 'NP', 'NP', 'VP', 'PP', 'NP', 'NP', 'S', 'VP', 'VP', 'VP', 'PP', 'NP', 'S', 'S']\n",
      "      - ['-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', 'NP', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-', 'ADVP', '-NONE-', '-NONE-', '-NONE-', '-NONE-', '-NONE-']\n",
      "[*] Creating TokenClassification head with 35 labels\n",
      "[*] Creating TokenClassification head with 105 labels\n",
      "[*] Creating TokenClassification head with 51 labels\n",
      "[*] Model preprocessing task naive_absolute_n_commons\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a4a0556f764d878280a27a6fdfd033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef56e599b074509afc28f97e20c4451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Model has 3 output heads\n",
      "[*] Model has 1 training datasets\n",
      "[*] Model has 1 evaluation datasets\n",
      "[*] Init multitask trainer with tasks: {'naive_absolute_n_commons': {'train': Dataset({\n",
      "    features: ['tokens', 'target_1', 'target_2', 'target_3', 'input_ids', 'token_type_ids', 'attention_mask', 'task_ids'],\n",
      "    num_rows: 39832\n",
      "}), 'validation': Dataset({\n",
      "    features: ['tokens', 'target_1', 'target_2', 'target_3', 'input_ids', 'token_type_ids', 'attention_mask', 'task_ids'],\n",
      "    num_rows: 1700\n",
      "})}}\n",
      "[*] Label names are: {'naive_absolute_n_commons': {'target_1': ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '4', '5', '6', '7', '8', '9'], 'target_2': ['ADJP', 'ADJP[+]ADJP', 'ADJP[+]ADVP', 'ADJP[+]NP', 'ADJP[+]QP', 'ADVP', 'ADVP[+]ADVP', 'CONJP', 'FRAG', 'FRAG[+]ADJP', 'FRAG[+]ADVP', 'FRAG[+]NNP', 'FRAG[+]NP', 'FRAG[+]PP', 'FRAG[+]S', 'FRAG[+]SBAR', 'FRAG[+]SBARQ', 'FRAG[+]S[+]VP', 'FRAG[+]UCP', 'FRAG[+]VP', 'FRAG[+]WHADVP', 'FRAG[+]WHNP', 'FRAG[+]WHPP', 'INTJ', 'INTJ[+]S', 'LST', 'NAC', 'NP', 'NP[+]ADJP', 'NP[+]FRAG', 'NP[+]NN', 'NP[+]NNP', 'NP[+]NNS', 'NP[+]NP', 'NP[+]NP[+]NP', 'NP[+]NP[+]QP', 'NP[+]PP', 'NP[+]PRN', 'NP[+]QP', 'NP[+]S', 'NP[+]SBAR', 'NP[+]SBAR[+]S[+]VP', 'NP[+]S[+]VP', 'NP[+]VBN', 'NX', 'NX[+]NX', 'NX[+]QP', 'NX[+]S', 'NX[+]S[+]VP', 'PP', 'PP[+]NP', 'PP[+]PP', 'PRN', 'PRN[+]FRAG[+]WHADJP', 'PRN[+]NP', 'PRN[+]PP', 'PRN[+]S', 'PRN[+]SBAR', 'PRN[+]SINV', 'PRT', 'QP', 'RRC', 'RRC[+]VP', 'S', 'SBAR', 'SBARQ', 'SBAR[+]FRAG', 'SBAR[+]S', 'SBAR[+]SBARQ', 'SBAR[+]SBAR[+]S', 'SBAR[+]SINV', 'SBAR[+]S[+]VP', 'SBAR[+]WHNP', 'SINV', 'SQ', 'SQ[+]VP', 'S[+]ADJP', 'S[+]ADVP', 'S[+]NP', 'S[+]PP', 'S[+]S', 'S[+]UCP', 'S[+]VP', 'S[+]VP[+]NNP', 'S[+]VP[+]VP', 'UCP', 'UCP[+]ADJP', 'UCP[+]PP', 'VP', 'VP[+]ADVP', 'VP[+]NP', 'VP[+]PP', 'VP[+]SBAR', 'VP[+]VP', 'WHADJP', 'WHADVP', 'WHNP', 'WHNP[+]QP', 'WHPP', 'X', 'X[+]ADVP', 'X[+]NN', 'X[+]NP', 'X[+]SBARQ', 'X[+]VP'], 'target_3': ['-NONE-', 'ADJP', 'ADJP[+]ADJP', 'ADVP', 'ADVP[+]ADJP', 'ADVP[+]ADVP', 'ADVP[+]PRT', 'CONJP', 'FRAG', 'FRAG[+]ADJP', 'FRAG[+]ADVP', 'FRAG[+]INTJ', 'FRAG[+]NP', 'FRAG[+]PP', 'FRAG[+]S[+]ADJP', 'FRAG[+]VP', 'FRAG[+]WHADVP', 'FRAG[+]WHNP', 'INTJ', 'LST', 'NAC', 'NP', 'NP[+]ADVP', 'NP[+]INTJ', 'NP[+]NP', 'NX', 'NX[+]NX', 'PP', 'PRN[+]S[+]VP', 'PRT', 'QP', 'SBAR', 'SBARQ[+]WHADVP', 'SBAR[+]S[+]VP', 'SBAR[+]WHADVP', 'SBAR[+]WHNP', 'SQ[+]VP', 'S[+]ADJP', 'S[+]ADVP', 'S[+]NP', 'S[+]VP', 'S[+]VP[+]ADVP', 'VP', 'VP[+]ADVP', 'VP[+]FRAG[+]ADJP', 'VP[+]S[+]VP', 'WHADVP', 'WHNP', 'WHNP[+]WHNP', 'X', 'X[+]PP']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13473715b39491da4daaff0710ee657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1205, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 4.0771, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n",
      "{'loss': 4.004, 'learning_rate': 3e-06, 'epoch': 0.01}\n",
      "{'loss': 3.8977, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 3.7325, 'learning_rate': 5e-06, 'epoch': 0.02}\n",
      "{'loss': 3.5, 'learning_rate': 6e-06, 'epoch': 0.02}\n",
      "{'loss': 3.0041, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 2.4568, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 2.1162, 'learning_rate': 9e-06, 'epoch': 0.04}\n",
      "{'loss': 1.895, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.863, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7974, 'learning_rate': 1.2e-05, 'epoch': 0.05}\n",
      "{'loss': 1.6771, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.05}\n",
      "{'loss': 1.5819, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.06}\n",
      "{'loss': 1.5361, 'learning_rate': 1.5e-05, 'epoch': 0.06}\n",
      "{'loss': 1.3153, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 1.3101, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 1.2324, 'learning_rate': 1.8e-05, 'epoch': 0.07}\n",
      "{'loss': 1.1482, 'learning_rate': 1.9e-05, 'epoch': 0.08}\n",
      "{'loss': 1.0802, 'learning_rate': 2e-05, 'epoch': 0.08}\n",
      "{'loss': 1.0858, 'learning_rate': 2.1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.0008, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 0.9835, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 0.9681, 'learning_rate': 2.4e-05, 'epoch': 0.1}\n",
      "{'loss': 0.999, 'learning_rate': 2.5e-05, 'epoch': 0.1}\n",
      "{'loss': 0.8823, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.1}\n",
      "{'loss': 0.8688, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8727, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7863, 'learning_rate': 2.9e-05, 'epoch': 0.12}\n",
      "{'loss': 0.8459, 'learning_rate': 3e-05, 'epoch': 0.12}\n",
      "{'loss': 0.8161, 'learning_rate': 3.1e-05, 'epoch': 0.12}\n",
      "{'loss': 0.8936, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.13}\n",
      "{'loss': 0.7337, 'learning_rate': 3.3e-05, 'epoch': 0.13}\n",
      "{'loss': 0.8073, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.14}\n",
      "{'loss': 0.7521, 'learning_rate': 3.5e-05, 'epoch': 0.14}\n",
      "{'loss': 0.6581, 'learning_rate': 3.6e-05, 'epoch': 0.14}\n",
      "{'loss': 0.6788, 'learning_rate': 3.7e-05, 'epoch': 0.15}\n",
      "{'loss': 0.6662, 'learning_rate': 3.8e-05, 'epoch': 0.15}\n",
      "{'loss': 0.7468, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.16}\n",
      "{'loss': 0.6257, 'learning_rate': 4e-05, 'epoch': 0.16}\n",
      "{'loss': 0.7381, 'learning_rate': 4.1e-05, 'epoch': 0.16}\n",
      "{'loss': 0.6533, 'learning_rate': 4.2e-05, 'epoch': 0.17}\n",
      "{'loss': 0.6715, 'learning_rate': 4.3e-05, 'epoch': 0.17}\n",
      "{'loss': 0.5984, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.18}\n",
      "{'loss': 0.6531, 'learning_rate': 4.5e-05, 'epoch': 0.18}\n",
      "{'loss': 0.659, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.18}\n",
      "{'loss': 0.5758, 'learning_rate': 4.7e-05, 'epoch': 0.19}\n",
      "{'loss': 0.6001, 'learning_rate': 4.8e-05, 'epoch': 0.19}\n",
      "{'loss': 0.6827, 'learning_rate': 4.9e-05, 'epoch': 0.2}\n",
      "{'loss': 0.6361, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
      "{'loss': 0.6087, 'learning_rate': 4.9888392857142854e-05, 'epoch': 0.2}\n",
      "{'loss': 0.6136, 'learning_rate': 4.977678571428572e-05, 'epoch': 0.21}\n",
      "{'loss': 0.5696, 'learning_rate': 4.966517857142857e-05, 'epoch': 0.21}\n",
      "{'loss': 0.6301, 'learning_rate': 4.955357142857143e-05, 'epoch': 0.22}\n",
      "{'loss': 0.57, 'learning_rate': 4.944196428571429e-05, 'epoch': 0.22}\n",
      "{'loss': 0.5748, 'learning_rate': 4.933035714285715e-05, 'epoch': 0.22}\n",
      "{'loss': 0.5403, 'learning_rate': 4.921875e-05, 'epoch': 0.23}\n",
      "{'loss': 0.5962, 'learning_rate': 4.910714285714286e-05, 'epoch': 0.23}\n",
      "{'loss': 0.6396, 'learning_rate': 4.899553571428572e-05, 'epoch': 0.24}\n",
      "{'loss': 0.5641, 'learning_rate': 4.888392857142857e-05, 'epoch': 0.24}\n",
      "{'loss': 0.5301, 'learning_rate': 4.8772321428571435e-05, 'epoch': 0.24}\n",
      "{'loss': 0.537, 'learning_rate': 4.866071428571429e-05, 'epoch': 0.25}\n",
      "{'loss': 0.516, 'learning_rate': 4.8549107142857146e-05, 'epoch': 0.25}\n",
      "{'loss': 0.5449, 'learning_rate': 4.8437500000000005e-05, 'epoch': 0.26}\n",
      "{'loss': 0.4778, 'learning_rate': 4.832589285714286e-05, 'epoch': 0.26}\n",
      "{'loss': 0.588, 'learning_rate': 4.8214285714285716e-05, 'epoch': 0.27}\n",
      "{'loss': 0.5485, 'learning_rate': 4.8102678571428575e-05, 'epoch': 0.27}\n",
      "{'loss': 0.4616, 'learning_rate': 4.7991071428571433e-05, 'epoch': 0.27}\n",
      "{'loss': 0.5249, 'learning_rate': 4.7879464285714285e-05, 'epoch': 0.28}\n",
      "{'loss': 0.5118, 'learning_rate': 4.7767857142857144e-05, 'epoch': 0.28}\n",
      "{'loss': 0.5463, 'learning_rate': 4.765625e-05, 'epoch': 0.29}\n",
      "{'loss': 0.4686, 'learning_rate': 4.7544642857142855e-05, 'epoch': 0.29}\n",
      "{'loss': 0.5197, 'learning_rate': 4.743303571428572e-05, 'epoch': 0.29}\n",
      "{'loss': 0.5144, 'learning_rate': 4.732142857142857e-05, 'epoch': 0.3}\n",
      "{'loss': 0.5083, 'learning_rate': 4.720982142857143e-05, 'epoch': 0.3}\n",
      "{'loss': 0.4738, 'learning_rate': 4.709821428571429e-05, 'epoch': 0.31}\n",
      "{'loss': 0.4801, 'learning_rate': 4.698660714285715e-05, 'epoch': 0.31}\n",
      "{'loss': 0.438, 'learning_rate': 4.6875e-05, 'epoch': 0.31}\n",
      "{'loss': 0.4873, 'learning_rate': 4.676339285714286e-05, 'epoch': 0.32}\n",
      "{'loss': 0.4126, 'learning_rate': 4.665178571428572e-05, 'epoch': 0.32}\n",
      "{'loss': 0.5141, 'learning_rate': 4.654017857142857e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5077, 'learning_rate': 4.642857142857143e-05, 'epoch': 0.33}\n",
      "{'loss': 0.42, 'learning_rate': 4.631696428571429e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5124, 'learning_rate': 4.620535714285715e-05, 'epoch': 0.34}\n",
      "{'loss': 0.4751, 'learning_rate': 4.609375e-05, 'epoch': 0.34}\n",
      "{'loss': 0.5065, 'learning_rate': 4.598214285714286e-05, 'epoch': 0.35}\n",
      "{'loss': 0.5035, 'learning_rate': 4.5870535714285716e-05, 'epoch': 0.35}\n",
      "{'loss': 0.5448, 'learning_rate': 4.5758928571428575e-05, 'epoch': 0.35}\n",
      "{'loss': 0.4065, 'learning_rate': 4.5647321428571434e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4486, 'learning_rate': 4.5535714285714286e-05, 'epoch': 0.36}\n",
      "{'loss': 0.439, 'learning_rate': 4.5424107142857145e-05, 'epoch': 0.37}\n",
      "{'loss': 0.4554, 'learning_rate': 4.5312500000000004e-05, 'epoch': 0.37}\n",
      "{'loss': 0.4257, 'learning_rate': 4.5200892857142856e-05, 'epoch': 0.37}\n",
      "{'loss': 0.4401, 'learning_rate': 4.5089285714285714e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4237, 'learning_rate': 4.497767857142857e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4222, 'learning_rate': 4.486607142857143e-05, 'epoch': 0.39}\n",
      "{'loss': 0.4489, 'learning_rate': 4.4754464285714284e-05, 'epoch': 0.39}\n",
      "{'loss': 0.4299, 'learning_rate': 4.464285714285715e-05, 'epoch': 0.39}\n",
      "{'loss': 0.3789, 'learning_rate': 4.453125e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4064, 'learning_rate': 4.4419642857142854e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3938, 'learning_rate': 4.430803571428572e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4275, 'learning_rate': 4.419642857142857e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4236, 'learning_rate': 4.408482142857143e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4552, 'learning_rate': 4.397321428571429e-05, 'epoch': 0.42}\n",
      "{'loss': 0.455, 'learning_rate': 4.386160714285715e-05, 'epoch': 0.42}\n",
      "{'loss': 0.4512, 'learning_rate': 4.375e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4499, 'learning_rate': 4.363839285714286e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4513, 'learning_rate': 4.352678571428572e-05, 'epoch': 0.43}\n",
      "{'loss': 0.2915, 'learning_rate': 4.341517857142857e-05, 'epoch': 0.44}\n",
      "{'loss': 0.401, 'learning_rate': 4.3303571428571435e-05, 'epoch': 0.44}\n",
      "{'loss': 0.4518, 'learning_rate': 4.319196428571429e-05, 'epoch': 0.45}\n",
      "{'loss': 0.477, 'learning_rate': 4.3080357142857145e-05, 'epoch': 0.45}\n",
      "{'loss': 0.5062, 'learning_rate': 4.2968750000000004e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3923, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.46}\n",
      "{'loss': 0.405, 'learning_rate': 4.2745535714285715e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4144, 'learning_rate': 4.2633928571428574e-05, 'epoch': 0.47}\n",
      "{'loss': 0.413, 'learning_rate': 4.252232142857143e-05, 'epoch': 0.47}\n",
      "{'loss': 0.3817, 'learning_rate': 4.2410714285714285e-05, 'epoch': 0.47}\n",
      "{'loss': 0.4031, 'learning_rate': 4.229910714285715e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4076, 'learning_rate': 4.21875e-05, 'epoch': 0.48}\n",
      "{'loss': 0.3541, 'learning_rate': 4.2075892857142854e-05, 'epoch': 0.49}\n",
      "{'loss': 0.3846, 'learning_rate': 4.196428571428572e-05, 'epoch': 0.49}\n",
      "{'loss': 0.4299, 'learning_rate': 4.185267857142857e-05, 'epoch': 0.49}\n",
      "{'loss': 0.3604, 'learning_rate': 4.174107142857143e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4299, 'learning_rate': 4.162946428571429e-05, 'epoch': 0.5}\n",
      "{'loss': 0.3743, 'learning_rate': 4.151785714285715e-05, 'epoch': 0.51}\n",
      "{'loss': 0.3454, 'learning_rate': 4.140625e-05, 'epoch': 0.51}\n",
      "{'loss': 0.4497, 'learning_rate': 4.129464285714286e-05, 'epoch': 0.51}\n",
      "{'loss': 0.3396, 'learning_rate': 4.118303571428572e-05, 'epoch': 0.52}\n",
      "{'loss': 0.3865, 'learning_rate': 4.107142857142857e-05, 'epoch': 0.52}\n",
      "{'loss': 0.3935, 'learning_rate': 4.0959821428571435e-05, 'epoch': 0.53}\n",
      "{'loss': 0.353, 'learning_rate': 4.084821428571429e-05, 'epoch': 0.53}\n",
      "{'loss': 0.3133, 'learning_rate': 4.0736607142857146e-05, 'epoch': 0.53}\n",
      "{'loss': 0.3632, 'learning_rate': 4.0625000000000005e-05, 'epoch': 0.54}\n",
      "{'loss': 0.3748, 'learning_rate': 4.051339285714286e-05, 'epoch': 0.54}\n",
      "{'loss': 0.3854, 'learning_rate': 4.0401785714285716e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3306, 'learning_rate': 4.0290178571428574e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3898, 'learning_rate': 4.017857142857143e-05, 'epoch': 0.55}\n",
      "{'loss': 0.4003, 'learning_rate': 4.0066964285714285e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3684, 'learning_rate': 3.9955357142857144e-05, 'epoch': 0.56}\n",
      "{'loss': 0.4076, 'learning_rate': 3.984375e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3495, 'learning_rate': 3.9732142857142855e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3598, 'learning_rate': 3.9620535714285714e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3211, 'learning_rate': 3.950892857142857e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4146, 'learning_rate': 3.939732142857143e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4514, 'learning_rate': 3.928571428571429e-05, 'epoch': 0.59}\n",
      "{'loss': 0.4195, 'learning_rate': 3.917410714285715e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3942, 'learning_rate': 3.90625e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3609, 'learning_rate': 3.895089285714286e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3575, 'learning_rate': 3.883928571428572e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3736, 'learning_rate': 3.872767857142857e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3454, 'learning_rate': 3.861607142857143e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3237, 'learning_rate': 3.850446428571429e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3499, 'learning_rate': 3.839285714285715e-05, 'epoch': 0.62}\n",
      "{'loss': 0.3838, 'learning_rate': 3.828125e-05, 'epoch': 0.62}\n",
      "{'loss': 0.3452, 'learning_rate': 3.816964285714286e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3741, 'learning_rate': 3.8058035714285716e-05, 'epoch': 0.63}\n",
      "{'loss': 0.41, 'learning_rate': 3.794642857142857e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3857, 'learning_rate': 3.7834821428571434e-05, 'epoch': 0.64}\n",
      "{'loss': 0.4036, 'learning_rate': 3.7723214285714286e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3494, 'learning_rate': 3.7611607142857145e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3582, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3479, 'learning_rate': 3.7388392857142856e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3314, 'learning_rate': 3.7276785714285714e-05, 'epoch': 0.66}\n",
      "{'loss': 0.3457, 'learning_rate': 3.716517857142857e-05, 'epoch': 0.66}\n",
      "{'loss': 0.4233, 'learning_rate': 3.705357142857143e-05, 'epoch': 0.67}\n",
      "{'loss': 0.4105, 'learning_rate': 3.6941964285714284e-05, 'epoch': 0.67}\n",
      "{'loss': 0.4028, 'learning_rate': 3.683035714285715e-05, 'epoch': 0.67}\n",
      "{'loss': 0.4162, 'learning_rate': 3.671875e-05, 'epoch': 0.68}\n",
      "{'loss': 0.3348, 'learning_rate': 3.6607142857142853e-05, 'epoch': 0.68}\n",
      "{'loss': 0.3504, 'learning_rate': 3.649553571428572e-05, 'epoch': 0.69}\n",
      "{'loss': 0.3166, 'learning_rate': 3.638392857142857e-05, 'epoch': 0.69}\n",
      "{'loss': 0.3037, 'learning_rate': 3.627232142857143e-05, 'epoch': 0.69}\n",
      "{'loss': 0.3069, 'learning_rate': 3.616071428571429e-05, 'epoch': 0.7}\n",
      "{'loss': 0.3265, 'learning_rate': 3.604910714285715e-05, 'epoch': 0.7}\n",
      "{'loss': 0.3983, 'learning_rate': 3.59375e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3682, 'learning_rate': 3.582589285714286e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3721, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.71}\n",
      "{'loss': 0.374, 'learning_rate': 3.560267857142857e-05, 'epoch': 0.72}\n",
      "{'loss': 0.347, 'learning_rate': 3.5491071428571435e-05, 'epoch': 0.72}\n",
      "{'loss': 0.338, 'learning_rate': 3.5379464285714287e-05, 'epoch': 0.73}\n",
      "{'loss': 0.3258, 'learning_rate': 3.5267857142857145e-05, 'epoch': 0.73}\n",
      "{'loss': 0.381, 'learning_rate': 3.5156250000000004e-05, 'epoch': 0.73}\n",
      "{'loss': 0.3431, 'learning_rate': 3.5044642857142856e-05, 'epoch': 0.74}\n",
      "{'loss': 0.3124, 'learning_rate': 3.4933035714285715e-05, 'epoch': 0.74}\n",
      "{'loss': 0.403, 'learning_rate': 3.4821428571428574e-05, 'epoch': 0.75}\n",
      "{'loss': 0.3671, 'learning_rate': 3.470982142857143e-05, 'epoch': 0.75}\n",
      "{'loss': 0.33, 'learning_rate': 3.4598214285714284e-05, 'epoch': 0.76}\n",
      "{'loss': 0.3967, 'learning_rate': 3.448660714285715e-05, 'epoch': 0.76}\n",
      "{'loss': 0.393, 'learning_rate': 3.4375e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2952, 'learning_rate': 3.4263392857142854e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2986, 'learning_rate': 3.415178571428572e-05, 'epoch': 0.77}\n",
      "{'loss': 0.3256, 'learning_rate': 3.404017857142857e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3098, 'learning_rate': 3.392857142857143e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3568, 'learning_rate': 3.381696428571429e-05, 'epoch': 0.78}\n",
      "{'loss': 0.4075, 'learning_rate': 3.370535714285715e-05, 'epoch': 0.79}\n",
      "{'loss': 0.3473, 'learning_rate': 3.359375e-05, 'epoch': 0.79}\n",
      "{'loss': 0.3457, 'learning_rate': 3.348214285714286e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3346, 'learning_rate': 3.337053571428572e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3388, 'learning_rate': 3.325892857142857e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3669, 'learning_rate': 3.314732142857143e-05, 'epoch': 0.81}\n",
      "{'loss': 0.3039, 'learning_rate': 3.303571428571429e-05, 'epoch': 0.81}\n",
      "{'loss': 0.3264, 'learning_rate': 3.2924107142857146e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3142, 'learning_rate': 3.2812500000000005e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3457, 'learning_rate': 3.270089285714286e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3715, 'learning_rate': 3.2589285714285716e-05, 'epoch': 0.83}\n",
      "{'loss': 0.355, 'learning_rate': 3.2477678571428574e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2979, 'learning_rate': 3.236607142857143e-05, 'epoch': 0.84}\n",
      "{'loss': 0.3287, 'learning_rate': 3.2254464285714285e-05, 'epoch': 0.84}\n",
      "{'loss': 0.3294, 'learning_rate': 3.2142857142857144e-05, 'epoch': 0.84}\n",
      "{'loss': 0.3686, 'learning_rate': 3.203125e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3214, 'learning_rate': 3.1919642857142855e-05, 'epoch': 0.85}\n",
      "{'loss': 0.2932, 'learning_rate': 3.1808035714285713e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3045, 'learning_rate': 3.169642857142857e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3034, 'learning_rate': 3.158482142857143e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3187, 'learning_rate': 3.147321428571428e-05, 'epoch': 0.87}\n",
      "{'loss': 0.2965, 'learning_rate': 3.136160714285715e-05, 'epoch': 0.87}\n",
      "{'loss': 0.3727, 'learning_rate': 3.125e-05, 'epoch': 0.88}\n",
      "{'loss': 0.3401, 'learning_rate': 3.113839285714286e-05, 'epoch': 0.88}\n",
      "{'loss': 0.3307, 'learning_rate': 3.102678571428572e-05, 'epoch': 0.88}\n",
      "{'loss': 0.3025, 'learning_rate': 3.091517857142857e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3887, 'learning_rate': 3.080357142857143e-05, 'epoch': 0.89}\n",
      "{'loss': 0.2721, 'learning_rate': 3.069196428571429e-05, 'epoch': 0.9}\n",
      "{'loss': 0.2901, 'learning_rate': 3.0580357142857147e-05, 'epoch': 0.9}\n",
      "{'loss': 0.3297, 'learning_rate': 3.0468750000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 0.2803, 'learning_rate': 3.0357142857142857e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3694, 'learning_rate': 3.0245535714285716e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3455, 'learning_rate': 3.013392857142857e-05, 'epoch': 0.92}\n",
      "{'loss': 0.2941, 'learning_rate': 3.002232142857143e-05, 'epoch': 0.92}\n",
      "{'loss': 0.3121, 'learning_rate': 2.9910714285714286e-05, 'epoch': 0.92}\n",
      "{'loss': 0.3654, 'learning_rate': 2.9799107142857148e-05, 'epoch': 0.93}\n",
      "{'loss': 0.3007, 'learning_rate': 2.96875e-05, 'epoch': 0.93}\n",
      "{'loss': 0.3307, 'learning_rate': 2.9575892857142855e-05, 'epoch': 0.94}\n",
      "{'loss': 0.3169, 'learning_rate': 2.9464285714285718e-05, 'epoch': 0.94}\n",
      "{'loss': 0.3166, 'learning_rate': 2.9352678571428573e-05, 'epoch': 0.94}\n",
      "{'loss': 0.3535, 'learning_rate': 2.9241071428571432e-05, 'epoch': 0.95}\n",
      "{'loss': 0.3229, 'learning_rate': 2.9129464285714287e-05, 'epoch': 0.95}\n",
      "{'loss': 0.3239, 'learning_rate': 2.9017857142857146e-05, 'epoch': 0.96}\n",
      "{'loss': 0.3462, 'learning_rate': 2.890625e-05, 'epoch': 0.96}\n",
      "{'loss': 0.3867, 'learning_rate': 2.8794642857142857e-05, 'epoch': 0.96}\n",
      "{'loss': 0.3502, 'learning_rate': 2.8683035714285715e-05, 'epoch': 0.97}\n",
      "{'loss': 0.3703, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.97}\n",
      "{'loss': 0.2779, 'learning_rate': 2.8459821428571433e-05, 'epoch': 0.98}\n",
      "{'loss': 0.2838, 'learning_rate': 2.8348214285714285e-05, 'epoch': 0.98}\n",
      "{'loss': 0.3132, 'learning_rate': 2.8236607142857147e-05, 'epoch': 0.98}\n",
      "{'loss': 0.3133, 'learning_rate': 2.8125000000000003e-05, 'epoch': 0.99}\n",
      "{'loss': 0.3316, 'learning_rate': 2.8013392857142855e-05, 'epoch': 0.99}\n",
      "{'loss': 0.2767, 'learning_rate': 2.7901785714285717e-05, 'epoch': 1.0}\n",
      "{'loss': 0.376, 'learning_rate': 2.7790178571428572e-05, 'epoch': 1.0}\n",
      "[*] Evaluation_loop\n",
      "[*] Step 0 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4208, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBAR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: S[+]VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WHNP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SINV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]QP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBAR[+]S[+]VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBAR[+]S seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: QP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -NONE- seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WHADVP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADVP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 1 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3767, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VP[+]VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 2 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4135, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 19 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WHPP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 3 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3563, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 20 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UCP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADVP[+]ADVP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]NP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 4 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3318, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJP[+]QP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SQ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LST seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 5 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3713, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FRAG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBARQ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 6 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.6014, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 21 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: S[+]NP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJP[+]ADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 7 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2494, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 8 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2732, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 9 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3229, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: S[+]ADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WHADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 10 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1775, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 11 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4042, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRN[+]S seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 12 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3589, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 13 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3538, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 14 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3417, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 15 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1954, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 16 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2074, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 17 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2898, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 18 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2417, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 19 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2481, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBAR[+]SINV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 20 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2380, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 21 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2625, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 22 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2879, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 22 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 23 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 24 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 23 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2843, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 24 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4278, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]VBN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 25 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3031, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 26 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2102, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 27 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3757, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SQ[+]VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 28 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3279, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 29 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4347, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 30 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4863, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 31 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3749, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 32 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3893, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 33 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2510, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 34 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3558, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRN[+]SINV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 35 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1882, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 36 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2617, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 37 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4259, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 38 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2919, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 39 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4263, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FRAG[+]NP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 40 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3242, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 41 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3684, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 42 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1894, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FRAG[+]ADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 43 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2695, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 44 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3105, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 45 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2453, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 46 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3717, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 47 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2713, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 48 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4308, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 49 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2608, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 50 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2583, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 51 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2262, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 52 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3107, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 53 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2598, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 54 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3506, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]NP[+]QP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 55 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3416, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 56 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3730, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 57 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3231, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 58 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2575, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 59 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3327, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 60 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3605, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 61 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2285, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 62 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3239, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 63 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3800, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]NNS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 64 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3473, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 65 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3669, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 66 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2551, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 67 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1625, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 68 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3127, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 69 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3728, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 70 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2589, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 71 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2875, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 72 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2593, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 73 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4269, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FRAG[+]ADVP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 74 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3469, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 75 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4142, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]SBAR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 76 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2764, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 77 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2712, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 78 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3092, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 79 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3456, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 80 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2374, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 81 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3048, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 82 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3661, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 83 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2645, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 84 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3875, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 85 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2348, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 86 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2646, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 87 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2842, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 88 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3647, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 89 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3111, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 90 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3354, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 91 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2793, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 92 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2195, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 93 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2485, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 94 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2735, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 95 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2543, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 96 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3370, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 97 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2876, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 98 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3693, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 99 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2821, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 100 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2636, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 101 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3334, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 102 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2857, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 103 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4830, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: S[+]PP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 104 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2556, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 105 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4052, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VP[+]PP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 106 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4791, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "{'eval_precision': 0.8181818181818182, 'eval_recall': 0.75, 'eval_f1': 0.7826086956521738, 'eval_accuracy': 0.9763779527559056, 'eval_name': 'naive_absolute_n_commons', 'eval_size': 4, 'eval_index': 0, 'eval_runtime': 365.2367, 'eval_samples_per_second': 0.003, 'eval_steps_per_second': 0.003, 'epoch': 1.0}\n",
      "{'eval_precision': 0.8181818181818182, 'eval_recall': 0.75, 'eval_f1': 0.7826086956521738, 'eval_accuracy': 0.9763779527559056, 'eval_name': 'naive_absolute_n_commons', 'eval_size': 4, 'eval_index': 0, 'eval_runtime': 365.2367, 'eval_samples_per_second': 0.003, 'eval_steps_per_second': 0.003, 'epoch': 1.0}\n",
      "{'loss': 0.3781, 'learning_rate': 2.767857142857143e-05, 'epoch': 1.0}\n",
      "{'loss': 0.2982, 'learning_rate': 2.7566964285714286e-05, 'epoch': 1.01}\n",
      "{'loss': 0.2673, 'learning_rate': 2.7455357142857145e-05, 'epoch': 1.01}\n",
      "{'loss': 0.4579, 'learning_rate': 2.734375e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3683, 'learning_rate': 2.7232142857142856e-05, 'epoch': 1.02}\n",
      "{'loss': 0.316, 'learning_rate': 2.7120535714285715e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3148, 'learning_rate': 2.700892857142857e-05, 'epoch': 1.03}\n",
      "{'loss': 0.2869, 'learning_rate': 2.6897321428571432e-05, 'epoch': 1.03}\n",
      "{'loss': 0.3213, 'learning_rate': 2.6785714285714288e-05, 'epoch': 1.04}\n",
      "{'loss': 0.2845, 'learning_rate': 2.6674107142857147e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3522, 'learning_rate': 2.6562500000000002e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3593, 'learning_rate': 2.6450892857142857e-05, 'epoch': 1.05}\n",
      "{'loss': 0.3272, 'learning_rate': 2.6339285714285716e-05, 'epoch': 1.05}\n",
      "{'loss': 0.37, 'learning_rate': 2.622767857142857e-05, 'epoch': 1.06}\n",
      "{'loss': 0.3446, 'learning_rate': 2.611607142857143e-05, 'epoch': 1.06}\n",
      "{'loss': 0.2778, 'learning_rate': 2.6004464285714286e-05, 'epoch': 1.06}\n",
      "{'loss': 0.3237, 'learning_rate': 2.5892857142857148e-05, 'epoch': 1.07}\n",
      "{'loss': 0.2898, 'learning_rate': 2.578125e-05, 'epoch': 1.07}\n",
      "{'loss': 0.2982, 'learning_rate': 2.5669642857142855e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3097, 'learning_rate': 2.5558035714285717e-05, 'epoch': 1.08}\n",
      "{'loss': 0.346, 'learning_rate': 2.544642857142857e-05, 'epoch': 1.08}\n",
      "{'loss': 0.2702, 'learning_rate': 2.533482142857143e-05, 'epoch': 1.09}\n",
      "{'loss': 0.2623, 'learning_rate': 2.5223214285714287e-05, 'epoch': 1.09}\n",
      "{'loss': 0.3126, 'learning_rate': 2.5111607142857146e-05, 'epoch': 1.1}\n",
      "{'loss': 0.3404, 'learning_rate': 2.5e-05, 'epoch': 1.1}\n",
      "{'loss': 0.2683, 'learning_rate': 2.488839285714286e-05, 'epoch': 1.1}\n",
      "{'loss': 0.2831, 'learning_rate': 2.4776785714285715e-05, 'epoch': 1.11}\n",
      "{'loss': 0.291, 'learning_rate': 2.4665178571428574e-05, 'epoch': 1.11}\n",
      "{'loss': 0.2759, 'learning_rate': 2.455357142857143e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3291, 'learning_rate': 2.4441964285714285e-05, 'epoch': 1.12}\n",
      "{'loss': 0.316, 'learning_rate': 2.4330357142857144e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3078, 'learning_rate': 2.4218750000000003e-05, 'epoch': 1.13}\n",
      "{'loss': 0.2727, 'learning_rate': 2.4107142857142858e-05, 'epoch': 1.13}\n",
      "{'loss': 0.3309, 'learning_rate': 2.3995535714285717e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3245, 'learning_rate': 2.3883928571428572e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2491, 'learning_rate': 2.3772321428571428e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2933, 'learning_rate': 2.3660714285714286e-05, 'epoch': 1.15}\n",
      "{'loss': 0.2664, 'learning_rate': 2.3549107142857145e-05, 'epoch': 1.15}\n",
      "{'loss': 0.3431, 'learning_rate': 2.34375e-05, 'epoch': 1.16}\n",
      "{'loss': 0.2618, 'learning_rate': 2.332589285714286e-05, 'epoch': 1.16}\n",
      "{'loss': 0.3205, 'learning_rate': 2.3214285714285715e-05, 'epoch': 1.16}\n",
      "{'loss': 0.2893, 'learning_rate': 2.3102678571428573e-05, 'epoch': 1.17}\n",
      "{'loss': 0.3348, 'learning_rate': 2.299107142857143e-05, 'epoch': 1.17}\n",
      "{'loss': 0.2578, 'learning_rate': 2.2879464285714288e-05, 'epoch': 1.18}\n",
      "{'loss': 0.3006, 'learning_rate': 2.2767857142857143e-05, 'epoch': 1.18}\n",
      "{'loss': 0.3072, 'learning_rate': 2.2656250000000002e-05, 'epoch': 1.18}\n",
      "{'loss': 0.2329, 'learning_rate': 2.2544642857142857e-05, 'epoch': 1.19}\n",
      "{'loss': 0.2603, 'learning_rate': 2.2433035714285716e-05, 'epoch': 1.19}\n",
      "{'loss': 0.3002, 'learning_rate': 2.2321428571428575e-05, 'epoch': 1.2}\n",
      "{'loss': 0.3206, 'learning_rate': 2.2209821428571427e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2892, 'learning_rate': 2.2098214285714286e-05, 'epoch': 1.2}\n",
      "{'loss': 0.3224, 'learning_rate': 2.1986607142857144e-05, 'epoch': 1.21}\n",
      "{'loss': 0.2585, 'learning_rate': 2.1875e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3062, 'learning_rate': 2.176339285714286e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2559, 'learning_rate': 2.1651785714285717e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2849, 'learning_rate': 2.1540178571428573e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2732, 'learning_rate': 2.1428571428571428e-05, 'epoch': 1.23}\n",
      "{'loss': 0.3336, 'learning_rate': 2.1316964285714287e-05, 'epoch': 1.23}\n",
      "{'loss': 0.2978, 'learning_rate': 2.1205357142857142e-05, 'epoch': 1.24}\n",
      "{'loss': 0.2925, 'learning_rate': 2.109375e-05, 'epoch': 1.24}\n",
      "{'loss': 0.2861, 'learning_rate': 2.098214285714286e-05, 'epoch': 1.24}\n",
      "{'loss': 0.3085, 'learning_rate': 2.0870535714285715e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2833, 'learning_rate': 2.0758928571428574e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2585, 'learning_rate': 2.064732142857143e-05, 'epoch': 1.26}\n",
      "{'loss': 0.2468, 'learning_rate': 2.0535714285714285e-05, 'epoch': 1.26}\n",
      "{'loss': 0.3423, 'learning_rate': 2.0424107142857144e-05, 'epoch': 1.27}\n",
      "{'loss': 0.2844, 'learning_rate': 2.0312500000000002e-05, 'epoch': 1.27}\n",
      "{'loss': 0.2304, 'learning_rate': 2.0200892857142858e-05, 'epoch': 1.27}\n",
      "{'loss': 0.2907, 'learning_rate': 2.0089285714285717e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2922, 'learning_rate': 1.9977678571428572e-05, 'epoch': 1.28}\n",
      "{'loss': 0.3107, 'learning_rate': 1.9866071428571427e-05, 'epoch': 1.29}\n",
      "{'loss': 0.2547, 'learning_rate': 1.9754464285714286e-05, 'epoch': 1.29}\n",
      "{'loss': 0.2848, 'learning_rate': 1.9642857142857145e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3067, 'learning_rate': 1.953125e-05, 'epoch': 1.3}\n",
      "{'loss': 0.2611, 'learning_rate': 1.941964285714286e-05, 'epoch': 1.3}\n",
      "{'loss': 0.2491, 'learning_rate': 1.9308035714285715e-05, 'epoch': 1.31}\n",
      "{'loss': 0.2698, 'learning_rate': 1.9196428571428573e-05, 'epoch': 1.31}\n",
      "{'loss': 0.224, 'learning_rate': 1.908482142857143e-05, 'epoch': 1.31}\n",
      "{'loss': 0.2604, 'learning_rate': 1.8973214285714284e-05, 'epoch': 1.32}\n",
      "{'loss': 0.1988, 'learning_rate': 1.8861607142857143e-05, 'epoch': 1.32}\n",
      "{'loss': 0.2802, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.33}\n",
      "{'loss': 0.2752, 'learning_rate': 1.8638392857142857e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1963, 'learning_rate': 1.8526785714285716e-05, 'epoch': 1.33}\n",
      "{'loss': 0.2811, 'learning_rate': 1.8415178571428575e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2546, 'learning_rate': 1.8303571428571427e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2526, 'learning_rate': 1.8191964285714286e-05, 'epoch': 1.35}\n",
      "{'loss': 0.2852, 'learning_rate': 1.8080357142857144e-05, 'epoch': 1.35}\n",
      "{'loss': 0.299, 'learning_rate': 1.796875e-05, 'epoch': 1.35}\n",
      "{'loss': 0.2313, 'learning_rate': 1.785714285714286e-05, 'epoch': 1.36}\n",
      "{'loss': 0.2219, 'learning_rate': 1.7745535714285717e-05, 'epoch': 1.36}\n",
      "{'loss': 0.2612, 'learning_rate': 1.7633928571428573e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2728, 'learning_rate': 1.7522321428571428e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2406, 'learning_rate': 1.7410714285714287e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2398, 'learning_rate': 1.7299107142857142e-05, 'epoch': 1.38}\n",
      "{'loss': 0.2539, 'learning_rate': 1.71875e-05, 'epoch': 1.38}\n",
      "{'loss': 0.2334, 'learning_rate': 1.707589285714286e-05, 'epoch': 1.39}\n",
      "{'loss': 0.2357, 'learning_rate': 1.6964285714285715e-05, 'epoch': 1.39}\n",
      "{'loss': 0.2302, 'learning_rate': 1.6852678571428574e-05, 'epoch': 1.39}\n",
      "{'loss': 0.2363, 'learning_rate': 1.674107142857143e-05, 'epoch': 1.4}\n",
      "{'loss': 0.2306, 'learning_rate': 1.6629464285714285e-05, 'epoch': 1.4}\n",
      "{'loss': 0.2197, 'learning_rate': 1.6517857142857144e-05, 'epoch': 1.41}\n",
      "{'loss': 0.2467, 'learning_rate': 1.6406250000000002e-05, 'epoch': 1.41}\n",
      "{'loss': 0.2463, 'learning_rate': 1.6294642857142858e-05, 'epoch': 1.41}\n",
      "{'loss': 0.2558, 'learning_rate': 1.6183035714285717e-05, 'epoch': 1.42}\n",
      "{'loss': 0.2783, 'learning_rate': 1.6071428571428572e-05, 'epoch': 1.42}\n",
      "{'loss': 0.2558, 'learning_rate': 1.5959821428571427e-05, 'epoch': 1.43}\n",
      "{'loss': 0.2695, 'learning_rate': 1.5848214285714286e-05, 'epoch': 1.43}\n",
      "{'loss': 0.2633, 'learning_rate': 1.573660714285714e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1373, 'learning_rate': 1.5625e-05, 'epoch': 1.44}\n",
      "{'loss': 0.2193, 'learning_rate': 1.551339285714286e-05, 'epoch': 1.44}\n",
      "{'loss': 0.2748, 'learning_rate': 1.5401785714285715e-05, 'epoch': 1.45}\n",
      "{'loss': 0.3123, 'learning_rate': 1.5290178571428573e-05, 'epoch': 1.45}\n",
      "{'loss': 0.3373, 'learning_rate': 1.5178571428571429e-05, 'epoch': 1.45}\n",
      "{'loss': 0.2239, 'learning_rate': 1.5066964285714286e-05, 'epoch': 1.46}\n",
      "{'loss': 0.2429, 'learning_rate': 1.4955357142857143e-05, 'epoch': 1.46}\n",
      "{'loss': 0.251, 'learning_rate': 1.484375e-05, 'epoch': 1.47}\n",
      "{'loss': 0.265, 'learning_rate': 1.4732142857142859e-05, 'epoch': 1.47}\n",
      "{'loss': 0.243, 'learning_rate': 1.4620535714285716e-05, 'epoch': 1.47}\n",
      "{'loss': 0.2516, 'learning_rate': 1.4508928571428573e-05, 'epoch': 1.48}\n",
      "{'loss': 0.2358, 'learning_rate': 1.4397321428571428e-05, 'epoch': 1.48}\n",
      "{'loss': 0.2118, 'learning_rate': 1.4285714285714285e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2333, 'learning_rate': 1.4174107142857143e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2798, 'learning_rate': 1.4062500000000001e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2061, 'learning_rate': 1.3950892857142858e-05, 'epoch': 1.5}\n",
      "{'loss': 0.2862, 'learning_rate': 1.3839285714285715e-05, 'epoch': 1.5}\n",
      "{'loss': 0.2238, 'learning_rate': 1.3727678571428573e-05, 'epoch': 1.51}\n",
      "{'loss': 0.2082, 'learning_rate': 1.3616071428571428e-05, 'epoch': 1.51}\n",
      "{'loss': 0.2689, 'learning_rate': 1.3504464285714285e-05, 'epoch': 1.51}\n",
      "{'loss': 0.1985, 'learning_rate': 1.3392857142857144e-05, 'epoch': 1.52}\n",
      "{'loss': 0.232, 'learning_rate': 1.3281250000000001e-05, 'epoch': 1.52}\n",
      "{'loss': 0.2393, 'learning_rate': 1.3169642857142858e-05, 'epoch': 1.53}\n",
      "{'loss': 0.2087, 'learning_rate': 1.3058035714285715e-05, 'epoch': 1.53}\n",
      "{'loss': 0.1768, 'learning_rate': 1.2946428571428574e-05, 'epoch': 1.53}\n",
      "{'loss': 0.1966, 'learning_rate': 1.2834821428571428e-05, 'epoch': 1.54}\n",
      "{'loss': 0.2151, 'learning_rate': 1.2723214285714285e-05, 'epoch': 1.54}\n",
      "{'loss': 0.2361, 'learning_rate': 1.2611607142857144e-05, 'epoch': 1.55}\n",
      "{'loss': 0.1939, 'learning_rate': 1.25e-05, 'epoch': 1.55}\n",
      "{'loss': 0.1901, 'learning_rate': 1.2388392857142858e-05, 'epoch': 1.55}\n",
      "{'loss': 0.2403, 'learning_rate': 1.2276785714285715e-05, 'epoch': 1.56}\n",
      "{'loss': 0.2144, 'learning_rate': 1.2165178571428572e-05, 'epoch': 1.56}\n",
      "{'loss': 0.2426, 'learning_rate': 1.2053571428571429e-05, 'epoch': 1.57}\n",
      "{'loss': 0.1984, 'learning_rate': 1.1941964285714286e-05, 'epoch': 1.57}\n",
      "{'loss': 0.2171, 'learning_rate': 1.1830357142857143e-05, 'epoch': 1.57}\n",
      "{'loss': 0.1812, 'learning_rate': 1.171875e-05, 'epoch': 1.58}\n",
      "{'loss': 0.242, 'learning_rate': 1.1607142857142857e-05, 'epoch': 1.58}\n",
      "{'loss': 0.3196, 'learning_rate': 1.1495535714285714e-05, 'epoch': 1.59}\n",
      "{'loss': 0.293, 'learning_rate': 1.1383928571428572e-05, 'epoch': 1.59}\n",
      "{'loss': 0.2594, 'learning_rate': 1.1272321428571429e-05, 'epoch': 1.59}\n",
      "{'loss': 0.2279, 'learning_rate': 1.1160714285714287e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2241, 'learning_rate': 1.1049107142857143e-05, 'epoch': 1.6}\n",
      "{'loss': 0.255, 'learning_rate': 1.09375e-05, 'epoch': 1.61}\n",
      "{'loss': 0.1972, 'learning_rate': 1.0825892857142859e-05, 'epoch': 1.61}\n",
      "{'loss': 0.1904, 'learning_rate': 1.0714285714285714e-05, 'epoch': 1.61}\n",
      "{'loss': 0.2202, 'learning_rate': 1.0602678571428571e-05, 'epoch': 1.62}\n",
      "{'loss': 0.2647, 'learning_rate': 1.049107142857143e-05, 'epoch': 1.62}\n",
      "{'loss': 0.2246, 'learning_rate': 1.0379464285714287e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2053, 'learning_rate': 1.0267857142857142e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2821, 'learning_rate': 1.0156250000000001e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2418, 'learning_rate': 1.0044642857142858e-05, 'epoch': 1.64}\n",
      "{'loss': 0.2477, 'learning_rate': 9.933035714285714e-06, 'epoch': 1.64}\n",
      "{'loss': 0.2115, 'learning_rate': 9.821428571428573e-06, 'epoch': 1.65}\n",
      "{'loss': 0.2334, 'learning_rate': 9.70982142857143e-06, 'epoch': 1.65}\n",
      "{'loss': 0.2074, 'learning_rate': 9.598214285714287e-06, 'epoch': 1.65}\n",
      "{'loss': 0.2103, 'learning_rate': 9.486607142857142e-06, 'epoch': 1.66}\n",
      "{'loss': 0.1929, 'learning_rate': 9.375000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 0.2579, 'learning_rate': 9.263392857142858e-06, 'epoch': 1.67}\n",
      "{'loss': 0.2595, 'learning_rate': 9.151785714285713e-06, 'epoch': 1.67}\n",
      "{'loss': 0.2808, 'learning_rate': 9.040178571428572e-06, 'epoch': 1.67}\n",
      "{'loss': 0.2697, 'learning_rate': 8.92857142857143e-06, 'epoch': 1.68}\n",
      "{'loss': 0.2078, 'learning_rate': 8.816964285714286e-06, 'epoch': 1.68}\n",
      "{'loss': 0.2063, 'learning_rate': 8.705357142857143e-06, 'epoch': 1.69}\n",
      "{'loss': 0.1904, 'learning_rate': 8.59375e-06, 'epoch': 1.69}\n",
      "{'loss': 0.1946, 'learning_rate': 8.482142857142858e-06, 'epoch': 1.69}\n",
      "{'loss': 0.1915, 'learning_rate': 8.370535714285715e-06, 'epoch': 1.7}\n",
      "{'loss': 0.1964, 'learning_rate': 8.258928571428572e-06, 'epoch': 1.7}\n",
      "{'loss': 0.2611, 'learning_rate': 8.147321428571429e-06, 'epoch': 1.71}\n",
      "{'loss': 0.2401, 'learning_rate': 8.035714285714286e-06, 'epoch': 1.71}\n",
      "{'loss': 0.243, 'learning_rate': 7.924107142857143e-06, 'epoch': 1.71}\n",
      "{'loss': 0.2343, 'learning_rate': 7.8125e-06, 'epoch': 1.72}\n",
      "{'loss': 0.206, 'learning_rate': 7.700892857142857e-06, 'epoch': 1.72}\n",
      "{'loss': 0.2129, 'learning_rate': 7.589285714285714e-06, 'epoch': 1.73}\n",
      "{'loss': 0.2009, 'learning_rate': 7.4776785714285714e-06, 'epoch': 1.73}\n",
      "{'loss': 0.2434, 'learning_rate': 7.366071428571429e-06, 'epoch': 1.73}\n",
      "{'loss': 0.2069, 'learning_rate': 7.2544642857142865e-06, 'epoch': 1.74}\n",
      "{'loss': 0.1976, 'learning_rate': 7.142857142857143e-06, 'epoch': 1.74}\n",
      "{'loss': 0.2816, 'learning_rate': 7.031250000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 0.2288, 'learning_rate': 6.919642857142858e-06, 'epoch': 1.75}\n",
      "{'loss': 0.2018, 'learning_rate': 6.808035714285714e-06, 'epoch': 1.76}\n",
      "{'loss': 0.2553, 'learning_rate': 6.696428571428572e-06, 'epoch': 1.76}\n",
      "{'loss': 0.2379, 'learning_rate': 6.584821428571429e-06, 'epoch': 1.76}\n",
      "{'loss': 0.1795, 'learning_rate': 6.473214285714287e-06, 'epoch': 1.77}\n",
      "{'loss': 0.1949, 'learning_rate': 6.361607142857142e-06, 'epoch': 1.77}\n",
      "{'loss': 0.2013, 'learning_rate': 6.25e-06, 'epoch': 1.78}\n",
      "{'loss': 0.1921, 'learning_rate': 6.138392857142857e-06, 'epoch': 1.78}\n",
      "{'loss': 0.2073, 'learning_rate': 6.0267857142857145e-06, 'epoch': 1.78}\n",
      "{'loss': 0.265, 'learning_rate': 5.9151785714285716e-06, 'epoch': 1.79}\n",
      "{'loss': 0.2083, 'learning_rate': 5.803571428571429e-06, 'epoch': 1.79}\n",
      "{'loss': 0.2, 'learning_rate': 5.691964285714286e-06, 'epoch': 1.8}\n",
      "{'loss': 0.2184, 'learning_rate': 5.580357142857144e-06, 'epoch': 1.8}\n",
      "{'loss': 0.2127, 'learning_rate': 5.46875e-06, 'epoch': 1.8}\n",
      "{'loss': 0.2356, 'learning_rate': 5.357142857142857e-06, 'epoch': 1.81}\n",
      "{'loss': 0.1872, 'learning_rate': 5.245535714285715e-06, 'epoch': 1.81}\n",
      "{'loss': 0.2123, 'learning_rate': 5.133928571428571e-06, 'epoch': 1.82}\n",
      "{'loss': 0.2052, 'learning_rate': 5.022321428571429e-06, 'epoch': 1.82}\n",
      "{'loss': 0.2087, 'learning_rate': 4.910714285714286e-06, 'epoch': 1.82}\n",
      "{'loss': 0.2294, 'learning_rate': 4.799107142857143e-06, 'epoch': 1.83}\n",
      "{'loss': 0.2143, 'learning_rate': 4.6875000000000004e-06, 'epoch': 1.83}\n",
      "{'loss': 0.1866, 'learning_rate': 4.575892857142857e-06, 'epoch': 1.84}\n",
      "{'loss': 0.2095, 'learning_rate': 4.464285714285715e-06, 'epoch': 1.84}\n",
      "{'loss': 0.2131, 'learning_rate': 4.352678571428572e-06, 'epoch': 1.84}\n",
      "{'loss': 0.2355, 'learning_rate': 4.241071428571429e-06, 'epoch': 1.85}\n",
      "{'loss': 0.202, 'learning_rate': 4.129464285714286e-06, 'epoch': 1.85}\n",
      "{'loss': 0.1743, 'learning_rate': 4.017857142857143e-06, 'epoch': 1.86}\n",
      "{'loss': 0.1864, 'learning_rate': 3.90625e-06, 'epoch': 1.86}\n",
      "{'loss': 0.1819, 'learning_rate': 3.794642857142857e-06, 'epoch': 1.86}\n",
      "{'loss': 0.1966, 'learning_rate': 3.6830357142857147e-06, 'epoch': 1.87}\n",
      "{'loss': 0.1945, 'learning_rate': 3.5714285714285714e-06, 'epoch': 1.87}\n",
      "{'loss': 0.2332, 'learning_rate': 3.459821428571429e-06, 'epoch': 1.88}\n",
      "{'loss': 0.2208, 'learning_rate': 3.348214285714286e-06, 'epoch': 1.88}\n",
      "{'loss': 0.2171, 'learning_rate': 3.2366071428571435e-06, 'epoch': 1.88}\n",
      "{'loss': 0.1853, 'learning_rate': 3.125e-06, 'epoch': 1.89}\n",
      "{'loss': 0.2734, 'learning_rate': 3.0133928571428572e-06, 'epoch': 1.89}\n",
      "{'loss': 0.1567, 'learning_rate': 2.9017857142857143e-06, 'epoch': 1.9}\n",
      "{'loss': 0.1899, 'learning_rate': 2.790178571428572e-06, 'epoch': 1.9}\n",
      "{'loss': 0.2244, 'learning_rate': 2.6785714285714285e-06, 'epoch': 1.9}\n",
      "{'loss': 0.1685, 'learning_rate': 2.5669642857142856e-06, 'epoch': 1.91}\n",
      "{'loss': 0.2561, 'learning_rate': 2.455357142857143e-06, 'epoch': 1.91}\n",
      "{'loss': 0.2309, 'learning_rate': 2.3437500000000002e-06, 'epoch': 1.92}\n",
      "{'loss': 0.1941, 'learning_rate': 2.2321428571428573e-06, 'epoch': 1.92}\n",
      "{'loss': 0.2215, 'learning_rate': 2.1205357142857144e-06, 'epoch': 1.92}\n",
      "{'loss': 0.2467, 'learning_rate': 2.0089285714285715e-06, 'epoch': 1.93}\n",
      "{'loss': 0.1968, 'learning_rate': 1.8973214285714286e-06, 'epoch': 1.93}\n",
      "{'loss': 0.2112, 'learning_rate': 1.7857142857142857e-06, 'epoch': 1.94}\n",
      "{'loss': 0.2175, 'learning_rate': 1.674107142857143e-06, 'epoch': 1.94}\n",
      "{'loss': 0.2204, 'learning_rate': 1.5625e-06, 'epoch': 1.94}\n",
      "{'loss': 0.2563, 'learning_rate': 1.4508928571428572e-06, 'epoch': 1.95}\n",
      "{'loss': 0.2337, 'learning_rate': 1.3392857142857143e-06, 'epoch': 1.95}\n",
      "{'loss': 0.2456, 'learning_rate': 1.2276785714285716e-06, 'epoch': 1.96}\n",
      "{'loss': 0.2386, 'learning_rate': 1.1160714285714287e-06, 'epoch': 1.96}\n",
      "{'loss': 0.2474, 'learning_rate': 1.0044642857142857e-06, 'epoch': 1.96}\n",
      "{'loss': 0.2587, 'learning_rate': 8.928571428571428e-07, 'epoch': 1.97}\n",
      "{'loss': 0.276, 'learning_rate': 7.8125e-07, 'epoch': 1.97}\n",
      "{'loss': 0.1897, 'learning_rate': 6.696428571428571e-07, 'epoch': 1.98}\n",
      "{'loss': 0.1927, 'learning_rate': 5.580357142857143e-07, 'epoch': 1.98}\n",
      "{'loss': 0.2184, 'learning_rate': 4.464285714285714e-07, 'epoch': 1.98}\n",
      "{'loss': 0.1984, 'learning_rate': 3.3482142857142856e-07, 'epoch': 1.99}\n",
      "{'loss': 0.2439, 'learning_rate': 2.232142857142857e-07, 'epoch': 1.99}\n",
      "{'loss': 0.1983, 'learning_rate': 1.1160714285714285e-07, 'epoch': 2.0}\n",
      "{'loss': 0.2783, 'learning_rate': 0.0, 'epoch': 2.0}\n",
      "[*] Evaluation_loop\n",
      "[*] Step 0 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3693, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBAR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: S[+]VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WHNP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SINV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]QP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBAR[+]S[+]VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBAR[+]S seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: QP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -NONE- seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WHADVP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADVP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]NP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 1 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3280, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VP[+]VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 2 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3087, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 19 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WHPP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FRAG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 3 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2784, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UCP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADVP[+]ADVP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 4 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2946, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJP[+]QP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SQ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LST seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 5 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3199, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 6 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.5683, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 20 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 21 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: S[+]NP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJP[+]ADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 7 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2509, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 8 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1444, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBARQ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 9 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2663, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: S[+]ADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WHADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 10 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1664, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 11 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3641, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRN[+]S seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 12 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3470, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 13 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2660, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 14 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3264, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 15 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1538, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 16 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1521, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 17 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2602, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 18 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1518, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 19 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1658, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SBAR[+]SINV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 20 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1681, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 21 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2154, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 22 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1856, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 22 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 23 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 24 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 23 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1988, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 24 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3587, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]VBN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 25 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2176, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 26 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1416, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 27 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3173, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SQ[+]VP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 28 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2307, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 29 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3521, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 30 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3753, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 31 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3334, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 32 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3719, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 33 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2076, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 34 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3212, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRN[+]SINV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 35 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1793, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 36 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2190, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 37 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3507, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 38 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2274, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 39 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3072, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FRAG[+]NP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 40 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2286, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 41 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2812, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 42 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1381, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FRAG[+]ADJP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Step 43 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2012, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 44 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2577, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 45 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2010, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 46 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3803, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 47 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1784, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 48 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3242, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 49 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2089, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 50 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2270, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 51 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1748, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 52 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2951, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 53 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1930, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 54 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3059, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]NP[+]QP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 55 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2715, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 56 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2833, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 57 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2679, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 58 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1922, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 59 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3535, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 60 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3178, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 61 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2330, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 62 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2871, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 63 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2973, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]NNS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 64 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3212, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 65 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3210, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 66 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1958, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 67 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1398, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 68 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2182, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 69 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3739, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 70 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1976, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 71 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2099, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 72 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2597, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 73 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3702, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FRAG[+]ADVP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 74 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2898, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 75 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3510, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NP[+]SBAR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 76 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2481, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 77 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1869, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 78 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1616, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 79 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1850, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 80 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1827, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 81 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2683, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 82 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2856, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 83 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2026, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 84 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3323, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 85 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2103, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 86 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2048, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 87 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2460, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 88 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3433, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 89 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2794, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 90 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2320, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 91 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2418, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 92 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.1820, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 93 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2273, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 94 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2689, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 95 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2004, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 96 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3164, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 97 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2409, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 98 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3401, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 99 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2754, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 100 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2383, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 101 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2661, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 102 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2938, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 103 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3673, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: S[+]PP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 104 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.2122, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 105 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.3855, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droca1/.conda/envs/tf/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VP[+]PP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing metrics for subtask target_3 ...\n",
      "[*] Step 106 of 107 ...\n",
      "[*] Prediction Step\n",
      "[*] Loss: tensor(0.4440, device='cuda:0')\n",
      "[*] Evaluating task: naive_absolute_n_commons\n",
      "[*] Computing metrics for subtask target_1 ...\n",
      "[*] Computing metrics for subtask target_2 ...\n",
      "[*] Computing metrics for subtask target_3 ...\n",
      "{'eval_precision': 0.9583333333333334, 'eval_recall': 0.9583333333333334, 'eval_f1': 0.9583333333333334, 'eval_accuracy': 0.9921259842519685, 'eval_name': 'naive_absolute_n_commons', 'eval_size': 4, 'eval_index': 0, 'eval_runtime': 284.9026, 'eval_samples_per_second': 0.004, 'eval_steps_per_second': 0.004, 'epoch': 2.0}\n",
      "{'eval_precision': 0.9583333333333334, 'eval_recall': 0.9583333333333334, 'eval_f1': 0.9583333333333334, 'eval_accuracy': 0.9921259842519685, 'eval_name': 'naive_absolute_n_commons', 'eval_size': 4, 'eval_index': 0, 'eval_runtime': 284.9026, 'eval_samples_per_second': 0.004, 'eval_steps_per_second': 0.004, 'epoch': 2.0}\n",
      "{'train_runtime': 2295.593, 'train_samples_per_second': 34.703, 'train_steps_per_second': 2.169, 'train_loss': 0.42515791460692165, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# import trainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# train and evaluate using Evalb\n",
    "encodings = gen_dsets()\n",
    "results = {}\n",
    "max_seq_len = 128\n",
    "train_limit = None\n",
    "model_name = \"bert-base-cased\"\n",
    "\n",
    "# probably this could be done in parallel\n",
    "for enc in encodings[:1]:\n",
    "    results_df = pd.DataFrame(columns=[\"encoding\", \"recall\", \"precision\", \"f1\", \"n_labels\"])\n",
    "    encoder = enc[\"encoder\"]\n",
    "    \n",
    "    train_enc, mlt1 = encode_dset(encoder, ptb_train[:train_limit] if train_limit else ptb_train)\n",
    "    dev_enc,   mlt2   = encode_dset(encoder, ptb_dev[:train_limit]   if train_limit else ptb_dev)\n",
    "    dataset  = generate_dataset_from_codelin(train_enc, dev_enc)\n",
    "    \n",
    "    print(\"[*] Sample encoded sentence\")\n",
    "    print(\"   \",train_enc['tokens'][0])\n",
    "    print(\"   \",train_enc['target_1'][0])\n",
    "    print(\"   \",train_enc['target_2'][0])\n",
    "    print(\"   \",train_enc['target_3'][0])\n",
    "\n",
    "    tasks = [TokenClassification(\n",
    "                dataset = dataset,\n",
    "                y = [\"target_1\", \"target_2\", \"target_3\"],\n",
    "                name = enc[\"name\"]+\"_n_commons\",\n",
    "                tokenizer_kwargs = frozendict(padding=\"max_length\", max_length = max_seq_len, truncation=True)\n",
    "            )]\n",
    "    \n",
    "    model = MultiTaskModel(model_name, tasks)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = f\"results/{enc['name']}\",\n",
    "        num_train_epochs = 2,\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 8,\n",
    "        warmup_steps = 500,\n",
    "        weight_decay = 0.01,\n",
    "        logging_dir = f\"results/{enc['name']}/logs\",\n",
    "        logging_steps = 10,\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        save_strategy = \"epoch\",\n",
    "        load_best_model_at_end = True,\n",
    "        metric_for_best_model = \"f1\",\n",
    "        greater_is_better = True,\n",
    "        save_total_limit = 1,\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    "\n",
    "    train_dataset = model.train_dataset\n",
    "    trainer = MultiTaskTrainer(\n",
    "        model = model,\n",
    "        tasks = tasks,\n",
    "        args = training_args,\n",
    "        train_dataset = model.train_dataset,\n",
    "        eval_dataset = model.eval_dataset,\n",
    "        compute_metrics = None,\n",
    "        tokenizer = model.tokenizer\n",
    "    )\n",
    "    \n",
    "    trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f6a80f18e31b3afbf65f4c0ba16ab618b75d927e0f96f1f2ebf3c840526a5fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
