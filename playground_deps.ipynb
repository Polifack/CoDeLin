{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Linearization Playground"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "smallest_non_projective = 3992\n",
    "tree = trees[smallest_non_projective]\n",
    "\n",
    "encoder = D_Brk7BitsEncoding()\n",
    "bits = D_Brk7BitsEncoding.labels_to_bits(encoder.encode(tree).labels)\n",
    "bracket_bits = []\n",
    "for b in bits:\n",
    "    b_str = [str(i) for i in b]\n",
    "    bracket_bits.append(\"\".join(b_str))\n",
    "\n",
    "print(D_Tree.to_latex(tree, include_col=False, planar_separate=True, planar_colors=['black', 'red'], additional_labels=bracket_bits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=True)\n",
    "\n",
    "target_tree = 0\n",
    "n_skips = 2 # just in case the tree is not good\n",
    "for i,tree in enumerate(trees):\n",
    "    if len(tree) == 8:\n",
    "        if n_skips>0:\n",
    "            n_skips-=1\n",
    "            continue\n",
    "        \n",
    "        target_tree = i\n",
    "        break\n",
    "\n",
    "tree = trees[target_tree]\n",
    "\n",
    "encoder = D_Brk4BitsEncoding()\n",
    "\n",
    "brackets = [str(i.xi) for i in  encoder.encode(tree).labels]\n",
    "\n",
    "bits = D_Brk4BitsEncoding.labels_to_bits(encoder.encode(tree).labels)\n",
    "bracket_bits = []\n",
    "for b in bits:\n",
    "    b_str = [str(i) for i in b]\n",
    "    bracket_bits.append(\"\".join(b_str))\n",
    "\n",
    "print(D_Tree.to_latex(tree, include_col=False, planar_separate=True, planar_colors=['black', 'red'], additional_labels=bracket_bits))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode with 4-bits encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "enc_7b = D_Brk7BitsEncoding(separator=\"_\")\n",
    "for i, sample_tree in enumerate(trees):\n",
    "    lin_tree = enc_7b.encode(sample_tree)\n",
    "    dec_tree = enc_7b.decode(lin_tree)\n",
    "    las = dec_tree.las_score(sample_tree)\n",
    "    \n",
    "    if las != 1:\n",
    "        print(\"Error at tree\",i,\"length\",len(sample_tree))\n",
    "        print(D_Tree.to_latex(sample_tree))\n",
    "        print(lin_tree)\n",
    "        print(\"LAS =\",dec_tree.las_score(sample_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "deps_treebank = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "sample_tree = trees[6114]\n",
    "enc_7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "lin_tree = enc_7b.encode(sample_tree)\n",
    "print(lin_tree)\n",
    "dec_tree = enc_7b.decode(lin_tree)\n",
    "print(\"LAS =\",dec_tree.las_score(sample_tree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planar extraction for all UD Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ UD-Spanish ] Processing /home/droca1/Treebanks/UD_Spanish-AnCora/UD_Spanish/test.conlluu\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>total trees</th>\n",
       "      <th>1-planar trees</th>\n",
       "      <th>projective trees</th>\n",
       "      <th>right dependants (%)</th>\n",
       "      <th>left dependants (%)</th>\n",
       "      <th>average dependants per head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UD-Spanish</td>\n",
       "      <td>17662</td>\n",
       "      <td>93.77194</td>\n",
       "      <td>93.766278</td>\n",
       "      <td>54.430832</td>\n",
       "      <td>45.569168</td>\n",
       "      <td>2.605713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Corpus total trees  1-planar trees  projective trees  \\\n",
       "0  UD-Spanish       17662        93.77194         93.766278   \n",
       "\n",
       "   right dependants (%)  left dependants (%)  average dependants per head  \n",
       "0             54.430832            45.569168                     2.605713  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path = \"/home/droca1/Treebanks/UD_Spanish-AnCora/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"total trees\",\"1-planar trees\",\"projective trees\",\"right dependants (%)\",\"left dependants (%)\",\"average dependants per head\"])\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    print(\"[    ] Processing\", ud_folder, end=\"\\r\")\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    \n",
    "    # get all conllu files in ud_folder\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        print(\"[\",treebank_name,\"] Processing\", conllu_file, end=\"\\r\")\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "        total_trees += trees\n",
    "    \n",
    "    proj                        = D_Tree.get_projectivity_percentage(total_trees)\n",
    "    planar1, planar2, planarN   = D_Tree.get_planarity_percentage(total_trees)\n",
    "    r_deps, l_deps              = D_Tree.get_dependency_direction_percentage(total_trees)\n",
    "    avg_dependants              = D_Tree.get_avg_dependants(total_trees)\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, len(total_trees), proj*100, planar1*100, r_deps*100, l_deps*100, avg_dependants]], columns=results_df.columns)])\n",
    "\n",
    "\n",
    "#print(results_df.to_latex(index=False, float_format=\"{:0.10}\".format))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "ptb_path=\"/home/droca1/Treebanks/20ag/PENN_TREEBANK/\"\n",
    "ptb_files = [os.path.join(ptb_path, f) for f in os.listdir(ptb_path) if f.endswith(\".conllu\")]\n",
    "total_trees = []\n",
    "\n",
    "for ptb_file in ptb_files:\n",
    "    trees = D_Tree.read_conllu_file(ptb_file)\n",
    "    total_trees += trees\n",
    "\n",
    "for tree in total_trees:\n",
    "    p1,p2 = D_Tree.two_planar_greedy(tree)\n",
    "    if len(p2) != 0 and len(p1) != 0:\n",
    "        print(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"BRK\", \"BRK2P\", \"BRK4B\", \"BRK7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = True)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = True)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    total_labels = {\"brk\":[], \"brk2p\":[], \"brk4b\":[], \"brk7b\":[]}\n",
    "    \n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                        filter_projective=False)\n",
    "        total_trees += trees\n",
    "        \n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk\"] += [str(lbl.xi) for lbl in t_brk.labels]\n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk7b\"] += [str(lbl.xi) for lbl in t_brk7b.labels]\n",
    "            t_brk_2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk2p\"] += [str(lbl.xi) for lbl in t_brk_2p.labels]\n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk4b\"] += [str(lbl.xi) for lbl in t_brk4b.labels]\n",
    "\n",
    "    \n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    \n",
    "    total_labels[\"brk\"] =   set(total_labels[\"brk\"])\n",
    "    total_labels[\"brk2p\"] = set(total_labels[\"brk2p\"])\n",
    "    total_labels[\"brk4b\"] = set(total_labels[\"brk4b\"])\n",
    "    total_labels[\"brk7b\"] = set(total_labels[\"brk7b\"])\n",
    "    \n",
    "    # remove none\n",
    "    print(total_labels[\"brk4b\"])\n",
    "    if \"NONE\" in total_labels[\"brk\"]:\n",
    "        total_labels[\"brk\"].remove(\"-NONE-\")\n",
    "    if \"-NONE-\" in total_labels[\"brk2p\"]:\n",
    "        total_labels[\"brk2p\"].remove(\"-NONE-\")\n",
    "    if \"-NONE-\" in total_labels[\"brk4b\"]:\n",
    "        total_labels[\"brk4b\"].remove(\"-NONE-\")\n",
    "    if \"-NONE-\" in total_labels[\"brk7b\"]:\n",
    "        total_labels[\"brk7b\"].remove(\"-NONE-\")\n",
    "    \n",
    "    total_labels[\"brk\"]   = len(total_labels[\"brk\"])\n",
    "    total_labels[\"brk2p\"] = len(total_labels[\"brk2p\"])\n",
    "    total_labels[\"brk4b\"] = len(total_labels[\"brk4b\"])\n",
    "    total_labels[\"brk7b\"] = len(total_labels[\"brk7b\"])\n",
    "\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, total_labels[\"brk\"], total_labels[\"brk2p\"], total_labels[\"brk4b\"], total_labels[\"brk7b\"]]],\n",
    "                                                        columns=[\"Corpus\",\"BRK\", \"BRK2P\", \"BRK4B\", \"BRK7B\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.8}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of dependency arcs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"BRK\", \"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = False)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = True)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    injective = {\"brk\":0.0, \"brk2p\":0.0, \"brk4b\":0.0, \"brk7b\":0.0}\n",
    "    \n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                        filter_projective=False)\n",
    "        total_trees += trees\n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            t_brk.remove_dummy()\n",
    "            t_brk_dec = ebrk.decode(t_brk)\n",
    "            injective[\"brk\"] += t_brk_dec.las_score(t)\n",
    "            \n",
    "            t_brk2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            t_brk2p.remove_dummy()\n",
    "            t_brk2p_dec = ebrk2p.decode(t_brk2p)\n",
    "            injective[\"brk2p\"] += t_brk2p_dec.las_score(t)\n",
    "            \n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            t_brk4b_dec = ebrk4b.decode(t_brk4b)\n",
    "            injective[\"brk4b\"] += t_brk4b_dec.las_score(t)\n",
    "            \n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            t_brk7b_dec = ebrk7b.decode(t_brk7b)\n",
    "            injective[\"brk7b\"] += t_brk7b_dec.las_score(t)\n",
    "    \n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, injective[\"brk\"]/len(total_trees), injective[\"brk2p\"]/len(total_trees), injective[\"brk4b\"]/len(total_trees), injective[\"brk7b\"]/len(total_trees)]],\n",
    "                                                        columns=[\"Corpus\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.8}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = False)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = False)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    injective = {\"brk\":0.0, \"brk2p\":0.0, \"brk4b\":0.0, \"brk7b\":0.0}\n",
    "    \n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank,filter_projective = False)\n",
    "        total_trees += trees\n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            t_brk.remove_dummy()\n",
    "            t_brk_dec = ebrk.decode(t_brk)\n",
    "            injective[\"brk\"] += 1 if t_brk_dec.las_score(t)==1 else 0\n",
    "            \n",
    "            t_brk2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            t_brk2p.remove_dummy()\n",
    "            t_brk2p_dec = ebrk2p.decode(t_brk2p)\n",
    "            injective[\"brk2p\"] += 1 if t_brk2p_dec.las_score(t)==1 else 0\n",
    "            \n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            t_brk4b_dec = ebrk4b.decode(t_brk4b)\n",
    "            injective[\"brk4b\"] += 1 if t_brk4b_dec.las_score(t)==1 else 0\n",
    "            \n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            t_brk7b_dec = ebrk7b.decode(t_brk7b)\n",
    "            injective[\"brk7b\"] += 1 if t_brk7b_dec.las_score(t)==1 else 0\n",
    "    \n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, injective[\"brk\"]/len(total_trees), injective[\"brk2p\"]/len(total_trees), injective[\"brk4b\"]/len(total_trees), injective[\"brk7b\"]/len(total_trees)]],\n",
    "                                                        columns=[\"Corpus\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.5}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different encodings coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# conllu_file = \"/home/poli/Treebanks/20ag/PTB/ptb-train.conllu\"\n",
    "conllu_file = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\", displacement = False)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "total_trees = []\n",
    "trees = D_Tree.read_conllu_file(conllu_file, filter_projective=False)\n",
    "\n",
    "for i,t in enumerate(trees):\n",
    "    t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "    t_brk.remove_dummy()\n",
    "    t_brk_dec = ebrk.decode(t_brk)\n",
    "    \n",
    "    t_brk_4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "    t_brk_4b_dec = ebrk4b.decode(t_brk_4b)\n",
    "    \n",
    "    if t.las_score(t_brk_dec) == 1 and t.las_score(t_brk_4b_dec) != 1:\n",
    "        print(\"Tree with BRK but not with BRK-4B: \",i)\n",
    "        t.remove_dummy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hexatag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Transform the dependency trees into binary head consituent trees\n",
    "2) Transform the BHT into hexatags shaped as [<arrow>_<reltype>] where arrow is the corresponding hexatag arrow and reltype is the relationship type for the word whose index is being parsed\n",
    "3) Implement decoding operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m trees:\n\u001b[1;32m     20\u001b[0m     lin_tree \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mencode(sample)\n\u001b[0;32m---> 21\u001b[0m     encoder\u001b[39m.\u001b[39;49mdecode(lin_tree)\n",
      "File \u001b[0;32m~/CoDeLin/codelin/encs/enc_deps/hexatag.py:28\u001b[0m, in \u001b[0;36mD_HexatagEncoding.decode\u001b[0;34m(self, lin_tree)\u001b[0m\n\u001b[1;32m     26\u001b[0m tagger \u001b[39m=\u001b[39m C_Tetratag(separator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseparator, unary_joiner\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minorder\u001b[39m\u001b[39m\"\u001b[39m, binary_marker\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[b]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m bht_tree \u001b[39m=\u001b[39m tagger\u001b[39m.\u001b[39mdecode(lin_tree)\n\u001b[0;32m---> 28\u001b[0m dectree \u001b[39m=\u001b[39m D_Tree\u001b[39m.\u001b[39mfrom_bht(bht_tree)\n\u001b[1;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m dectree\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:814\u001b[0m, in \u001b[0;36mD_Tree.from_bht\u001b[0;34m(bht)\u001b[0m\n\u001b[1;32m    811\u001b[0m     i\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    812\u001b[0m idx_words \u001b[39m=\u001b[39m {value: key \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m word_idxs\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 814\u001b[0m from_bht_rec(bht)\n\u001b[1;32m    815\u001b[0m \u001b[39m# sort nodes by id\u001b[39;00m\n\u001b[1;32m    816\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(nodes, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mid)\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:777\u001b[0m, in \u001b[0;36mD_Tree.from_bht.<locals>.from_bht_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[1;32m    776\u001b[0m left  \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 777\u001b[0m right \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39;49mchildren[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mlabel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    780\u001b[0m     \u001b[39m# L => head to the left and dependant to the right\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     node_head      \u001b[39m=\u001b[39m word_idxs[left]   \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(left) \u001b[39mis\u001b[39;00m C_Tree \u001b[39melse\u001b[39;00m \u001b[39mint\u001b[39m(left\u001b[39m.\u001b[39mhead)\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:776\u001b[0m, in \u001b[0;36mD_Tree.from_bht.<locals>.from_bht_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mis_preterminal():\n\u001b[1;32m    774\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 776\u001b[0m left  \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39;49mchildren[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    777\u001b[0m right \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39mchildren[\u001b[39m1\u001b[39m])\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mlabel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    780\u001b[0m     \u001b[39m# L => head to the left and dependant to the right\u001b[39;00m\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:777\u001b[0m, in \u001b[0;36mD_Tree.from_bht.<locals>.from_bht_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[1;32m    776\u001b[0m left  \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 777\u001b[0m right \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39;49mchildren[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mlabel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    780\u001b[0m     \u001b[39m# L => head to the left and dependant to the right\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     node_head      \u001b[39m=\u001b[39m word_idxs[left]   \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(left) \u001b[39mis\u001b[39;00m C_Tree \u001b[39melse\u001b[39;00m \u001b[39mint\u001b[39m(left\u001b[39m.\u001b[39mhead)\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:777\u001b[0m, in \u001b[0;36mD_Tree.from_bht.<locals>.from_bht_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[1;32m    776\u001b[0m left  \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 777\u001b[0m right \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39;49mchildren[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mlabel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    780\u001b[0m     \u001b[39m# L => head to the left and dependant to the right\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     node_head      \u001b[39m=\u001b[39m word_idxs[left]   \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(left) \u001b[39mis\u001b[39;00m C_Tree \u001b[39melse\u001b[39;00m \u001b[39mint\u001b[39m(left\u001b[39m.\u001b[39mhead)\n",
      "    \u001b[0;31m[... skipping similar frames: D_Tree.from_bht.<locals>.from_bht_rec at line 777 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:777\u001b[0m, in \u001b[0;36mD_Tree.from_bht.<locals>.from_bht_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[1;32m    776\u001b[0m left  \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 777\u001b[0m right \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39;49mchildren[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mlabel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    780\u001b[0m     \u001b[39m# L => head to the left and dependant to the right\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     node_head      \u001b[39m=\u001b[39m word_idxs[left]   \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(left) \u001b[39mis\u001b[39;00m C_Tree \u001b[39melse\u001b[39;00m \u001b[39mint\u001b[39m(left\u001b[39m.\u001b[39mhead)\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:776\u001b[0m, in \u001b[0;36mD_Tree.from_bht.<locals>.from_bht_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mis_preterminal():\n\u001b[1;32m    774\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 776\u001b[0m left  \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39;49mchildren[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    777\u001b[0m right \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39mchildren[\u001b[39m1\u001b[39m])\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mlabel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    780\u001b[0m     \u001b[39m# L => head to the left and dependant to the right\u001b[39;00m\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:776\u001b[0m, in \u001b[0;36mD_Tree.from_bht.<locals>.from_bht_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mis_preterminal():\n\u001b[1;32m    774\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 776\u001b[0m left  \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39;49mchildren[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    777\u001b[0m right \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39mchildren[\u001b[39m1\u001b[39m])\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mlabel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    780\u001b[0m     \u001b[39m# L => head to the left and dependant to the right\u001b[39;00m\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:777\u001b[0m, in \u001b[0;36mD_Tree.from_bht.<locals>.from_bht_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[1;32m    776\u001b[0m left  \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 777\u001b[0m right \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39;49mchildren[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mlabel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    780\u001b[0m     \u001b[39m# L => head to the left and dependant to the right\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     node_head      \u001b[39m=\u001b[39m word_idxs[left]   \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(left) \u001b[39mis\u001b[39;00m C_Tree \u001b[39melse\u001b[39;00m \u001b[39mint\u001b[39m(left\u001b[39m.\u001b[39mhead)\n",
      "File \u001b[0;32m~/CoDeLin/codelin/models/deps_tree.py:777\u001b[0m, in \u001b[0;36mD_Tree.from_bht.<locals>.from_bht_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[1;32m    776\u001b[0m left  \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 777\u001b[0m right \u001b[39m=\u001b[39m from_bht_rec(node\u001b[39m.\u001b[39;49mchildren[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mlabel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    780\u001b[0m     \u001b[39m# L => head to the left and dependant to the right\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     node_head      \u001b[39m=\u001b[39m word_idxs[left]   \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(left) \u001b[39mis\u001b[39;00m C_Tree \u001b[39melse\u001b[39;00m \u001b[39mint\u001b[39m(left\u001b[39m.\u001b[39mhead)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def pt(t, d=True):\n",
    "    if d:\n",
    "        if type(t) is list:\n",
    "            for i in t:\n",
    "                print(i)\n",
    "            for i in t:\n",
    "                Tree.fromstring(str(i)).pretty_print()\n",
    "        else:\n",
    "            Tree.fromstring(str(t)).pretty_print()\n",
    "\n",
    "path = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-test.conllu\"\n",
    "encoder = D_HexatagEncoding(separator = \"[_]\")\n",
    "trees = D_Tree.read_conllu_file(path, filter_projective=True)\n",
    "for sample in trees:\n",
    "    lin_tree = encoder.encode(sample)\n",
    "    encoder.decode(lin_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and generate machamp config for training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean multi-expression lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import re\n",
    "\n",
    "treebank_path=\"/home/droca1/Treebanks/UD_Spanish-AnCora\"\n",
    "treebank_folders = [os.path.join(treebank_path, f) for f in os.listdir(treebank_path) if os.path.isdir(os.path.join(treebank_path, f))]\n",
    "mtl = [True, False]\n",
    "encoder = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "\n",
    "for tb_f in treebank_folders:\n",
    "    print(\"[INFO] Processing\",tb_f)\n",
    "    # get all conllu files\n",
    "    treebank_name = (tb_f.split(\"/\")[-1])\n",
    "    conllu_files = [os.path.join(tb_f, f) for f in os.listdir(tb_f) if (f.endswith(\".conllu\") and 'test' in f)]\n",
    "    \n",
    "    train_file = None\n",
    "    dev_file = None\n",
    "\n",
    "    # encode\n",
    "    for conllu_file in conllu_files:\n",
    "        print(\"[INFO] Cleaning\",conllu_file)\n",
    "        deps_treebank = os.path.join(tb_f, conllu_file)\n",
    "        output_file = os.path.join(tb_f, conllu_file)\n",
    "        \n",
    "        with open(deps_treebank, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        with open(deps_treebank, \"w\") as f:\n",
    "            for line in lines:\n",
    "                if re.match(r\"^\\d+-.*\", line):\n",
    "                    continue\n",
    "                f.write(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 80% split of treebanks without dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform holdout of 20%\n",
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "treebank_path = \"/home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-train.backup\"\n",
    "trees = D_Tree.read_conllu_file(treebank_path, filter_projective=False)\n",
    "\n",
    "trees_train = trees[:int(len(trees)*0.8)]\n",
    "trees_dev = trees[int(len(trees)*0.8):]\n",
    "\n",
    "with open(\"/home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-train.conllu\", \"w\") as f:\n",
    "        for t in trees_train:\n",
    "                t.remove_dummy()\n",
    "                f.write(str(t))\n",
    "with open(\"/home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-dev.conllu\", \"w\") as f:\n",
    "        for t in trees_dev:\n",
    "                t.remove_dummy()\n",
    "                f.write(str(t))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode and generate machamp configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "config_singletask = {\n",
    "    \"dependency\":{\n",
    "        \"train_data_path\":\"XXX\",\n",
    "        \"dev_data_path\":\"XXX\",\n",
    "        \"word_idx\":0,\n",
    "        \"tasks\":{\n",
    "            \"label\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":2\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "config_multitask = {\n",
    "    \"dependency\":{\n",
    "        \"train_data_path\":\"XXX\",\n",
    "        \"dev_data_path\":\"XXX\",\n",
    "        \"word_idx\":0,\n",
    "        \"tasks\":{\n",
    "            \"brk\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":2\n",
    "            },\n",
    "            \"reltype\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":3\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "treebank_path = \"/home/poli/Treebanks/d21/\"\n",
    "treebank_folders = [os.path.join(treebank_path, f) for f in os.listdir(treebank_path) if os.path.isdir(os.path.join(treebank_path, f))]\n",
    "mtl = [True, False]\n",
    "\n",
    "brk_bs = D_BrkBasedEncoding(separator=\"[_]\", displacement=False)\n",
    "brk_2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement=False)\n",
    "brk_4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "brk_7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "encodings = [brk_bs, brk_2p, brk_4b, brk_7b]\n",
    "filter_projective = False\n",
    "\n",
    "for encoder in encodings:\n",
    "    print(\"[INFO] Encoding with\", encoder.__class__.__name__)\n",
    "\n",
    "    for tb_f in treebank_folders:\n",
    "        print(\"[INFO] Processing\",tb_f)\n",
    "        # get all conllu files\n",
    "        treebank_name = (tb_f.split(\"/\")[-1])\n",
    "        conllu_files = [os.path.join(tb_f, f) for f in os.listdir(tb_f) if (f.endswith(\".conllu\"))]\n",
    "        \n",
    "        train_file = \"\"\n",
    "        dev_file = \"\"\n",
    "\n",
    "        # encode\n",
    "        for conllu_file in conllu_files:\n",
    "            deps_treebank = os.path.join(tb_f, conllu_file)\n",
    "            output_file = os.path.join(tb_f, conllu_file)\n",
    "            \n",
    "            target_extension = \"_\"+encoder.__class__.__name__+\".labels\"\n",
    "            output_file = output_file.replace(\".conllu\", target_extension)  \n",
    "            \n",
    "            if \"train\" in output_file:\n",
    "                train_file = output_file\n",
    "            elif \"dev\" in output_file:\n",
    "                dev_file = output_file\n",
    "            \n",
    "            trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                            filter_projective=filter_projective)\n",
    "\n",
    "            with open(output_file, \"w\") as f:\n",
    "                for tree in trees:\n",
    "                    lin_tree = encoder.encode(tree)\n",
    "                    f.write(lin_tree.to_string(f_idx_dict=None, \n",
    "                                            add_bos_eos=True, \n",
    "                                            separate_columns=True) +\"\\n\")\n",
    "            \n",
    "            # save a clean test\n",
    "            if 'test' in conllu_file and filter_projective:\n",
    "                output_file = output_file.replace(\".labels\", \"-clean.conllu\")\n",
    "                with open(output_file, \"w\") as f:\n",
    "                    for tree in trees:\n",
    "                        tree.remove_dummy()\n",
    "                        f.write(\"# text = \"+tree.get_sentence()+\"\\n\")\n",
    "                        f.write(str(tree))\n",
    "        \n",
    "        current_config = config_multitask.copy()\n",
    "        current_config[\"dependency\"][\"train_data_path\"] = train_file.replace('poli', 'diego.roca')\n",
    "        current_config[\"dependency\"][\"dev_data_path\"] = dev_file.replace('poli', 'diego.roca')\n",
    "\n",
    "        config_name = \"config_\"+encoder.__class__.__name__+\".json\"\n",
    "        with open(os.path.join(tb_f, config_name), \"w\") as f:\n",
    "            json.dump(current_config, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
