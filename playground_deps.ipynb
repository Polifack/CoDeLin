{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Linearization Playground"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/droca1/Treebanks/20ag/Penn-Treebank/ptb-dev.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=True)\n",
    "\n",
    "sample_tree=trees[554]\n",
    "print(sample_tree)\n",
    "print(D_Tree.to_latex(sample_tree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"./pics/notebooks/d_tree_1.png\" /></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode with 4-bits encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "enc_7b = D_Brk7BitsEncoding(separator=\"_\")\n",
    "for i, sample_tree in enumerate(trees):\n",
    "    lin_tree = enc_7b.encode(sample_tree)\n",
    "    dec_tree = enc_7b.decode(lin_tree)\n",
    "    las = dec_tree.las_score(sample_tree)\n",
    "    \n",
    "    if las != 1:\n",
    "        print(\"Error at tree\",i,\"length\",len(sample_tree))\n",
    "        print(D_Tree.to_latex(sample_tree))\n",
    "        print(lin_tree)\n",
    "        print(\"LAS =\",dec_tree.las_score(sample_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "deps_treebank = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "sample_tree = trees[6114]\n",
    "enc_7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "lin_tree = enc_7b.encode(sample_tree)\n",
    "print(lin_tree)\n",
    "dec_tree = enc_7b.decode(lin_tree)\n",
    "print(\"LAS =\",dec_tree.las_score(sample_tree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planar extraction for all UD Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/droca1/Treebanks/20ag/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"n_trees\",\"1-planar\",\"2-planar\",\"3-planar\",\"r_deps\",\"l_deps\",\"avg_dependants\"])\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    \n",
    "    # get all conllu files in ud_folder\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "        total_trees += trees\n",
    "    \n",
    "    planar1,planar2,planarN = D_Tree.get_planarity_percentage(total_trees)\n",
    "    r_deps, l_deps = D_Tree.get_dependency_direction_percentage(total_trees)\n",
    "    avg_dependants = D_Tree.get_avg_dependants(total_trees)\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, len(total_trees), str(planar1)+\"%\", str(planar2)+\"%\", str(planarN)+\"%\", r_deps, l_deps, avg_dependants]], \n",
    "                                                     columns=[\"Corpus\",\"n_trees\",\"1-planar\",\"2-planar\",\"3-planar\",\"r_deps\",\"l_deps\",\"avg_dependants\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "ptb_path=\"/home/droca1/Treebanks/20ag/PENN_TREEBANK/\"\n",
    "ptb_files = [os.path.join(ptb_path, f) for f in os.listdir(ptb_path) if f.endswith(\".conllu\")]\n",
    "total_trees = []\n",
    "\n",
    "for ptb_file in ptb_files:\n",
    "    trees = D_Tree.read_conllu_file(ptb_file)\n",
    "    total_trees += trees\n",
    "\n",
    "for tree in total_trees:\n",
    "    p1,p2 = D_Tree.two_planar_greedy(tree)\n",
    "    if len(p2) != 0 and len(p1) != 0:\n",
    "        print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "                  Corpus &        BRK &     BRK-2P &     BRK-4B &     BRK-7B \\\\\n",
      "\\midrule\n",
      "          UD-Russian-GSD & 0.99755674 & 0.99997546 & 0.99613951 & 0.99997546 \\\\\n",
      "          UD-Finnish-TDT & 0.99717628 & 0.99997437 & 0.99353297 & 0.99997437 \\\\\n",
      "           UD-German-GSD & 0.99547451 & 0.99987743 & 0.99275148 & 0.99987743 \\\\\n",
      "           PENN-TREEBANK & 0.99999617 &        1.0 & 0.99999232 &        1.0 \\\\\n",
      "UD-Ancient-Greek-Perseus & 0.95806205 &  0.9923733 &  0.8893046 &  0.9923733 \\\\\n",
      "          UD-Chinese-GSD & 0.99913695 & 0.99999375 & 0.99835233 & 0.99999375 \\\\\n",
      "           UD-Hebrew-HTB & 0.99983322 &        1.0 & 0.99978495 &        1.0 \\\\\n",
      "            UD-Tamil-TTB &  0.9994489 &        1.0 & 0.99849143 &        1.0 \\\\\n",
      "           UD-Uyghur-UDT &  0.9943495 & 0.99997589 & 0.99064191 & 0.99997589 \\\\\n",
      "            UD-Wolof-WTB & 0.99828107 & 0.99998305 & 0.99748056 & 0.99998305 \\\\\n",
      "          UD-English-EWT & 0.99875497 & 0.99999259 & 0.99808308 & 0.99999259 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118802/3957907777.py:55: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.to_latex(index=False, float_format=\"{:0.8}\".format))\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/droca1/Treebanks/20ag/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = True)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = True)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    injective = {\"brk\":0, \"brk2p\":0, \"brk4b\":0, \"brk7b\":0}\n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                        filter_projective=False)\n",
    "        total_trees += trees\n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            t_brk.remove_dummy()\n",
    "            t_brk_dec = ebrk.decode(t_brk)\n",
    "            injective[\"brk\"] += t_brk_dec.las_score(t)\n",
    "            \n",
    "            t_brk2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            t_brk2p.remove_dummy()\n",
    "            t_brk2p_dec = ebrk2p.decode(t_brk2p)\n",
    "            injective[\"brk2p\"] += t_brk2p_dec.las_score(t)\n",
    "            \n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            t_brk4b_dec = ebrk4b.decode(t_brk4b)\n",
    "            injective[\"brk4b\"] += t_brk4b_dec.las_score(t)\n",
    "            \n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            t_brk7b_dec = ebrk7b.decode(t_brk7b)\n",
    "            injective[\"brk7b\"] += t_brk7b_dec.las_score(t)\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, injective[\"brk\"]/len(total_trees), injective[\"brk2p\"]/len(total_trees), injective[\"brk4b\"]/len(total_trees), injective[\"brk7b\"]/len(total_trees)]],\n",
    "                                                        columns=[\"Corpus\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])], ignore_index=True)\n",
    "    \n",
    "\n",
    "# Find columns of float type\n",
    "# float_columns = results_df.select_dtypes(include=[float]).columns\n",
    "# results_df[float_columns] = results_df[float_columns].applymap('{:.4e}'.format)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.8}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hexatag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "from codelin.models.const_tree import C_Tree\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def pt(t, d=True):\n",
    "    if d:\n",
    "        if type(t) is list:\n",
    "            for i in t:\n",
    "                print(i)\n",
    "            for i in t:\n",
    "                Tree.fromstring(str(i)).pretty_print()\n",
    "        else:\n",
    "            Tree.fromstring(str(t)).pretty_print()\n",
    "\n",
    "path = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-test.conllu\"\n",
    "encoder = D_Brk4BitsEncoding(separator = \"[_]\")\n",
    "trees = D_Tree.read_conllu_file(path, filter_projective=True)\n",
    "sample = trees[0]\n",
    "\n",
    "print(sample)\n",
    "bht = D_Tree.to_bht(sample)\n",
    "print(bht)\n",
    "dec_tree = D_Tree.from_bht(bht)\n",
    "print(dec_tree)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean multi-expression lines from CONLLU files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import re\n",
    "\n",
    "ag20_path=\"/home/droca1/Treebanks/20ag/\"\n",
    "ag20_folders = [os.path.join(ag20_path, f) for f in os.listdir(ag20_path) if os.path.isdir(os.path.join(ag20_path, f))]\n",
    "mtl = [True, False]\n",
    "encoder = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "\n",
    "for ag20_folder in ag20_folders:\n",
    "    print(\"[INFO] Processing\",ag20_folder)\n",
    "    # get all conllu files\n",
    "    treebank_name = (ag20_folder.split(\"/\")[-1])\n",
    "    conllu_files = [os.path.join(ag20_folder, f) for f in os.listdir(ag20_folder) if (f.endswith(\".conllu\"))]\n",
    "    \n",
    "    train_file = None\n",
    "    dev_file = None\n",
    "\n",
    "    # encode\n",
    "    for conllu_file in conllu_files:\n",
    "        print(\"[INFO] Cleaning\",conllu_file)\n",
    "        deps_treebank = os.path.join(ag20_folder, conllu_file)\n",
    "        output_file = os.path.join(ag20_folder, conllu_file)\n",
    "        \n",
    "        with open(deps_treebank, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        with open(deps_treebank, \"w\") as f:\n",
    "            for line in lines:\n",
    "                if re.match(r\"^\\d+-.*\", line):\n",
    "                    continue\n",
    "                f.write(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode and generate machamp config for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "config_singletask = {\n",
    "    \"dependency\":{\n",
    "        \"train_data_path\":\"XXX\",\n",
    "        \"dev_data_path\":\"XXX\",\n",
    "        \"word_idx\":0,\n",
    "        \"tasks\":{\n",
    "            \"label\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":2\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "config_multitask = {\n",
    "    \"dependency\":{\n",
    "        \"train_data_path\":\"XXX\",\n",
    "        \"dev_data_path\":\"XXX\",\n",
    "        \"word_idx\":0,\n",
    "        \"tasks\":{\n",
    "            \"brk\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":2\n",
    "            },\n",
    "            \"reltype\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":3\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "ag20_path=\"/home/droca1/Treebanks/20ag/\"\n",
    "ag20_folders = [os.path.join(ag20_path, f) for f in os.listdir(ag20_path) if os.path.isdir(os.path.join(ag20_path, f))]\n",
    "mtl = [True, False]\n",
    "\n",
    "#encoder = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "encoder = D_Brk2PBasedEncoding(separator=\"[_]\")\n",
    "\n",
    "filter_projective = False\n",
    "for ag20_folder in ag20_folders:\n",
    "    print(\"[INFO] Processing\",ag20_folder)\n",
    "    # get all conllu files\n",
    "    treebank_name = (ag20_folder.split(\"/\")[-1])\n",
    "    conllu_files = [os.path.join(ag20_folder, f) for f in os.listdir(ag20_folder) if (f.endswith(\".conllu\"))]\n",
    "\n",
    "    \n",
    "    train_file = None\n",
    "    dev_file = None\n",
    "\n",
    "    # encode\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ag20_folder, conllu_file)\n",
    "        output_file = os.path.join(ag20_folder, conllu_file)\n",
    "        target_extension = \".labels\"\n",
    "        output_file = output_file.replace(\".conllu\", target_extension)  \n",
    "        \n",
    "        if \"train\" in output_file:\n",
    "            train_file = output_file\n",
    "        elif \"dev\" in output_file:\n",
    "            dev_file = output_file\n",
    "        \n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                        filter_projective=filter_projective)\n",
    "\n",
    "        with open(output_file, \"w\") as f:\n",
    "            for tree in trees:\n",
    "                lin_tree = encoder.encode(tree)\n",
    "                f.write(lin_tree.to_string(f_idx_dict=None, \n",
    "                                           add_bos_eos=True, \n",
    "                                           separate_columns=True) +\"\\n\")\n",
    "        \n",
    "        # save a clean test\n",
    "        if 'test' in conllu_file and filter_projective:\n",
    "            output_file = output_file.replace(\".labels\", \"-clean.conllu\")\n",
    "            with open(output_file, \"w\") as f:\n",
    "                for tree in trees:\n",
    "                    tree.remove_dummy()\n",
    "                    f.write(\"# text = \"+tree.get_sentence()+\"\\n\")\n",
    "                    f.write(str(tree))\n",
    "    \n",
    "    current_config = config_multitask.copy()\n",
    "    current_config[\"dependency\"][\"train_data_path\"] = train_file.replace('droca1', 'diego.roca')\n",
    "    current_config[\"dependency\"][\"dev_data_path\"] = dev_file.replace('droca1', 'diego.roca')\n",
    "\n",
    "    config_name = \"config.json\"\n",
    "    with open(os.path.join(ag20_folder, config_name), \"w\") as f:\n",
    "        json.dump(current_config, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
