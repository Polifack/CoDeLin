{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Linearization Playground"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "smallest_non_projective = 3992\n",
    "tree = trees[smallest_non_projective]\n",
    "\n",
    "encoder = D_Brk7BitsEncoding()\n",
    "bits = D_Brk7BitsEncoding.labels_to_bits(encoder.encode(tree).labels)\n",
    "bracket_bits = []\n",
    "for b in bits:\n",
    "    b_str = [str(i) for i in b]\n",
    "    bracket_bits.append(\"\".join(b_str))\n",
    "\n",
    "print(D_Tree.to_latex(tree, include_col=False, planar_separate=True, planar_colors=['black', 'red'], additional_labels=bracket_bits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=True)\n",
    "\n",
    "target_tree = 0\n",
    "n_skips = 2 # just in case the tree is not good\n",
    "for i,tree in enumerate(trees):\n",
    "    if len(tree) == 8:\n",
    "        if n_skips>0:\n",
    "            n_skips-=1\n",
    "            continue\n",
    "        \n",
    "        target_tree = i\n",
    "        break\n",
    "\n",
    "tree = trees[target_tree]\n",
    "\n",
    "encoder = D_Brk4BitsEncoding()\n",
    "\n",
    "brackets = [str(i.xi) for i in  encoder.encode(tree).labels]\n",
    "\n",
    "bits = D_Brk4BitsEncoding.labels_to_bits(encoder.encode(tree).labels)\n",
    "bracket_bits = []\n",
    "for b in bits:\n",
    "    b_str = [str(i) for i in b]\n",
    "    bracket_bits.append(\"\".join(b_str))\n",
    "\n",
    "print(D_Tree.to_latex(tree, include_col=False, planar_separate=True, planar_colors=['black', 'red'], additional_labels=bracket_bits))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode with 4-bits encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "enc_7b = D_Brk7BitsEncoding(separator=\"_\")\n",
    "for i, sample_tree in enumerate(trees):\n",
    "    lin_tree = enc_7b.encode(sample_tree)\n",
    "    dec_tree = enc_7b.decode(lin_tree)\n",
    "    las = dec_tree.las_score(sample_tree)\n",
    "    \n",
    "    if las != 1:\n",
    "        print(\"Error at tree\",i,\"length\",len(sample_tree))\n",
    "        print(D_Tree.to_latex(sample_tree))\n",
    "        print(lin_tree)\n",
    "        print(\"LAS =\",dec_tree.las_score(sample_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "deps_treebank = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "sample_tree = trees[6114]\n",
    "enc_7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "lin_tree = enc_7b.encode(sample_tree)\n",
    "print(lin_tree)\n",
    "dec_tree = enc_7b.decode(lin_tree)\n",
    "print(\"LAS =\",dec_tree.las_score(sample_tree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planar extraction for all UD Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"n_trees\",\"1-planar\",\"proj\",\"r_deps\",\"l_deps\",\"avg_dependants\"])\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    \n",
    "    # get all conllu files in ud_folder\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "        total_trees += trees\n",
    "    \n",
    "    proj                        = D_Tree.get_projectivity_percentage(total_trees)\n",
    "    planar1, planar2, planarN   = D_Tree.get_planarity_percentage(total_trees)\n",
    "    r_deps, l_deps              = D_Tree.get_dependency_direction_percentage(total_trees)\n",
    "    avg_dependants              = D_Tree.get_avg_dependants(total_trees)\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, len(total_trees), proj, planar1, r_deps, l_deps, avg_dependants]], columns=results_df.columns)])\n",
    "\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.10}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "ptb_path=\"/home/droca1/Treebanks/20ag/PENN_TREEBANK/\"\n",
    "ptb_files = [os.path.join(ptb_path, f) for f in os.listdir(ptb_path) if f.endswith(\".conllu\")]\n",
    "total_trees = []\n",
    "\n",
    "for ptb_file in ptb_files:\n",
    "    trees = D_Tree.read_conllu_file(ptb_file)\n",
    "    total_trees += trees\n",
    "\n",
    "for tree in total_trees:\n",
    "    p1,p2 = D_Tree.two_planar_greedy(tree)\n",
    "    if len(p2) != 0 and len(p1) != 0:\n",
    "        print(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"BRK\", \"BRK2P\", \"BRK4B\", \"BRK7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = True)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = True)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    total_labels = {\"brk\":[], \"brk2p\":[], \"brk4b\":[], \"brk7b\":[]}\n",
    "    \n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                        filter_projective=False)\n",
    "        total_trees += trees\n",
    "        \n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk\"] += [str(lbl.xi) for lbl in t_brk.labels]\n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk7b\"] += [str(lbl.xi) for lbl in t_brk7b.labels]\n",
    "            t_brk_2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk2p\"] += [str(lbl.xi) for lbl in t_brk_2p.labels]\n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk4b\"] += [str(lbl.xi) for lbl in t_brk4b.labels]\n",
    "\n",
    "    \n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    \n",
    "    total_labels[\"brk\"] =   set(total_labels[\"brk\"])\n",
    "    total_labels[\"brk2p\"] = set(total_labels[\"brk2p\"])\n",
    "    total_labels[\"brk4b\"] = set(total_labels[\"brk4b\"])\n",
    "    total_labels[\"brk7b\"] = set(total_labels[\"brk7b\"])\n",
    "    \n",
    "    # remove none\n",
    "    print(total_labels[\"brk4b\"])\n",
    "    if \"NONE\" in total_labels[\"brk\"]:\n",
    "        total_labels[\"brk\"].remove(\"-NONE-\")\n",
    "    if \"-NONE-\" in total_labels[\"brk2p\"]:\n",
    "        total_labels[\"brk2p\"].remove(\"-NONE-\")\n",
    "    if \"-NONE-\" in total_labels[\"brk4b\"]:\n",
    "        total_labels[\"brk4b\"].remove(\"-NONE-\")\n",
    "    if \"-NONE-\" in total_labels[\"brk7b\"]:\n",
    "        total_labels[\"brk7b\"].remove(\"-NONE-\")\n",
    "    \n",
    "    total_labels[\"brk\"]   = len(total_labels[\"brk\"])\n",
    "    total_labels[\"brk2p\"] = len(total_labels[\"brk2p\"])\n",
    "    total_labels[\"brk4b\"] = len(total_labels[\"brk4b\"])\n",
    "    total_labels[\"brk7b\"] = len(total_labels[\"brk7b\"])\n",
    "\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, total_labels[\"brk\"], total_labels[\"brk2p\"], total_labels[\"brk4b\"], total_labels[\"brk7b\"]]],\n",
    "                                                        columns=[\"Corpus\",\"BRK\", \"BRK2P\", \"BRK4B\", \"BRK7B\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.8}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of dependency arcs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"BRK\", \"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = False)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = True)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    injective = {\"brk\":0.0, \"brk2p\":0.0, \"brk4b\":0.0, \"brk7b\":0.0}\n",
    "    \n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                        filter_projective=False)\n",
    "        total_trees += trees\n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            t_brk.remove_dummy()\n",
    "            t_brk_dec = ebrk.decode(t_brk)\n",
    "            injective[\"brk\"] += t_brk_dec.las_score(t)\n",
    "            \n",
    "            t_brk2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            t_brk2p.remove_dummy()\n",
    "            t_brk2p_dec = ebrk2p.decode(t_brk2p)\n",
    "            injective[\"brk2p\"] += t_brk2p_dec.las_score(t)\n",
    "            \n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            t_brk4b_dec = ebrk4b.decode(t_brk4b)\n",
    "            injective[\"brk4b\"] += t_brk4b_dec.las_score(t)\n",
    "            \n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            t_brk7b_dec = ebrk7b.decode(t_brk7b)\n",
    "            injective[\"brk7b\"] += t_brk7b_dec.las_score(t)\n",
    "    \n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, injective[\"brk\"]/len(total_trees), injective[\"brk2p\"]/len(total_trees), injective[\"brk4b\"]/len(total_trees), injective[\"brk7b\"]/len(total_trees)]],\n",
    "                                                        columns=[\"Corpus\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.8}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = False)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = False)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    injective = {\"brk\":0.0, \"brk2p\":0.0, \"brk4b\":0.0, \"brk7b\":0.0}\n",
    "    \n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank,filter_projective = False)\n",
    "        total_trees += trees\n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            t_brk.remove_dummy()\n",
    "            t_brk_dec = ebrk.decode(t_brk)\n",
    "            injective[\"brk\"] += 1 if t_brk_dec.las_score(t)==1 else 0\n",
    "            \n",
    "            t_brk2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            t_brk2p.remove_dummy()\n",
    "            t_brk2p_dec = ebrk2p.decode(t_brk2p)\n",
    "            injective[\"brk2p\"] += 1 if t_brk2p_dec.las_score(t)==1 else 0\n",
    "            \n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            t_brk4b_dec = ebrk4b.decode(t_brk4b)\n",
    "            injective[\"brk4b\"] += 1 if t_brk4b_dec.las_score(t)==1 else 0\n",
    "            \n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            t_brk7b_dec = ebrk7b.decode(t_brk7b)\n",
    "            injective[\"brk7b\"] += 1 if t_brk7b_dec.las_score(t)==1 else 0\n",
    "    \n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, injective[\"brk\"]/len(total_trees), injective[\"brk2p\"]/len(total_trees), injective[\"brk4b\"]/len(total_trees), injective[\"brk7b\"]/len(total_trees)]],\n",
    "                                                        columns=[\"Corpus\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.5}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different encodings coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# conllu_file = \"/home/poli/Treebanks/20ag/PTB/ptb-train.conllu\"\n",
    "conllu_file = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\", displacement = False)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "total_trees = []\n",
    "trees = D_Tree.read_conllu_file(conllu_file, filter_projective=False)\n",
    "\n",
    "for i,t in enumerate(trees):\n",
    "    t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "    t_brk.remove_dummy()\n",
    "    t_brk_dec = ebrk.decode(t_brk)\n",
    "    \n",
    "    t_brk_4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "    t_brk_4b_dec = ebrk4b.decode(t_brk_4b)\n",
    "    \n",
    "    if t.las_score(t_brk_dec) == 1 and t.las_score(t_brk_4b_dec) != 1:\n",
    "        print(\"Tree with BRK but not with BRK-4B: \",i)\n",
    "        t.remove_dummy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hexatag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Transform the dependency trees into binary head consituent trees\n",
    "2) Transform the BHT into hexatags shaped as [<arrow>_<reltype>] where arrow is the corresponding hexatag arrow and reltype is the relationship type for the word whose index is being parsed\n",
    "3) Implement decoding operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t-ROOT-\t_\t-ROOT-\t_\t_\t0\t-NOREL-\t_\t_\n",
      "1\tWhat\twhat\tPRON\tWP\tPronType=Int\t0\troot\t0:root\t_\n",
      "2\tif\tif\tSCONJ\tIN\t_\t4\tmark\t4:mark\t_\n",
      "3\tGoogle\tGoogle\tPROPN\tNNP\tNumber=Sing\t4\tnsubj\t4:nsubj\t_\n",
      "4\tMorphed\tmorph\tVERB\tVBD\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\t1\tadvcl\t1:advcl:if\t_\n",
      "5\tInto\tinto\tADP\tIN\t_\t6\tcase\t6:case\t_\n",
      "6\tGoogleOS\tGoogleOS\tPROPN\tNNP\tNumber=Sing\t4\tobl\t4:obl:into\tSpaceAfter=No\n",
      "7\t?\t?\tPUNCT\t.\t_\t4\tpunct\t4:punct\t_\n",
      "\n",
      "\n",
      "1\t-NONE-\t_\t_\t_\t_\t0\t-NONE-\t_\t_\n",
      "2\t-NONE-\t_\t_\t_\t_\t4\t-NONE-\t_\t_\n",
      "3\t-NONE-\t_\t_\t_\t_\t4\t-NONE-\t_\t_\n",
      "4\t-NONE-\t_\t_\t_\t_\t1\t-NONE-\t_\t_\n",
      "5\t-NONE-\t_\t_\t_\t_\t6\t-NONE-\t_\t_\n",
      "6\t-NONE-\t_\t_\t_\t_\t4\t-NONE-\t_\t_\n",
      "7\t-NONE-\t_\t_\t_\t_\t4\t-NONE-\t_\t_\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "from codelin.models.const_tree import C_Tree\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def pt(t, d=True):\n",
    "    if d:\n",
    "        if type(t) is list:\n",
    "            for i in t:\n",
    "                print(i)\n",
    "            for i in t:\n",
    "                Tree.fromstring(str(i)).pretty_print()\n",
    "        else:\n",
    "            Tree.fromstring(str(t)).pretty_print()\n",
    "\n",
    "path = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-test.conllu\"\n",
    "encoder = D_Brk4BitsEncoding(separator = \"[_]\")\n",
    "trees = D_Tree.read_conllu_file(path, filter_projective=True)\n",
    "sample = trees[0]\n",
    "\n",
    "print(sample)\n",
    "bht = D_Tree.to_bht(sample)\n",
    "#print(bht)\n",
    "#Tree.fromstring(str(bht)).pretty_print()\n",
    "dec_tree = D_Tree.from_bht(bht)\n",
    "print(dec_tree)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and generate machamp config for training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean multi-expression lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import re\n",
    "\n",
    "treebank_path=\"/home/droca1/Treebanks/UD_Spanish-AnCora\"\n",
    "treebank_folders = [os.path.join(treebank_path, f) for f in os.listdir(treebank_path) if os.path.isdir(os.path.join(treebank_path, f))]\n",
    "mtl = [True, False]\n",
    "encoder = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "\n",
    "for tb_f in treebank_folders:\n",
    "    print(\"[INFO] Processing\",tb_f)\n",
    "    # get all conllu files\n",
    "    treebank_name = (tb_f.split(\"/\")[-1])\n",
    "    conllu_files = [os.path.join(tb_f, f) for f in os.listdir(tb_f) if (f.endswith(\".conllu\") and 'test' in f)]\n",
    "    \n",
    "    train_file = None\n",
    "    dev_file = None\n",
    "\n",
    "    # encode\n",
    "    for conllu_file in conllu_files:\n",
    "        print(\"[INFO] Cleaning\",conllu_file)\n",
    "        deps_treebank = os.path.join(tb_f, conllu_file)\n",
    "        output_file = os.path.join(tb_f, conllu_file)\n",
    "        \n",
    "        with open(deps_treebank, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        with open(deps_treebank, \"w\") as f:\n",
    "            for line in lines:\n",
    "                if re.match(r\"^\\d+-.*\", line):\n",
    "                    continue\n",
    "                f.write(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 80% split of treebanks without dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform holdout of 20%\n",
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "treebank_path = \"/home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-train.backup\"\n",
    "trees = D_Tree.read_conllu_file(treebank_path, filter_projective=False)\n",
    "\n",
    "trees_train = trees[:int(len(trees)*0.8)]\n",
    "trees_dev = trees[int(len(trees)*0.8):]\n",
    "\n",
    "with open(\"/home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-train.conllu\", \"w\") as f:\n",
    "        for t in trees_train:\n",
    "                t.remove_dummy()\n",
    "                f.write(str(t))\n",
    "with open(\"/home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-dev.conllu\", \"w\") as f:\n",
    "        for t in trees_dev:\n",
    "                t.remove_dummy()\n",
    "                f.write(str(t))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode and generate machamp configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "config_singletask = {\n",
    "    \"dependency\":{\n",
    "        \"train_data_path\":\"XXX\",\n",
    "        \"dev_data_path\":\"XXX\",\n",
    "        \"word_idx\":0,\n",
    "        \"tasks\":{\n",
    "            \"label\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":2\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "config_multitask = {\n",
    "    \"dependency\":{\n",
    "        \"train_data_path\":\"XXX\",\n",
    "        \"dev_data_path\":\"XXX\",\n",
    "        \"word_idx\":0,\n",
    "        \"tasks\":{\n",
    "            \"brk\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":2\n",
    "            },\n",
    "            \"reltype\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":3\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "treebank_path = \"/home/poli/Treebanks/d21/\"\n",
    "treebank_folders = [os.path.join(treebank_path, f) for f in os.listdir(treebank_path) if os.path.isdir(os.path.join(treebank_path, f))]\n",
    "mtl = [True, False]\n",
    "\n",
    "brk_bs = D_BrkBasedEncoding(separator=\"[_]\", displacement=False)\n",
    "brk_2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement=False)\n",
    "brk_4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "brk_7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "encodings = [brk_bs, brk_2p, brk_4b, brk_7b]\n",
    "filter_projective = False\n",
    "\n",
    "for encoder in encodings:\n",
    "    print(\"[INFO] Encoding with\", encoder.__class__.__name__)\n",
    "\n",
    "    for tb_f in treebank_folders:\n",
    "        print(\"[INFO] Processing\",tb_f)\n",
    "        # get all conllu files\n",
    "        treebank_name = (tb_f.split(\"/\")[-1])\n",
    "        conllu_files = [os.path.join(tb_f, f) for f in os.listdir(tb_f) if (f.endswith(\".conllu\"))]\n",
    "        \n",
    "        train_file = \"\"\n",
    "        dev_file = \"\"\n",
    "\n",
    "        # encode\n",
    "        for conllu_file in conllu_files:\n",
    "            deps_treebank = os.path.join(tb_f, conllu_file)\n",
    "            output_file = os.path.join(tb_f, conllu_file)\n",
    "            \n",
    "            target_extension = \"_\"+encoder.__class__.__name__+\".labels\"\n",
    "            output_file = output_file.replace(\".conllu\", target_extension)  \n",
    "            \n",
    "            if \"train\" in output_file:\n",
    "                train_file = output_file\n",
    "            elif \"dev\" in output_file:\n",
    "                dev_file = output_file\n",
    "            \n",
    "            trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                            filter_projective=filter_projective)\n",
    "\n",
    "            with open(output_file, \"w\") as f:\n",
    "                for tree in trees:\n",
    "                    lin_tree = encoder.encode(tree)\n",
    "                    f.write(lin_tree.to_string(f_idx_dict=None, \n",
    "                                            add_bos_eos=True, \n",
    "                                            separate_columns=True) +\"\\n\")\n",
    "            \n",
    "            # save a clean test\n",
    "            if 'test' in conllu_file and filter_projective:\n",
    "                output_file = output_file.replace(\".labels\", \"-clean.conllu\")\n",
    "                with open(output_file, \"w\") as f:\n",
    "                    for tree in trees:\n",
    "                        tree.remove_dummy()\n",
    "                        f.write(\"# text = \"+tree.get_sentence()+\"\\n\")\n",
    "                        f.write(str(tree))\n",
    "        \n",
    "        current_config = config_multitask.copy()\n",
    "        current_config[\"dependency\"][\"train_data_path\"] = train_file.replace('poli', 'diego.roca')\n",
    "        current_config[\"dependency\"][\"dev_data_path\"] = dev_file.replace('poli', 'diego.roca')\n",
    "\n",
    "        config_name = \"config_\"+encoder.__class__.__name__+\".json\"\n",
    "        with open(os.path.join(tb_f, config_name), \"w\") as f:\n",
    "            json.dump(current_config, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
