{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Linearization Playground"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{dependency}[theme = simple]\n",
      "\\begin{deptext}[row sep=.25em, column sep=1.5em]\n",
      "0 \\& 1 \\& 2 \\& 3 \\& 4 \\& 5 \\& 6 \\& 7 \\\\ \n",
      "-ROOT- \\& What \\& do \\& I \\& need \\& to \\& do \\& ? \\\\ \n",
      "\\texttt{0000100} \\& \\texttt{0110000} \\& \\texttt{0010000} \\& \\texttt{0000000} \\& \\texttt{1011100} \\& \\texttt{0010000} \\& \\texttt{1001010} \\& \\texttt{1010000} \\\\ \n",
      "\\end{deptext}\n",
      "\\depedge[edge style={red}]{7}{2}{obj}\n",
      "\\depedge[edge style={black}]{5}{3}{aux}\n",
      "\\depedge[edge style={black}]{5}{4}{nsubj}\n",
      "\\depedge[edge style={black}]{1}{5}{root}\n",
      "\\depedge[edge style={black}]{7}{6}{mark}\n",
      "\\depedge[edge style={black}]{5}{7}{xcomp}\n",
      "\\depedge[edge style={black}]{5}{8}{punct}\n",
      "\\end{dependency}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "smallest_non_projective = 3992\n",
    "tree = trees[smallest_non_projective]\n",
    "\n",
    "encoder = D_Brk7BitsEncoding()\n",
    "bits = D_Brk7BitsEncoding.labels_to_bits(encoder.encode(tree).labels)\n",
    "bracket_bits = []\n",
    "for b in bits:\n",
    "    b_str = [str(i) for i in b]\n",
    "    bracket_bits.append(\"\".join(b_str))\n",
    "\n",
    "print(D_Tree.to_latex(tree, include_col=False, planar_separate=True, planar_colors=['black', 'red'], additional_labels=bracket_bits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{dependency}[theme = simple]\n",
      "\\begin{deptext}[row sep=.25em, column sep=1.5em]\n",
      "0 \\& 1 \\& 2 \\& 3 \\& 4 \\& 5 \\& 6 \\& 7 \\\\ \n",
      "-ROOT- \\& It \\& should \\& continue \\& to \\& be \\& defanged \\& . \\\\ \n",
      "\\texttt{0001} \\& \\texttt{0100} \\& \\texttt{0000} \\& \\texttt{1111} \\& \\texttt{0100} \\& \\texttt{0000} \\& \\texttt{1010} \\& \\texttt{1100} \\\\ \n",
      "\\end{deptext}\n",
      "\\depedge[edge style={black}]{4}{2}{nsubj}\n",
      "\\depedge[edge style={black}]{4}{3}{aux}\n",
      "\\depedge[edge style={black}]{1}{4}{root}\n",
      "\\depedge[edge style={black}]{7}{5}{mark}\n",
      "\\depedge[edge style={black}]{7}{6}{aux:pass}\n",
      "\\depedge[edge style={black}]{4}{7}{xcomp}\n",
      "\\depedge[edge style={black}]{4}{8}{punct}\n",
      "\\end{dependency}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=True)\n",
    "\n",
    "target_tree = 0\n",
    "n_skips = 2 # just in case the tree is not good\n",
    "for i,tree in enumerate(trees):\n",
    "    if len(tree) == 8:\n",
    "        if n_skips>0:\n",
    "            n_skips-=1\n",
    "            continue\n",
    "        \n",
    "        target_tree = i\n",
    "        break\n",
    "\n",
    "tree = trees[target_tree]\n",
    "\n",
    "encoder = D_Brk4BitsEncoding()\n",
    "\n",
    "brackets = [str(i.xi) for i in  encoder.encode(tree).labels]\n",
    "\n",
    "bits = D_Brk4BitsEncoding.labels_to_bits(encoder.encode(tree).labels)\n",
    "bracket_bits = []\n",
    "for b in bits:\n",
    "    b_str = [str(i) for i in b]\n",
    "    bracket_bits.append(\"\".join(b_str))\n",
    "\n",
    "print(D_Tree.to_latex(tree, include_col=False, planar_separate=True, planar_colors=['black', 'red'], additional_labels=bracket_bits))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode with 4-bits encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "# ptb-dev path\n",
    "deps_treebank = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "enc_7b = D_Brk7BitsEncoding(separator=\"_\")\n",
    "for i, sample_tree in enumerate(trees):\n",
    "    lin_tree = enc_7b.encode(sample_tree)\n",
    "    dec_tree = enc_7b.decode(lin_tree)\n",
    "    las = dec_tree.las_score(sample_tree)\n",
    "    \n",
    "    if las != 1:\n",
    "        print(\"Error at tree\",i,\"length\",len(sample_tree))\n",
    "        print(D_Tree.to_latex(sample_tree))\n",
    "        print(lin_tree)\n",
    "        print(\"LAS =\",dec_tree.las_score(sample_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "\n",
    "deps_treebank = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "sample_tree = trees[6114]\n",
    "enc_7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "lin_tree = enc_7b.encode(sample_tree)\n",
    "print(lin_tree)\n",
    "dec_tree = enc_7b.decode(lin_tree)\n",
    "print(\"LAS =\",dec_tree.las_score(sample_tree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planar extraction for all UD Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrr}\n",
      "\\toprule\n",
      "Corpus & n_trees & 1-planar & r_deps & l_deps & avg_dependants \\\\\n",
      "\\midrule\n",
      "UD-Galician-TreeGal & 1000 & 0.888% & 0.530257 & 0.469743 & 2.530101 \\\\\n",
      "UD-Lithuanian-HSE & 263 & 0.8593155893536122% & 0.584018 & 0.415982 & 2.321700 \\\\\n",
      "UD-Belarusian-HSE & 25231 & 0.9492291229043637% & 0.469295 & 0.530705 & 2.232214 \\\\\n",
      "UD-Old-East-Slavic-RNC & 1070 & 0.6626168224299065% & 0.582177 & 0.417823 & 2.433108 \\\\\n",
      "UD-Marathi-UFAL & 466 & 0.9592274678111588% & 0.508184 & 0.491816 & 2.362304 \\\\\n",
      "UD-Welsh-CCG & 2338 & 0.9824636441402909% & 0.439404 & 0.560596 & 2.324992 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"n_trees\",\"1-planar\",\"r_deps\",\"l_deps\",\"avg_dependants\"])\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    \n",
    "    # get all conllu files in ud_folder\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, filter_projective=False)\n",
    "        total_trees += trees\n",
    "    \n",
    "    planar1,planar2,planarN = D_Tree.get_planarity_percentage(total_trees)\n",
    "    r_deps, l_deps = D_Tree.get_dependency_direction_percentage(total_trees)\n",
    "    avg_dependants = D_Tree.get_avg_dependants(total_trees)\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, len(total_trees), str(planar1)+\"%\", r_deps, l_deps, avg_dependants]], \n",
    "                                                     columns=[\"Corpus\",\"n_trees\",\"1-planar\",\"r_deps\",\"l_deps\",\"avg_dependants\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "ptb_path=\"/home/droca1/Treebanks/20ag/PENN_TREEBANK/\"\n",
    "ptb_files = [os.path.join(ptb_path, f) for f in os.listdir(ptb_path) if f.endswith(\".conllu\")]\n",
    "total_trees = []\n",
    "\n",
    "for ptb_file in ptb_files:\n",
    "    trees = D_Tree.read_conllu_file(ptb_file)\n",
    "    total_trees += trees\n",
    "\n",
    "for tree in total_trees:\n",
    "    p1,p2 = D_Tree.two_planar_greedy(tree)\n",
    "    if len(p2) != 0 and len(p1) != 0:\n",
    "        print(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Corpus & BRK & BRK2P & BRK4B & BRK7B \\\\\n",
      "\\midrule\n",
      "UD-Galician-TreeGal & 512 & 601 & 270 & 376 \\\\\n",
      "UD-Lithuanian-HSE & 398 & 432 & 256 & 306 \\\\\n",
      "UD-Belarusian-HSE & 1136 & 1479 & 477 & 926 \\\\\n",
      "UD-Old-East-Slavic-RNC & 910 & 1181 & 378 & 715 \\\\\n",
      "UD-Marathi-UFAL & 275 & 291 & 197 & 223 \\\\\n",
      "UD-Welsh-CCG & 474 & 514 & 265 & 312 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"BRK\", \"BRK2P\", \"BRK4B\", \"BRK7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = True)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = True)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    total_labels = {\"brk\":[], \"brk2p\":[], \"brk4b\":[], \"brk7b\":[]}\n",
    "    \n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                        filter_projective=False)\n",
    "        total_trees += trees\n",
    "        \n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk\"] += [str(lbl) for lbl in t_brk.labels]\n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk7b\"] += [str(lbl) for lbl in t_brk7b.labels]\n",
    "            t_brk_2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk2p\"] += [str(lbl) for lbl in t_brk_2p.labels]\n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            total_labels[\"brk4b\"] += [str(lbl) for lbl in t_brk4b.labels]\n",
    "\n",
    "    \n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    \n",
    "    total_labels[\"brk\"] = set(total_labels[\"brk\"])\n",
    "    total_labels[\"brk2p\"] = set(total_labels[\"brk2p\"])\n",
    "    total_labels[\"brk4b\"] = set(total_labels[\"brk4b\"])\n",
    "    total_labels[\"brk7b\"] = set(total_labels[\"brk7b\"])\n",
    "    \n",
    "    # remove none\n",
    "    if \"-NONE-\" in total_labels[\"brk\"]:\n",
    "        total_labels[\"brk\"].remove(\"-NONE-\")\n",
    "    if \"-NONE-\" in total_labels[\"brk2p\"]:\n",
    "        total_labels[\"brk2p\"].remove(\"-NONE-\")\n",
    "    if \"-NONE-\" in total_labels[\"brk4b\"]:\n",
    "        total_labels[\"brk4b\"].remove(\"-NONE-\")\n",
    "    if \"-NONE-\" in total_labels[\"brk7b\"]:\n",
    "        total_labels[\"brk7b\"].remove(\"-NONE-\")\n",
    "    \n",
    "    total_labels[\"brk\"] = len(total_labels[\"brk\"])\n",
    "    total_labels[\"brk2p\"] = len(total_labels[\"brk2p\"])\n",
    "    total_labels[\"brk4b\"] = len(total_labels[\"brk4b\"])\n",
    "    total_labels[\"brk7b\"] = len(total_labels[\"brk7b\"])\n",
    "\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, total_labels[\"brk\"], total_labels[\"brk2p\"], total_labels[\"brk4b\"], total_labels[\"brk7b\"]]],\n",
    "                                                        columns=[\"Corpus\",\"BRK\", \"BRK2P\", \"BRK4B\", \"BRK7B\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.8}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract dependency coverage for bracket encodings (dependency coverage can be undestood as the attachment score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Corpus & BRK & BRK-2P & BRK-4B & BRK-7B \\\\\n",
      "\\midrule\n",
      "UD-Galician-TreeGal & 0.99653929 & 0.99993996 & 0.9952312 & 0.99993996 \\\\\n",
      "UD-Lithuanian-HSE & 0.99489936 & 0.99985376 & 0.9882175 & 0.99985376 \\\\\n",
      "UD-Belarusian-HSE & 0.9976523 & 0.99997075 & 0.99460695 & 0.99997075 \\\\\n",
      "UD-Old-East-Slavic-RNC & 0.98842905 & 0.99942381 & 0.97469781 & 0.99942381 \\\\\n",
      "UD-Marathi-UFAL & 0.99812002 & 1.0 & 0.99325199 & 1.0 \\\\\n",
      "UD-Welsh-CCG & 0.99922433 & 1.0 & 0.99931802 & 1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/ag20/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"BRK\", \"BRKD\", \"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = False)\n",
    "ebrkd   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = True)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = True)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    injective = {\"brk\":0.0, \"brkd\":0.0, \"brk2p\":0.0, \"brk4b\":0.0, \"brk7b\":0.0}\n",
    "    \n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                        filter_projective=False)\n",
    "        total_trees += trees\n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            t_brk.remove_dummy()\n",
    "            t_brk_dec = ebrk.decode(t_brk)\n",
    "            injective[\"brk\"] += t_brk_dec.las_score(t)\n",
    "\n",
    "            t_brkd = ebrkd.encode(copy.deepcopy(t))\n",
    "            t_brkd.remove_dummy()\n",
    "            t_brkd_dec = ebrkd.decode(t_brkd)\n",
    "            injective[\"brkd\"] += t_brkd_dec.las_score(t)\n",
    "            \n",
    "            t_brk2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            t_brk2p.remove_dummy()\n",
    "            t_brk2p_dec = ebrk2p.decode(t_brk2p)\n",
    "            injective[\"brk2p\"] += t_brk2p_dec.las_score(t)\n",
    "            \n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            t_brk4b_dec = ebrk4b.decode(t_brk4b)\n",
    "            injective[\"brk4b\"] += t_brk4b_dec.las_score(t)\n",
    "            \n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            t_brk7b_dec = ebrk7b.decode(t_brk7b)\n",
    "            injective[\"brk7b\"] += t_brk7b_dec.las_score(t)\n",
    "    \n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name, injective[\"brk\"]/len(total_trees), injective[\"brkd\"]/len(total_trees), injective[\"brk2p\"]/len(total_trees), injective[\"brk4b\"]/len(total_trees), injective[\"brk7b\"]/len(total_trees)]],\n",
    "                                                        columns=[\"Corpus\",\"BRK\",\"BRKD\", \"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.8}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract full trees coverage for bracket encodings (trees coverage can be understood as the number of trees decoded w/las=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "Corpus & Total Trees & BRK & BRK-2P & BRK-4B & BRK-7B \\\\\n",
      "\\midrule\n",
      "UD-Galician-TreeGal & 1000 & 0.945 & 0.945 & 0.945 & 0.945 \\\\\n",
      "UD-Lithuanian-HSE & 263 & 0.94676806 & 0.94676806 & 0.94676806 & 0.94676806 \\\\\n",
      "UD-Belarusian-HSE & 25231 & 0.97915263 & 0.97915263 & 0.97915263 & 0.97915263 \\\\\n",
      "UD-Old-East-Slavic-RNC & 1070 & 0.81962617 & 0.81962617 & 0.81962617 & 0.81962617 \\\\\n",
      "UD-Marathi-UFAL & 466 & 0.99141631 & 0.99141631 & 0.99141631 & 0.99141631 \\\\\n",
      "UD-Welsh-CCG & 2338 & 0.99059025 & 0.99059025 & 0.99059025 & 0.99059025 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all folders\n",
    "ud_path=\"/home/poli/Treebanks/d21/\"\n",
    "ud_folders = [os.path.join(ud_path, f) for f in os.listdir(ud_path) if os.path.isdir(os.path.join(ud_path, f))]\n",
    "results_df = pd.DataFrame(columns=[\"Corpus\",\"Total Trees\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\",   displacement = True)\n",
    "ebrk2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement = True)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "ebrk7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "for ud_folder in ud_folders:\n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    conllu_files = [os.path.join(ud_folder, f) for f in os.listdir(ud_folder) if f.endswith(\".conllu\")]\n",
    "    injective = {\"brk\":0.0, \"brk2p\":0.0, \"brk4b\":0.0, \"brk7b\":0.0}\n",
    "    \n",
    "    total_trees = []\n",
    "    for conllu_file in conllu_files:\n",
    "        deps_treebank = os.path.join(ud_folder, conllu_file)\n",
    "        trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                        filter_projective=False)\n",
    "        total_trees += trees\n",
    "        for t in trees:\n",
    "            t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "            t_brk.remove_dummy()\n",
    "            t_brk_dec = ebrk.decode(t_brk)\n",
    "            injective[\"brk\"] += 1 if t_brk_dec.las_score(t)==1 else 0\n",
    "            \n",
    "            t_brk2p = ebrk2p.encode(copy.deepcopy(t))\n",
    "            t_brk2p.remove_dummy()\n",
    "            t_brk2p_dec = ebrk2p.decode(t_brk2p)\n",
    "            injective[\"brk2p\"] += 1 if t_brk2p_dec.las_score(t)==1 else 0\n",
    "            \n",
    "            t_brk4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "            t_brk4b_dec = ebrk4b.decode(t_brk4b)\n",
    "            injective[\"brk4b\"] += 1 if t_brk4b_dec.las_score(t)==1 else 0\n",
    "            \n",
    "            t_brk7b = ebrk7b.encode(copy.deepcopy(t))\n",
    "            t_brk7b_dec = ebrk7b.decode(t_brk7b)\n",
    "            injective[\"brk7b\"] += 1 if t_brk7b_dec.las_score(t)==1 else 0\n",
    "    \n",
    "    treebank_name = (ud_folder.split(\"/\")[-1]).replace(\"_\",\"-\")\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([[treebank_name,len(total_trees),injective[\"brk\"]/len(total_trees), injective[\"brk2p\"]/len(total_trees), injective[\"brk4b\"]/len(total_trees), injective[\"brk7b\"]/len(total_trees)]],\n",
    "                                                        columns=[\"Corpus\",\"Total Trees\",\"BRK\",\"BRK-2P\",\"BRK-4B\",\"BRK-7B\"])], ignore_index=True)\n",
    "\n",
    "print(results_df.to_latex(index=False, float_format=\"{:0.8}\".format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find trees covered by 4bits but not brk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with BRK but not with BRK-4B:  1311\n",
      "1 17 || 1 17 || 1 17\n",
      "=====================================\n",
      "2 9 || 2 9 || 2 9\n",
      "=====================================\n",
      "3 9 || 3 9 || 3 9\n",
      "=====================================\n",
      "4 5 || 4 5 || 4 5\n",
      "=====================================\n",
      "5 3 || 5 3 || 5 3\n",
      "=====================================\n",
      "6 7 || 6 7 || 6 7\n",
      "=====================================\n",
      "7 3 || 7 3 || 7 3\n",
      "=====================================\n",
      "8 9 || 8 9 || 8 9\n",
      "=====================================\n",
      "9 1 || 9 1 || 9 1\n",
      "=====================================\n",
      "10 17 || 10 17 || 10 17\n",
      "=====================================\n",
      "11 16 || 11 16 || 11 16\n",
      "=====================================\n",
      "12 14 || 12 14 || 12 14\n",
      "=====================================\n",
      "13 14 || 13 14 || 13 14\n",
      "=====================================\n",
      "14 11 || 14 11 || 14 11\n",
      "=====================================\n",
      "15 16 || 15 16 || 15 16\n",
      "=====================================\n",
      "16 17 || 16 17 || 16 17\n",
      "=====================================\n",
      "17 0 || 17 16 || 17 0\n",
      "=====================================\n",
      "18 19 || 18 19 || 18 19\n",
      "=====================================\n",
      "19 16 || 19 0 || 19 16\n",
      "=====================================\n",
      "20 21 || 20 21 || 20 21\n",
      "=====================================\n",
      "21 19 || 21 19 || 21 19\n",
      "=====================================\n",
      "22 23 || 22 23 || 22 23\n",
      "=====================================\n",
      "23 19 || 23 19 || 23 19\n",
      "=====================================\n",
      "24 23 || 24 23 || 24 23\n",
      "=====================================\n",
      "25 26 || 25 26 || 25 26\n",
      "=====================================\n",
      "26 23 || 26 23 || 26 23\n",
      "=====================================\n",
      "27 30 || 27 30 || 27 30\n",
      "=====================================\n",
      "28 30 || 28 30 || 28 30\n",
      "=====================================\n",
      "29 30 || 29 30 || 29 30\n",
      "=====================================\n",
      "30 26 || 30 26 || 30 26\n",
      "=====================================\n",
      "31 19 || 31 19 || 31 19\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# conllu_file = \"/home/poli/Treebanks/20ag/PTB/ptb-train.conllu\"\n",
    "conllu_file = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\", displacement = False)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "total_trees = []\n",
    "trees = D_Tree.read_conllu_file(conllu_file, filter_projective=False)\n",
    "\n",
    "for i,t in enumerate(trees):\n",
    "    t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "    t_brk.remove_dummy()\n",
    "    t_brk_dec = ebrk.decode(t_brk)\n",
    "    \n",
    "    t_brk_4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "    t_brk_4b_dec = ebrk4b.decode(t_brk_4b)\n",
    "    \n",
    "    if t.las_score(t_brk_dec) == 1 and t.las_score(t_brk_4b_dec) != 1:\n",
    "        print(\"Tree with BRK but not with BRK-4B: \",i)\n",
    "        t.remove_dummy()\n",
    "        for gold_node, pred_node_4b, pred_node_brk in zip(t.nodes, t_brk_4b_dec.nodes, t_brk_dec.nodes):\n",
    "            print(gold_node.id, gold_node.head,\"||\", pred_node_4b.id, pred_node_4b.head, \"||\", pred_node_brk.id, pred_node_brk.head)\n",
    "            print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t-ROOT-\t_\t-ROOT-\t_\t_\t0\t-NOREL-\t_\t_\n",
      "1\tNow\tnow\tADV\tRB\t_\t17\tadvmod\t17:advmod\t_\n",
      "2\tthat\tthat\tSCONJ\tIN\t_\t9\tmark\t9:mark\t_\n",
      "3\tAfghanistan\tAfghanistan\tPROPN\tNNP\tNumber=Sing\t9\tnsubj\t9:nsubj\tSpaceAfter=No\n",
      "4\t,\t,\tPUNCT\t,\t_\t5\tpunct\t5:punct\t_\n",
      "5\tIraq\tIraq\tPROPN\tNNP\tNumber=Sing\t3\tconj\t3:conj:and|9:nsubj\t_\n",
      "6\tand\tand\tCCONJ\tCC\t_\t7\tcc\t7:cc\t_\n",
      "7\tLibya\tLibya\tPROPN\tNNP\tNumber=Sing\t3\tconj\t3:conj:and|9:nsubj\t_\n",
      "8\tare\tbe\tAUX\tVBP\tMood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\t9\tcop\t9:cop\t_\n",
      "9\tout\tout\tADV\tRB\t_\t1\tccomp\t1:ccomp\tSpaceAfter=No\n",
      "10\t,\t,\tPUNCT\t,\t_\t17\tpunct\t17:punct\t_\n",
      "11\ttwo\ttwo\tNUM\tCD\tNumType=Card\t16\tnummod\t16:nummod\t_\n",
      "12\tand\tand\tCCONJ\tCC\t_\t14\tcc\t14:cc\t_\n",
      "13\ta\ta\tDET\tDT\tDefinite=Ind|PronType=Art\t14\tdet\t14:det\t_\n",
      "14\thalf\thalf\tNOUN\tNN\tNumber=Sing|NumType=Frac\t11\tconj\t11:conj:and\t_\n",
      "15\tterrorist\tterrorist\tADJ\tJJ\tDegree=Pos\t16\tamod\t16:amod\t_\n",
      "16\tstates\tstate\tNOUN\tNNS\tNumber=Plur\t17\tnsubj\t17:nsubj\t_\n",
      "17\tremain\tremain\tVERB\tVBP\tMood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t0:root\tSpaceAfter=No\n",
      "18\t:\t:\tPUNCT\t:\t_\t19\tpunct\t19:punct\t_\n",
      "19\tIran\tIran\tPROPN\tNNP\tNumber=Sing\t16\tappos\t16:appos\tSpaceAfter=No\n",
      "20\t,\t,\tPUNCT\t,\t_\t21\tpunct\t21:punct\t_\n",
      "21\tSyria\tSyria\tPROPN\tNNP\tNumber=Sing\t19\tconj\t16:appos|19:conj:and\t_\n",
      "22\tand\tand\tCCONJ\tCC\t_\t23\tcc\t23:cc\t_\n",
      "23\tLebanon\tLebanon\tPROPN\tNNP\tNumber=Sing\t19\tconj\t16:appos|19:conj:and\tSpaceAfter=No\n",
      "24\t,\t,\tPUNCT\t,\t_\t23\tpunct\t23:punct\t_\n",
      "25\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t26\tdet\t26:det\t_\n",
      "26\tlatter\tlatter\tADJ\tJJ\tDegree=Pos\t23\tappos\t23:appos\t_\n",
      "27\tbeing\tbe\tAUX\tVBG\tVerbForm=Ger\t30\tcop\t30:cop\t_\n",
      "28\ta\ta\tDET\tDT\tDefinite=Ind|PronType=Art\t30\tdet\t30:det\t_\n",
      "29\tSyrian\tSyrian\tADJ\tJJ\tDegree=Pos\t30\tamod\t30:amod\t_\n",
      "30\tcolony\tcolony\tNOUN\tNN\tNumber=Sing\t26\tadvcl\t26:advcl\tSpaceAfter=No\n",
      "31\t.\t.\tPUNCT\t.\t_\t19\tpunct\t19:punct\t_\n",
      "\n",
      "\n",
      "\\begin{dependency}[theme = simple]\n",
      "\\begin{deptext}[row sep=.25em, column sep=1.5em]\n",
      "$i$ \\& 0 \\& 1 \\& 2 \\& 3 \\& 4 \\& 5 \\& 6 \\& 7 \\& 8 \\& 9 \\& 10 \\& 11 \\& 12 \\& 13 \\& 14 \\& 15 \\& 16 \\& 17 \\& 18 \\& 19 \\& 20 \\& 21 \\& 22 \\& 23 \\& 24 \\& 25 \\& 26 \\& 27 \\& 28 \\& 29 \\& 30 \\& 31 \\\\ \n",
      "$w_i$ \\& -ROOT- \\& Now \\& that \\& Afghanistan \\& , \\& Iraq \\& and \\& Libya \\& are \\& out \\& , \\& two \\& and \\& a \\& half \\& terrorist \\& states \\& remain \\& : \\& Iran \\& , \\& Syria \\& and \\& Lebanon \\& , \\& the \\& latter \\& being \\& a \\& Syrian \\& colony \\& . \\\\ \n",
      "$l_i$ \\& \\texttt{/} \\& \\texttt{<*/} \\& \\texttt{<*} \\& \\texttt{</} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>*} \\& \\texttt{<} \\& \\texttt{\\textbackslash>*} \\& \\texttt{<} \\& \\texttt{<*/} \\& \\texttt{<*} \\& \\texttt{<} \\& \\texttt{\\textbackslash>*} \\& \\texttt{<} \\& \\texttt{\\textbackslash</} \\& \\texttt{\\textbackslash>*} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>*/} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>/} \\& \\texttt{>} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>*/} \\& \\texttt{<*} \\& \\texttt{<} \\& \\texttt{<} \\& \\texttt{\\textbackslash>*} \\& \\texttt{>*} \\\\ \n",
      "\\end{deptext}\n",
      "\\depedge{19}{3}{advmod}\n",
      "\\depedge{11}{4}{mark}\n",
      "\\depedge{11}{5}{nsubj}\n",
      "\\depedge{7}{6}{punct}\n",
      "\\depedge{5}{7}{conj}\n",
      "\\depedge{9}{8}{cc}\n",
      "\\depedge{5}{9}{conj}\n",
      "\\depedge{11}{10}{cop}\n",
      "\\depedge{3}{11}{ccomp}\n",
      "\\depedge{19}{12}{punct}\n",
      "\\depedge{18}{13}{nummod}\n",
      "\\depedge{16}{14}{cc}\n",
      "\\depedge{16}{15}{det}\n",
      "\\depedge{13}{16}{conj}\n",
      "\\depedge{18}{17}{amod}\n",
      "\\depedge{19}{18}{nsubj}\n",
      "\\depedge{2}{19}{root}\n",
      "\\depedge{21}{20}{punct}\n",
      "\\depedge{18}{21}{appos}\n",
      "\\depedge{23}{22}{punct}\n",
      "\\depedge{21}{23}{conj}\n",
      "\\depedge{25}{24}{cc}\n",
      "\\depedge{21}{25}{conj}\n",
      "\\depedge{25}{26}{punct}\n",
      "\\depedge{28}{27}{det}\n",
      "\\depedge{25}{28}{appos}\n",
      "\\depedge{32}{29}{cop}\n",
      "\\depedge{32}{30}{det}\n",
      "\\depedge{32}{31}{amod}\n",
      "\\depedge{28}{32}{advcl}\n",
      "\\depedge{21}{33}{punct}\n",
      "\\end{dependency}\n",
      "\n",
      "\\begin{dependency}[theme = simple]\n",
      "\\begin{deptext}[row sep=.25em, column sep=1.5em]\n",
      "$i$ \\& 0 \\& 1 \\& 2 \\& 3 \\& 4 \\& 5 \\& 6 \\& 7 \\& 8 \\& 9 \\& 10 \\& 11 \\& 12 \\& 13 \\& 14 \\& 15 \\& 16 \\& 17 \\& 18 \\& 19 \\& 20 \\& 21 \\& 22 \\& 23 \\& 24 \\& 25 \\& 26 \\& 27 \\& 28 \\& 29 \\& 30 \\& 31 \\\\ \n",
      "$w_i$ \\& -ROOT- \\& Now \\& that \\& Afghanistan \\& , \\& Iraq \\& and \\& Libya \\& are \\& out \\& , \\& two \\& and \\& a \\& half \\& terrorist \\& states \\& remain \\& : \\& Iran \\& , \\& Syria \\& and \\& Lebanon \\& , \\& the \\& latter \\& being \\& a \\& Syrian \\& colony \\& . \\\\ \n",
      "$l_i$ \\& \\texttt{</} \\& \\texttt{<} \\& \\texttt{<//} \\& \\texttt{<} \\& \\texttt{\\textbackslash>} \\& \\texttt{<} \\& \\texttt{\\textbackslash>} \\& \\texttt{<} \\& \\texttt{\\textbackslash\\textbackslash\\textbackslash>} \\& \\texttt{<} \\& \\texttt{</} \\& \\texttt{<} \\& \\texttt{<} \\& \\texttt{\\textbackslash\\textbackslash>} \\& \\texttt{<} \\& \\texttt{\\textbackslash\\textbackslash</} \\& \\texttt{\\textbackslash\\textbackslash\\textbackslash} \\& \\texttt{<} \\& \\texttt{\\textbackslash>///} \\& \\texttt{<} \\& \\texttt{\\textbackslash>} \\& \\texttt{<} \\& \\texttt{\\textbackslash>//} \\& \\texttt{>} \\& \\texttt{<} \\& \\texttt{\\textbackslash>/} \\& \\texttt{<} \\& \\texttt{<} \\& \\texttt{<} \\& \\texttt{\\textbackslash\\textbackslash\\textbackslash>} \\& \\texttt{>} \\\\ \n",
      "\\end{deptext}\n",
      "\\depedge{19}{3}{advmod}\n",
      "\\depedge{11}{4}{mark}\n",
      "\\depedge{11}{5}{nsubj}\n",
      "\\depedge{7}{6}{punct}\n",
      "\\depedge{5}{7}{conj}\n",
      "\\depedge{9}{8}{cc}\n",
      "\\depedge{5}{9}{conj}\n",
      "\\depedge{11}{10}{cop}\n",
      "\\depedge{3}{11}{ccomp}\n",
      "\\depedge{19}{12}{punct}\n",
      "\\depedge{18}{13}{nummod}\n",
      "\\depedge{16}{14}{cc}\n",
      "\\depedge{16}{15}{det}\n",
      "\\depedge{13}{16}{conj}\n",
      "\\depedge{18}{17}{amod}\n",
      "\\depedge{19}{18}{nsubj}\n",
      "\\depedge{2}{19}{root}\n",
      "\\depedge{21}{20}{punct}\n",
      "\\depedge{18}{21}{appos}\n",
      "\\depedge{23}{22}{punct}\n",
      "\\depedge{21}{23}{conj}\n",
      "\\depedge{25}{24}{cc}\n",
      "\\depedge{21}{25}{conj}\n",
      "\\depedge{25}{26}{punct}\n",
      "\\depedge{28}{27}{det}\n",
      "\\depedge{25}{28}{appos}\n",
      "\\depedge{32}{29}{cop}\n",
      "\\depedge{32}{30}{det}\n",
      "\\depedge{32}{31}{amod}\n",
      "\\depedge{28}{32}{advcl}\n",
      "\\depedge{21}{33}{punct}\n",
      "\\end{dependency}\n",
      "\n",
      "\\begin{dependency}[theme = simple]\n",
      "\\begin{deptext}[row sep=.25em, column sep=1.5em]\n",
      "$i$ \\& 0 \\& 1 \\& 2 \\& 3 \\& 4 \\& 5 \\& 6 \\& 7 \\& 8 \\& 9 \\& 10 \\& 11 \\& 12 \\& 13 \\& 14 \\& 15 \\& 16 \\& 17 \\& 18 \\& 19 \\& 20 \\& 21 \\& 22 \\& 23 \\& 24 \\& 25 \\& 26 \\& 27 \\& 28 \\& 29 \\& 30 \\& 31 \\\\ \n",
      "$w_i$ \\& -ROOT- \\& Now \\& that \\& Afghanistan \\& , \\& Iraq \\& and \\& Libya \\& are \\& out \\& , \\& two \\& and \\& a \\& half \\& terrorist \\& states \\& remain \\& : \\& Iran \\& , \\& Syria \\& and \\& Lebanon \\& , \\& the \\& latter \\& being \\& a \\& Syrian \\& colony \\& . \\\\ \n",
      "$l_i$ \\& \\texttt{/} \\& \\texttt{<*/} \\& \\texttt{<*} \\& \\texttt{</} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>*} \\& \\texttt{<} \\& \\texttt{\\textbackslash>*} \\& \\texttt{<} \\& \\texttt{<*/} \\& \\texttt{<*} \\& \\texttt{<} \\& \\texttt{\\textbackslash>*} \\& \\texttt{<} \\& \\texttt{\\textbackslash</} \\& \\texttt{\\textbackslash>*} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>*/} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>/} \\& \\texttt{>} \\& \\texttt{<*} \\& \\texttt{\\textbackslash>*/} \\& \\texttt{<*} \\& \\texttt{<} \\& \\texttt{<} \\& \\texttt{\\textbackslash>*} \\& \\texttt{>*} \\\\ \n",
      "\\end{deptext}\n",
      "\\depedge{19}{3}{advmod}\n",
      "\\depedge{11}{4}{mark}\n",
      "\\depedge{11}{5}{nsubj}\n",
      "\\depedge{7}{6}{punct}\n",
      "\\depedge{5}{7}{conj}\n",
      "\\depedge{9}{8}{cc}\n",
      "\\depedge{5}{9}{conj}\n",
      "\\depedge{11}{10}{cop}\n",
      "\\depedge{3}{11}{ccomp}\n",
      "\\depedge{19}{12}{punct}\n",
      "\\depedge{18}{13}{nummod}\n",
      "\\depedge{16}{14}{cc}\n",
      "\\depedge{16}{15}{det}\n",
      "\\depedge{13}{16}{conj}\n",
      "\\depedge{18}{17}{amod}\n",
      "\\depedge{19}{18}{nsubj}\n",
      "\\depedge{18}{19}{root}\n",
      "\\depedge{21}{20}{punct}\n",
      "\\depedge{2}{21}{appos}\n",
      "\\depedge{23}{22}{punct}\n",
      "\\depedge{21}{23}{conj}\n",
      "\\depedge{25}{24}{cc}\n",
      "\\depedge{21}{25}{conj}\n",
      "\\depedge{25}{26}{punct}\n",
      "\\depedge{28}{27}{det}\n",
      "\\depedge{25}{28}{appos}\n",
      "\\depedge{32}{29}{cop}\n",
      "\\depedge{32}{30}{det}\n",
      "\\depedge{32}{31}{amod}\n",
      "\\depedge{28}{32}{advcl}\n",
      "\\depedge{21}{33}{punct}\n",
      "\\end{dependency}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conllu_file = \"/home/poli/Treebanks/20ag/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "trees_idxs = [1311]\n",
    "\n",
    "ebrk   = D_BrkBasedEncoding(separator=\"[_]\", displacement = False)\n",
    "ebrk4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "trees = D_Tree.read_conllu_file(conllu_file, filter_projective = False)\n",
    "\n",
    "for i in trees_idxs:\n",
    "    t = trees[i]\n",
    "\n",
    "    t_brk = ebrk.encode(copy.deepcopy(t))\n",
    "    t_brk.remove_dummy()\n",
    "    t_brk_dec = ebrk.decode(t_brk)\n",
    "\n",
    "    t_brk_4b = ebrk4b.encode(copy.deepcopy(t))\n",
    "    t_brk_4b_dec = ebrk4b.decode(t_brk_4b)\n",
    "    t_brk_4b_dec.add_dummy_root()\n",
    "\n",
    "    print(t)\n",
    "    print(D_Tree.to_latex(t, include_col=True, additional_labels=['/']+[lbl.xi for lbl in t_brk_4b.labels]))\n",
    "    print(D_Tree.to_latex(t, include_col=True, additional_labels=[lbl.xi for lbl in t_brk.labels]))\n",
    "    print(D_Tree.to_latex(t_brk_4b_dec, include_col=True, additional_labels=[lbl.xi for lbl in t_brk_4b.labels]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hexatag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "from codelin.models.const_tree import C_Tree\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def pt(t, d=True):\n",
    "    if d:\n",
    "        if type(t) is list:\n",
    "            for i in t:\n",
    "                print(i)\n",
    "            for i in t:\n",
    "                Tree.fromstring(str(i)).pretty_print()\n",
    "        else:\n",
    "            Tree.fromstring(str(t)).pretty_print()\n",
    "\n",
    "path = \"/home/droca1/Treebanks/20ag/UD_English-EWT/en_ewt-ud-test.conllu\"\n",
    "encoder = D_Brk4BitsEncoding(separator = \"[_]\")\n",
    "trees = D_Tree.read_conllu_file(path, filter_projective=True)\n",
    "sample = trees[0]\n",
    "\n",
    "print(sample)\n",
    "bht = D_Tree.to_bht(sample)\n",
    "print(bht)\n",
    "dec_tree = D_Tree.from_bht(bht)\n",
    "print(dec_tree)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode and generate machamp config for training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean multi-expression lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Galician-TreeGal\n",
      "[INFO] Cleaning /home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-test.conllu\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Lithuanian-HSE\n",
      "[INFO] Cleaning /home/poli/Treebanks/d21/UD_Lithuanian-HSE/lt_hse-ud-test.conllu\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Belarusian-HSE\n",
      "[INFO] Cleaning /home/poli/Treebanks/d21/UD_Belarusian-HSE/be_hse-ud-test.conllu\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Old_East_Slavic-RNC\n",
      "[INFO] Cleaning /home/poli/Treebanks/d21/UD_Old_East_Slavic-RNC/orv_rnc-ud-test.conllu\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Marathi-UFAL\n",
      "[INFO] Cleaning /home/poli/Treebanks/d21/UD_Marathi-UFAL/mr_ufal-ud-test.conllu\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Welsh-CCG\n",
      "[INFO] Cleaning /home/poli/Treebanks/d21/UD_Welsh-CCG/cy_ccg-ud-test.conllu\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "import re\n",
    "\n",
    "treebank_path=\"/home/poli/Treebanks/d21/\"\n",
    "treebank_folders = [os.path.join(treebank_path, f) for f in os.listdir(treebank_path) if os.path.isdir(os.path.join(treebank_path, f))]\n",
    "mtl = [True, False]\n",
    "encoder = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "\n",
    "for tb_f in treebank_folders:\n",
    "    print(\"[INFO] Processing\",tb_f)\n",
    "    # get all conllu files\n",
    "    treebank_name = (tb_f.split(\"/\")[-1])\n",
    "    conllu_files = [os.path.join(tb_f, f) for f in os.listdir(tb_f) if (f.endswith(\".conllu\") and 'test' in f)]\n",
    "    \n",
    "    train_file = None\n",
    "    dev_file = None\n",
    "\n",
    "    # encode\n",
    "    for conllu_file in conllu_files:\n",
    "        print(\"[INFO] Cleaning\",conllu_file)\n",
    "        deps_treebank = os.path.join(tb_f, conllu_file)\n",
    "        output_file = os.path.join(tb_f, conllu_file)\n",
    "        \n",
    "        with open(deps_treebank, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        with open(deps_treebank, \"w\") as f:\n",
    "            for line in lines:\n",
    "                if re.match(r\"^\\d+-.*\", line):\n",
    "                    continue\n",
    "                f.write(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 80% split of treebanks without dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform holdout of 20%\n",
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "treebank_path = \"/home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-train.backup\"\n",
    "trees = D_Tree.read_conllu_file(treebank_path, filter_projective=False)\n",
    "\n",
    "trees_train = trees[:int(len(trees)*0.8)]\n",
    "trees_dev = trees[int(len(trees)*0.8):]\n",
    "\n",
    "with open(\"/home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-train.conllu\", \"w\") as f:\n",
    "        for t in trees_train:\n",
    "                t.remove_dummy()\n",
    "                f.write(str(t))\n",
    "with open(\"/home/poli/Treebanks/d21/UD_Galician-TreeGal/gl_treegal-ud-dev.conllu\", \"w\") as f:\n",
    "        for t in trees_dev:\n",
    "                t.remove_dummy()\n",
    "                f.write(str(t))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode and generate machamp configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Encoding with D_BrkBasedEncoding\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Galician-TreeGal\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Lithuanian-HSE\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Belarusian-HSE\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Old_East_Slavic-RNC\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Marathi-UFAL\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Welsh-CCG\n",
      "[INFO] Encoding with D_Brk2PBasedEncoding\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Galician-TreeGal\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Lithuanian-HSE\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Belarusian-HSE\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Old_East_Slavic-RNC\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Marathi-UFAL\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Welsh-CCG\n",
      "[INFO] Encoding with D_Brk4BitsEncoding\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Galician-TreeGal\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Lithuanian-HSE\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Belarusian-HSE\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Old_East_Slavic-RNC\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Marathi-UFAL\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Welsh-CCG\n",
      "[INFO] Encoding with D_Brk7BitsEncoding\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Galician-TreeGal\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Lithuanian-HSE\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Belarusian-HSE\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Old_East_Slavic-RNC\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Marathi-UFAL\n",
      "[INFO] Processing /home/poli/Treebanks/d21/UD_Welsh-CCG\n"
     ]
    }
   ],
   "source": [
    "from codelin.encs.enc_deps import *\n",
    "from codelin.models.deps_tree import D_Tree\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "config_singletask = {\n",
    "    \"dependency\":{\n",
    "        \"train_data_path\":\"XXX\",\n",
    "        \"dev_data_path\":\"XXX\",\n",
    "        \"word_idx\":0,\n",
    "        \"tasks\":{\n",
    "            \"label\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":2\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "config_multitask = {\n",
    "    \"dependency\":{\n",
    "        \"train_data_path\":\"XXX\",\n",
    "        \"dev_data_path\":\"XXX\",\n",
    "        \"word_idx\":0,\n",
    "        \"tasks\":{\n",
    "            \"brk\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":2\n",
    "            },\n",
    "            \"reltype\":{\n",
    "                \"task_type\":\"seq\",\n",
    "                \"column_idx\":3\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "treebank_path = \"/home/poli/Treebanks/d21/\"\n",
    "treebank_folders = [os.path.join(treebank_path, f) for f in os.listdir(treebank_path) if os.path.isdir(os.path.join(treebank_path, f))]\n",
    "mtl = [True, False]\n",
    "\n",
    "brk_bs = D_BrkBasedEncoding(separator=\"[_]\", displacement=False)\n",
    "brk_2p = D_Brk2PBasedEncoding(separator=\"[_]\", displacement=False)\n",
    "brk_4b = D_Brk4BitsEncoding(separator=\"[_]\")\n",
    "brk_7b = D_Brk7BitsEncoding(separator=\"[_]\")\n",
    "\n",
    "encodings = [brk_bs, brk_2p, brk_4b, brk_7b]\n",
    "filter_projective = False\n",
    "\n",
    "for encoder in encodings:\n",
    "    print(\"[INFO] Encoding with\", encoder.__class__.__name__)\n",
    "\n",
    "    for tb_f in treebank_folders:\n",
    "        print(\"[INFO] Processing\",tb_f)\n",
    "        # get all conllu files\n",
    "        treebank_name = (tb_f.split(\"/\")[-1])\n",
    "        conllu_files = [os.path.join(tb_f, f) for f in os.listdir(tb_f) if (f.endswith(\".conllu\"))]\n",
    "        \n",
    "        train_file = \"\"\n",
    "        dev_file = \"\"\n",
    "\n",
    "        # encode\n",
    "        for conllu_file in conllu_files:\n",
    "            deps_treebank = os.path.join(tb_f, conllu_file)\n",
    "            output_file = os.path.join(tb_f, conllu_file)\n",
    "            \n",
    "            target_extension = \"_\"+encoder.__class__.__name__+\".labels\"\n",
    "            output_file = output_file.replace(\".conllu\", target_extension)  \n",
    "            \n",
    "            if \"train\" in output_file:\n",
    "                train_file = output_file\n",
    "            elif \"dev\" in output_file:\n",
    "                dev_file = output_file\n",
    "            \n",
    "            trees = D_Tree.read_conllu_file(deps_treebank, \n",
    "                                            filter_projective=filter_projective)\n",
    "\n",
    "            with open(output_file, \"w\") as f:\n",
    "                for tree in trees:\n",
    "                    lin_tree = encoder.encode(tree)\n",
    "                    f.write(lin_tree.to_string(f_idx_dict=None, \n",
    "                                            add_bos_eos=True, \n",
    "                                            separate_columns=True) +\"\\n\")\n",
    "            \n",
    "            # save a clean test\n",
    "            if 'test' in conllu_file and filter_projective:\n",
    "                output_file = output_file.replace(\".labels\", \"-clean.conllu\")\n",
    "                with open(output_file, \"w\") as f:\n",
    "                    for tree in trees:\n",
    "                        tree.remove_dummy()\n",
    "                        f.write(\"# text = \"+tree.get_sentence()+\"\\n\")\n",
    "                        f.write(str(tree))\n",
    "        \n",
    "        current_config = config_multitask.copy()\n",
    "        current_config[\"dependency\"][\"train_data_path\"] = train_file.replace('poli', 'diego.roca')\n",
    "        current_config[\"dependency\"][\"dev_data_path\"] = dev_file.replace('poli', 'diego.roca')\n",
    "\n",
    "        config_name = \"config_\"+encoder.__class__.__name__+\".json\"\n",
    "        with open(os.path.join(tb_f, config_name), \"w\") as f:\n",
    "            json.dump(current_config, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
